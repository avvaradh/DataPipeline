link|title_x|description_x|loaddate
http://arxiv.org/abs/1903.12178|Open-ended  Evolution  and  a  Mechanism  of  Novelties  in  Web  Services.  (arXiv:1903.12178v1  [cs.SI])|<p>Analogous  to  living  ecosystems  in  nature,  web  services  form  an  artificialecosystem  consisting  of  many  tags  and  their  associated  media,  such  asphotographs,  movies,  and  web  pages  created  by  human  users.  Concerningbiological  ecosystems,  we  regard  tag  as  a  species  and  human  as  a  hiddenenvironmental  resource.  We  subsequently  analyze  the  evolution  of  the  webservices,  in  particular  social  tagging  systems,  with  respect  to  theself-organization  of  new  tags.  The  evolution  of  new  combinations  of  tags  isanalyzed  as  the  open-ended  evolution  (OEE)  index.  The  tag  meaning  is  computedby  the  types  of  associated  tags;  tags  that  vary  their  meanings  temporallyexist.  We  argue  that  such  tags  are  the  examples  of  OEE.</p>|2019-04-01  22:52:19.484094
http://arxiv.org/abs/1903.12204|Mutex-based  Desanonymization  of  an  Anonymous  Read/Write  Memory.  (arXiv:1903.12204v1  [cs.DC])|<p>Anonymous  shared  memory  is  a  memory  in  which  processes  use  different  namesfor  the  same  shared  read/write  register.  As  an  example,  a  shared  register  named$A$  by  a  process  $p$  and  a  shared  register  named  $B$  by  another  process  $q$  cancorrespond  to  the  very  same  register  $X$,  and  similarly  for  the  names  $B$  at$p$  and  $A$  at  $q$  which  can  correspond  to  the  same  register  $Y\neq  X$.  Hence,there  is  a  permanent  disagreement  on  the  register  names  among  the  processes.This  new  notion  of  anonymity  was  recently  introduced  by  G.  Taubenfeld  (PODC2017),  who  presented  several  memory-anonymous  algorithms  and  impossibilityresults.</p><p>This  paper  introduces  a  new  problem  (new  to  our  knowledge),  that  consists  in"desanonymizing"  an  anonymous  shared  memory.  To  this  end,  it  presents  analgorithm  that,  starting  with  a  shared  memory  made  up  of  $m$  anonymousread/write  atomic  registers  (i.e.,  there  is  no  a  priori  agreement  on  theirnames),  allows  each  process  to  compute  a  local  addressing  mapping,  such  thatall  the  processes  agree  on  the  names  of  each  register.  The  proposedconstruction  is  based  on  an  underlying  deadlock-free  mutex  algorithm  for  $n\geq2$  processes  (recently  proposed  in  a  paper  co-authored  by  some  of  the  authorsof  this  paper),  and  consequently  inherits  its  necessary  and  sufficientcondition  on  the  size  $m$  of  the  anonymous  memory,  namely  $m$  must  belongs  tothe  set  $M(n)=\{m:~$  such  that  $\forall~  \ell:  1&lt;\ell  \leq  n:~\gcd(\ell,m)=1\}\setminus  \{1\}$.  This  algorithm,  which  is  also  symmetric  inthe  sense  process  identities  can  only  be  compared  by  equality,  requires  theparticipation  of  all  the  processes;  hence  it  can  be  part  of  the  systeminitialization.  Last  but  not  least,  the  proposed  algorithm  has  a  first-classnoteworthy  property,  namely,  its  simplicity.</p>|2019-04-01  22:52:19.484139
http://arxiv.org/abs/1903.12206|Counting  with  Focus  for  Free.  (arXiv:1903.12206v1  [cs.CV])|<p>This  paper  aims  to  count  arbitrary  objects  in  images.  The  leading  countingapproaches  start  from  point  annotations  per  object  from  which  they  constructdensity  maps.  Then,  their  training  objective  transforms  input  images  to  densitymaps  through  deep  convolutional  networks.  We  posit  that  the  point  annotationsserve  more  supervision  purposes  than  just  constructing  density  maps.  Weintroduce  ways  to  repurpose  the  points  for  free.  First,  we  propose  supervisedfocus  from  segmentation,  where  points  are  converted  into  binary  maps.  Thebinary  maps  are  combined  with  a  network  branch  and  accompanying  loss  functionto  focus  on  areas  of  interest.  Second,  we  propose  supervised  focus  from  globaldensity,  where  the  ratio  of  point  annotations  to  image  pixels  is  used  inanother  branch  to  regularize  the  overall  density  estimation.  To  assist  both  thedensity  estimation  and  the  focus  from  segmentation,  we  also  introduce  animproved  kernel  size  estimator  for  the  point  annotations.  Experiments  on  fourdatasets  show  that  all  our  contributions  reduce  the  counting  error,  regardlessof  the  base  network,  resulting  in  state-of-the-art  accuracy  using  only  a  singlenetwork.  Finally,  we  are  the  first  to  count  on  WIDER  FACE,  allowing  us  to  showthe  benefits  of  our  approach  in  handling  varying  object  scales  and  crowdinglevels.</p>|2019-04-01  22:52:19.484180
http://arxiv.org/abs/1903.12211|Privacy  of  trajectory  micro-data  :  a  survey.  (arXiv:1903.12211v1  [cs.CR])|<p>We  survey  the  literature  on  the  privacy  of  trajectory  micro-data,  i.e.,spatiotemporal  information  about  the  mobility  of  individuals,  whose  collectionis  becoming  increasingly  simple  and  frequent  thanks  to  emerging  information  andcommunication  technologies.  The  focus  of  our  review  is  on  privacy-preservingdata  publishing  (PPDP),  i.e.,  the  publication  of  databases  of  trajectorymicro-data  that  preserve  the  privacy  of  the  monitored  individuals.  We  classifyand  present  the  literature  of  attacks  against  trajectory  micro-data,  as  well  assolutions  proposed  to  date  for  protecting  databases  from  such  attacks.  Thispaper  serves  as  an  introductory  reading  on  a  critical  subject  in  an  era  ofgrowing  awareness  about  privacy  risks  connected  to  digital  services,  andprovides  insights  into  open  problems  and  future  directions  for  research.</p>|2019-04-01  22:52:19.484250
http://arxiv.org/abs/1903.12212|All  about  Structure:  Adapting  Structural  Information  across  Domains  for  Boosting  Semantic  Segmentation.  (arXiv:1903.12212v1  [cs.CV])|<p>In  this  paper  we  tackle  the  problem  of  unsupervised  domain  adaptation  for  thetask  of  semantic  segmentation,  where  we  attempt  to  transfer  the  knowledgelearned  upon  synthetic  datasets  with  ground-truth  labels  to  real-world  imageswithout  any  annotation.  With  the  hypothesis  that  the  structural  content  ofimages  is  the  most  informative  and  decisive  factor  to  semantic  segmentation  andcan  be  readily  shared  across  domains,  we  propose  a  Domain  Invariant  StructureExtraction  (DISE)  framework  to  disentangle  images  into  domain-invariantstructure  and  domain-specific  texture  representations,  which  can  furtherrealize  image-translation  across  domains  and  enable  label  transfer  to  improvesegmentation  performance.  Extensive  experiments  verify  the  effectiveness  of  ourproposed  DISE  model  and  demonstrate  its  superiority  over  severalstate-of-the-art  approaches.</p>|2019-04-01  22:52:19.484314
http://arxiv.org/abs/1903.12216|Towards  6G  Networks:  Use  Cases  and  Technologies.  (arXiv:1903.12216v1  [cs.NI])|<p>As  the  digital  world  becomes  increasingly  intelligent,  automated  andubiquitous,  the  flow  of  data  becomes  ever  more  vital.  Mobile  wireless  networksare  the  data  highways,  and  in  a  fully  connected,  intelligent  digital  world,they  will  need  to  connect  everything  from  people,  vehicles,  sensors,  data,cloud  resources  and  even  robotic  agents.  Fifth  generation  (5G)  wirelessnetworks  that  are  being  released  soon  offer  significant  advances,  but  may  beunable  to  meet  the  full  connectivity  demands  of  emerging  systems.  This  paperenvisions  how  6G  systems  can  be  developed  to  address  the  needs  of  smartnetworks  of  the  future.  The  article  considers  several  potential  6G  use  casesand  attempts  to  provide  estimates  on  requirements  to  guide  design.  The  demandsare  daunting,  but  several  promising  technologies  that  can  provide  the  basis  for6G  systems  are  also  surveyed.</p>|2019-04-01  22:52:19.484349
http://arxiv.org/abs/1903.12220|The  Algorithmic  Automation  Problem:  Prediction,  Triage,  and  Human  Effort.  (arXiv:1903.12220v1  [cs.CV])|<p>In  a  wide  array  of  areas,  algorithms  are  matching  and  surpassing  theperformance  of  human  experts,  leading  to  consideration  of  the  roles  of  humanjudgment  and  algorithmic  prediction  in  these  domains.  The  discussion  aroundthese  developments,  however,  has  implicitly  equated  the  specific  task  ofprediction  with  the  general  task  of  automation.  We  argue  here  that  automationis  broader  than  just  a  comparison  of  human  versus  algorithmic  performance  on  atask;  it  also  involves  the  decision  of  which  instances  of  the  task  to  give  tothe  algorithm  in  the  first  place.  We  develop  a  general  framework  that  posesthis  latter  decision  as  an  optimization  problem,  and  we  show  how  basicheuristics  for  this  optimization  problem  can  lead  to  performance  gains  even  onheavily-studied  applications  of  AI  in  medicine.  Our  framework  also  serves  tohighlight  how  effective  automation  depends  crucially  on  estimating  bothalgorithmic  and  human  error  on  an  instance-by-instance  basis,  and  our  resultsshow  how  improvements  in  these  error  estimation  problems  can  yield  significantgains  for  automation  as  well.</p>|2019-04-01  22:52:19.484383
http://arxiv.org/abs/1903.12221|Mitigating  Cold  Starts  in  Serverless  Platforms:  A  Pool-Based  Approach.  (arXiv:1903.12221v1  [cs.DC])|<p>Rapid  adoption  of  the  serverless  (or  Function-as-a-Service,  FaaS)  paradigm,pioneered  by  Amazon  with  AWS  Lambda  and  followed  by  numerous  commercialofferings  and  open  source  projects,  introduces  new  challenges  in  designing  thecloud  infrastructure,  balancing  between  performance  and  cost.  While  instantper-request  elasticity  that  FaaS  platforms  typically  offer  applicationdevelopers  makes  it  possible  to  achieve  high  performance  of  bursty  workloadswithout  over-provisioning,  such  elasticity  often  involves  extra  latencyassociated  with  on-demand  provisioning  of  individual  runtime  containers  thatserve  the  functions.  This  phenomenon  is  often  called  cold  starts,  as  opposed  tothe  situation  when  a  function  is  served  by  a  pre-provisioned  "warm"  container,ready  to  serve  requests  with  close  to  zero  overhead.  Providers  are  constantlyworking  on  techniques  aimed  at  reducing  cold  starts.  A  common  approach  toreduce  cold  starts  is  to  maintain  a  pool  of  warm  containers,  in  anticipation  offuture  requests.  In  this  report,  we  address  the  cold  start  problem  inserverless  architectures,  specifically  under  the  Knative  Serving  FaaS  platform.We  describe  our  implementation  leveraging  a  pool  of  function  instances,  andevaluate  the  latency  compared  to  the  original  implementation,  resulting  in  a85%  reduction  of  P99  response  time  for  a  single  instance  pool.</p>|2019-04-01  22:52:19.484414
http://arxiv.org/abs/1903.12225|Arc-disjoint  Strong  Spanning  Subdigraphs  of  Semicomplete  Compositions.  (arXiv:1903.12225v1  [cs.DM])|<p>A  strong  arc  decomposition  of  a  digraph  $D=(V,A)$  is  a  decomposition  of  itsarc  set  $A$  into  two  disjoint  subsets  $A_1$  and  $A_2$  such  that  both  of  thespanning  subdigraphs  $D_1=(V,A_1)$  and  $D_2=(V,A_2)$  are  strong.  Let  $T$  be  adigraph  with  $t$  vertices  $u_1,\dots  ,  u_t$  and  let  $H_1,\dots  H_t$  be  digraphssuch  that  $H_i$  has  vertices  $u_{i,j_i},\  1\le  j_i\le  n_i.$  Then  thecomposition  $Q=T[H_1,\dots  ,  H_t]$  is  a  digraph  with  vertex  set  $\cup_{i=1}^tV(H_i)=\{u_{i,j_i}\mid  1\le  i\le  t,  1\le  j_i\le  n_i\}$  and  arc  set  \[\left(\cup^t_{i=1}A(H_i)  \right)  \cup  \left(  \cup_{u_iu_p\in  A(T)}\{u_{ij_i}u_{pq_p}  \mid  1\le  j_i\le  n_i,  1\le  q_p\le  n_p\}  \right).  \]  Weobtain  a  characterization  of  digraph  compositions  $Q=T[H_1,\dots  H_t]$  whichhave  a  strong  arc  decomposition  when  $T$  is  a  semicomplete  digraph  and  each$H_i$  is  an  arbitrary  digraph.  Our  characterization  generalizes  acharacterization  by  Bang-Jensen  and  Yeo  (2003)  of  semicomplete  digraphs  with  astrong  arc  decomposition  and  solves  an  open  problem  by  Sun,  Gutin  and  Ai  (2018)on  strong  arc  decompositions  of  digraph  compositions  $Q=T[H_1,\dots  ,  H_t]$  inwhich  $T$  is  semicomplete  and  each  $H_i$  is  arbitrary.  Our  proofs  areconstructive  and  imply  the  existence  of  a  polynomial  algorithm  for  constructinga  \good{}  decomposition  of  a  digraph  $Q=T[H_1,\dots  ,  H_t]$,  with  $T$semicomplete,  whenever  such  a  decomposition  exists.</p>|2019-04-01  22:52:19.484445
http://arxiv.org/abs/1903.12226|Co-evolving  Tracing  and  Fault  Injection  with  Box  of  Pain.  (arXiv:1903.12226v1  [cs.DC])|<p>Distributed  systems  are  hard  to  reason  about  largely  because  of  uncertaintyabout  what  may  go  wrong  in  a  particular  execution,  and  about  whether  the  systemwill  mitigate  those  faults.  Tools  that  perturb  executions  can  help  test  whethera  system  is  robust  to  faults,  while  tools  that  observe  executions  can  helpbetter  understand  their  system-wide  effects.  We  present  Box  of  Pain,  a  tracerand  fault  injector  for  unmodified  distributed  systems  that  addresses  bothconcerns  by  interposing  at  the  system  call  level  and  dynamically  reconstructingthe  partial  order  of  communication  events  based  on  causal  relationships.  Box  ofPain's  lightweight  approach  to  tracing  and  focus  on  simulating  the  effects  ofpartial  failures  on  communication  rather  than  the  failures  themselves  sets  itapart  from  other  tracing  and  fault  injection  systems.  We  present  evidence  ofthe  promise  of  Box  of  Pain  and  its  approach  to  lightweight  observation  andperturbation  of  distributed  systems.</p>|2019-04-01  22:52:19.484475
http://arxiv.org/abs/1903.12230|Learning  to  Transfer  Examples  for  Partial  Domain  Adaptation.  (arXiv:1903.12230v1  [cs.CV])|<p>Domain  adaptation  is  critical  for  learning  in  new  and  unseen  environments.With  domain  adversarial  training,  deep  networks  can  learn  disentangled  andtransferable  features  that  effectively  diminish  the  dataset  shift  between  thesource  and  target  domains  for  knowledge  transfer.  In  the  era  of  Big  Data,  theready  availability  of  large-scale  labeled  datasets  has  stimulated  wide  interestin  partial  domain  adaptation  (PDA),  which  transfers  a  recognizer  from  a  labeledlarge  domain  to  an  unlabeled  small  domain.  It  extends  standard  domainadaptation  to  the  scenario  where  target  labels  are  only  a  subset  of  sourcelabels.  Under  the  condition  that  target  labels  are  unknown,  the  key  challengeof  PDA  is  how  to  transfer  relevant  examples  in  the  shared  classes  to  promotepositive  transfer,  and  ignore  irrelevant  ones  in  the  specific  classes  tomitigate  negative  transfer.  In  this  work,  we  propose  a  unified  approach  to  PDA,Example  Transfer  Network  (ETN),  which  jointly  learns  domain-invariantrepresentations  across  the  source  and  target  domains,  and  a  progressiveweighting  scheme  that  quantifies  the  transferability  of  source  examples  whilecontrolling  their  importance  to  the  learning  task  in  the  target  domain.  Athorough  evaluation  on  several  benchmark  datasets  shows  that  our  approachachieves  state-of-the-art  results  for  partial  domain  adaptation  tasks.</p>|2019-04-01  22:52:19.484506
http://arxiv.org/abs/1903.12235|Information  Theoretic  Feature  Transformation  Learning  for  Brain  Interfaces.  (arXiv:1903.12235v1  [cs.LG])|<p>Objective:  A  variety  of  pattern  analysis  techniques  for  model  training  inbrain  interfaces  exploit  neural  feature  dimensionality  reduction  based  onfeature  ranking  and  selection  heuristics.  In  the  light  of  broad  evidencedemonstrating  the  potential  sub-optimality  of  ranking  based  feature  selectionby  any  criterion,  we  propose  to  extend  this  focus  with  an  information  theoreticlearning  driven  feature  transformation  concept.  Methods:  We  present  a  maximummutual  information  linear  transformation  (MMI-LinT),  and  a  nonlineartransformation  (MMI-NonLinT)  framework  derived  by  a  general  definition  of  thefeature  transformation  learning  problem.  Empirical  assessments  are  performedbased  on  electroencephalographic  (EEG)  data  recorded  during  a  four  class  motorimagery  brain-computer  interface  (BCI)  task.  Exploiting  state-of-the-artmethods  for  initial  feature  vector  construction,  we  compare  the  proposedapproaches  with  conventional  feature  selection  based  dimensionality  reductiontechniques  which  are  widely  used  in  brain  interfaces.  Furthermore,  for  themulti-class  problem,  we  present  and  exploit  a  hierarchical  graphical  modelbased  BCI  decoding  system.  Results:  Both  binary  and  multi-class  decodinganalyses  demonstrate  significantly  better  performances  with  the  proposedmethods.  Conclusion:  Information  theoretic  feature  transformations  are  capableof  tackling  potential  confounders  of  conventional  approaches  in  varioussettings.  Significance:  We  argue  that  this  concept  provides  significantinsights  to  extend  the  focus  on  feature  selection  heuristics  to  a  broaderdefinition  of  feature  transformation  learning  in  brain  interfaces.</p>|2019-04-01  22:52:19.484562
http://arxiv.org/abs/1903.12238|Modeling  Acoustic-Prosodic  Cues  for  Word  Importance  Prediction  in  Spoken  Dialogues.  (arXiv:1903.12238v1  [cs.CL])|<p>Prosodic  cues  in  conversational  speech  aid  listeners  in  discerning  a  message.We  investigate  whether  acoustic  cues  in  spoken  dialogue  can  be  used  to  identifythe  importance  of  individual  words  to  the  meaning  of  a  conversation  turn.Individuals  who  are  Deaf  and  Hard  of  Hearing  often  rely  on  real-time  captionsin  live  meetings.  Word  error  rate,  a  traditional  metric  for  evaluatingautomatic  speech  recognition,  fails  to  capture  that  some  words  are  moreimportant  for  a  system  to  transcribe  correctly  than  others.  We  present  andevaluate  neural  architectures  that  use  acoustic  features  for  3-class  wordimportance  prediction.  Our  model  performs  competitively  againststate-of-the-art  text-based  word-importance  prediction  models,  and  itdemonstrates  particular  benefits  when  operating  on  imperfect  ASR  output.</p>|2019-04-01  22:52:19.484596
http://arxiv.org/abs/1903.12239|SpaceNet  MVOI:  a  Multi-View  Overhead  Imagery  Dataset.  (arXiv:1903.12239v1  [cs.CV])|<p>Detection  and  segmentation  of  objects  in  overheard  imagery  is  a  challengingtask.  The  variable  density,  random  orientation,  small  size,  andinstance-to-instance  heterogeneity  of  objects  in  overhead  imagery  calls  forapproaches  distinct  from  existing  models  designed  for  natural  scene  datasets.Though  new  overhead  imagery  datasets  are  being  developed,  they  almostuniversally  comprise  a  single  view  taken  from  directly  overhead  ("at  nadir"),failing  to  address  one  critical  variable:  look  angle.  By  contrast,  views  varyin  real-world  overhead  imagery,  particularly  in  dynamic  scenarios  such  asnatural  disasters  where  first  looks  are  often  over  40  degrees  off-nadir.  Thisrepresents  an  important  challenge  to  computer  vision  methods,  as  changing  viewangle  adds  distortions,  alters  resolution,  and  changes  lighting.  At  present,the  impact  of  these  perturbations  for  algorithmic  detection  and  segmentation  ofobjects  is  untested.  To  address  this  problem,  we  introduce  the  SpaceNetMulti-View  Overhead  Imagery  (MVOI)  Dataset,  an  extension  of  the  SpaceNet  opensource  remote  sensing  dataset.  MVOI  comprises  27  unique  looks  from  a  broadrange  of  viewing  angles  (-32  to  54  degrees).  Each  of  these  images  cover  thesame  geography  and  are  annotated  with  126,747  building  footprint  labels,enabling  direct  assessment  of  the  impact  of  viewpoint  perturbation  on  modelperformance.  We  benchmark  multiple  leading  segmentation  and  object  detectionmodels  on:  (1)  building  detection,  (2)  generalization  to  unseen  viewing  anglesand  resolutions,  and  (3)  sensitivity  of  building  footprint  extraction  tochanges  in  resolution.  We  find  that  segmentation  and  object  detection  modelsstruggle  to  identify  buildings  in  off-nadir  imagery  and  generalize  poorly  tounseen  views,  presenting  an  important  benchmark  to  explore  the  broadly  relevantchallenge  of  detecting  small,  heterogeneous  target  objects  in  visually  dynamiccontexts.</p>|2019-04-01  22:52:19.484628
http://arxiv.org/abs/1903.12243|DEEP-FRI:  Sampling  outside  the  box  improves  soundness.  (arXiv:1903.12243v1  [cs.CC])|<p>Motivated  by  the  quest  for  scalable  and  succinct  zero  knowledge  arguments,  werevisit  worst-case-to-average-case  reductions  for  linear  spaces,  raised  by[Rothblum,  Vadhan,  Wigderson,  STOC  2013].  We  first  show  a  sharp  quantitativeform  of  a  theorem  which  says  that  if  an  affine  space  $U$  is  $\delta$-far  inrelative  Hamming  distance  from  a  linear  code  $V$  -  this  is  the  worst-caseassumption  -  then  most  elements  of  $U$  are  almost  $\delta$-far  from  $V$  -  thisis  the  average  case.  This  leads  to  an  optimal  analysis  of  the  soundness  of  theFRI  protocol  of  [Ben-Sasson,  et.al.,  eprint  2018]  for  proving  proximity  toReed-Solomon  codes.</p><p>To  further  improve  soundness,  we  sample  outside  the  box.  We  suggest  a  newprotocol  which  asks  a  prover  for  values  of  a  polynomial  at  points  outside  thedomain  of  evaluation  of  the  Reed-Solomon  code.  We  call  this  technique  DomainExtending  for  Eliminating  Pretenders  (DEEP).</p><p>We  use  the  DEEP  technique  to  devise  two  new  protocols:  (1)  An  InteractiveOracle  Proof  of  Proximity  (IOPP)  for  RS  codes,  called  DEEP-FRI.  This  soundnessof  the  protocol  improves  upon  that  of  the  FRI  protocol  while  retaining  lineararithmetic  proving  complexity  and  logarithmic  verifier  arithmetic  complexity.(2)  An  Interactive  Oracle  Proof  (IOP)  for  the  Algebraic  Linking  IOP  (ALI)protocol  used  to  construct  zero  knowledge  scalable  transparent  arguments  ofknowledge  (ZK-STARKs)  in  [Ben-Sasson  et  al.,  eprint  2018].  The  new  protocol,called  DEEP-ALI,  improves  soundness  of  this  crucial  step  from  a  small  constant$&lt;  1/8$  to  a  constant  arbitrarily  close  to  $1$.</p>|2019-04-01  22:52:19.484659
http://arxiv.org/abs/1903.12247|iGen:  Dynamic  Interaction  Inference  for  Configurable  Software.  (arXiv:1903.12247v1  [cs.SE])|<p>To  develop,  analyze,  and  evolve  today's  highly  configurable  software  systems,developers  need  deep  knowledge  of  a  system's  configuration  options,  e.g.,  howoptions  need  to  be  set  to  reach  certain  locations,  what  configurations  to  usefor  testing,  etc.  Today,  acquiring  this  detailed  information  requires  manualeffort  that  is  difficult,  expensive,  and  error  prone.  In  this  paper,  we  proposeiGen,  a  novel,  lightweight  dynamic  analysis  technique  that  automaticallydiscovers  a  program's  \emph{interactions}---expressive  logical  formulae  thatgive  developers  rich  and  detailed  information  about  how  a  system'sconfiguration  option  settings  map  to  particular  code  coverage.  iGen  employs  aniterative  algorithm  that  runs  a  system  under  a  small  set  of  configurations,capturing  coverage  data;  processes  the  coverage  data  to  infer  potentialinteractions;  and  then  generates  new  configurations  to  further  refineinteractions  in  the  next  iteration.  We  evaluated  iGen  on  29  programs  spanningfive  languages;  the  breadth  of  this  study  would  be  unachievable  using  priorinteraction  inference  tools.  Our  results  show  that  iGen  finds  preciseinteractions  based  on  a  very  small  fraction  of  the  number  of  possibleconfigurations.  Moreover,  iGen's  results  confirm  several  earlier  hypothesesabout  typical  interaction  distributions  and  structures.</p>|2019-04-01  22:52:19.484739
http://arxiv.org/abs/1903.12248|Adversarial  Approximate  Inference  for  Speech  to  Electroglottograph  Conversion.  (arXiv:1903.12248v1  [eess.AS])|<p>Speech  produced  by  human  vocal  apparatus  conveys  substantial  non-semanticinformation  including  the  gender  of  the  speaker,  voice  quality,  affectivestate,  abnormalities  in  the  vocal  apparatus  etc.  Such  information  is  attributedto  the  properties  of  the  voice  source  signal,  which  is  usually  estimated  fromthe  speech  signal.  However,  most  of  the  source  estimation  techniques  dependheavily  on  the  goodness  of  the  model  assumptions  and  are  prone  to  noise.  Apopular  alternative  is  to  indirectly  obtain  the  source  information  through  theElectroglottographic  (EGG)  signal  that  measures  the  electrical  admittancearound  the  vocal  folds  using  a  dedicated  hardware.  In  this  paper,  we  addressthe  problem  of  estimating  the  EGG  signal  directly  from  the  speech  signal,devoid  of  any  hardware.  Sampling  from  the  intractable  conditional  distributionof  the  EGG  signal  given  the  speech  signal  is  accomplished  through  optimizationof  an  evidence  lower  bound.  This  is  constructed  via  minimization  of  theKL-divergence  between  the  true  and  the  approximated  posteriors  of  a  latentvariable  learned  using  a  deep  neural  auto-encoder  that  serves  an  informativeprior  which  reconstructs  the  EGG  signal.  We  demonstrate  the  efficacy  of  themethod  to  generate  EGG  signal  by  conducting  several  experiments  on  datasetscomprising  multiple  speakers,  voice  qualities,  noise  settings  and  speechpathologies.  The  proposed  method  is  evaluated  on  many  benchmark  metrics  and  isfound  to  agree  with  the  gold  standards  while  being  better  than  thestate-of-the-art  algorithms  on  a  few  tasks  such  as  epoch  extraction.</p>|2019-04-01  22:52:19.484790
http://arxiv.org/abs/1903.12254|Proving  Differential  Privacy  with  Shadow  Execution.  (arXiv:1903.12254v1  [cs.PL])|<p>Recent  work  on  formal  verification  of  differential  privacy  shows  a  trendtoward  usability  and  expressiveness  --  generating  a  correctness  proof  ofsophisticated  algorithm  while  minimizing  the  annotation  burden  on  programmers.Sometimes,  combining  those  two  requires  substantial  changes  to  program  logics:one  recent  paper  is  able  to  verify  Report  Noisy  Max  automatically,  but  itinvolves  a  complex  verification  system  using  customized  program  logics  andverifiers.</p><p>In  this  paper,  we  propose  a  new  proof  technique,  called  shadow  execution,  andembed  it  into  a  language  called  ShadowDP.  ShadowDP  uses  shadow  execution  togenerate  proofs  of  differential  privacy  with  very  few  programmer  annotationsand  without  relying  on  customized  logics  and  verifiers.  In  addition  toverifying  Report  Noisy  Max,  we  show  that  it  can  verify  a  new  variant  of  SparseVector  that  reports  the  gap  between  some  noisy  query  answers  and  the  noisythreshold.  Moreover,  ShadowDP  reduces  the  complexity  of  verification:  for  allof  the  algorithms  we  have  evaluated,  type  checking  and  verification  in  totaltakes  at  most  3  seconds,  while  prior  work  takes  minutes  on  the  same  algorithms.</p>|2019-04-01  22:52:19.484824
http://arxiv.org/abs/1903.12255|Improving  Object  Detection  with  Inverted  Attention.  (arXiv:1903.12255v1  [cs.CV])|<p>Improving  object  detectors  against  occlusion,  blur  and  noise  is  a  criticalstep  to  deploy  detectors  in  real  applications.  Since  it  is  not  possible  toexhaust  all  image  defects  through  data  collection,  many  researchers  seek  togenerate  hard  samples  in  training.  The  generated  hard  samples  are  either  imagesor  feature  maps  with  coarse  patches  dropped  out  in  the  spatial  dimensions.Significant  overheads  are  required  in  training  the  extra  hard  samples  and/orestimating  drop-out  patches  using  extra  network  branches.  In  this  paper,  weimprove  object  detectors  using  a  highly  efficient  and  fine-grain  mechanismcalled  Inverted  Attention  (IA).  Different  from  the  original  detector  networkthat  only  focuses  on  the  dominant  part  of  objects,  the  detector  network  with  IAiteratively  inverts  attention  on  feature  maps  and  puts  more  attention  oncomplementary  object  parts,  feature  channels  and  even  context.  Our  approach  (1)operates  along  both  the  spatial  and  channels  dimensions  of  the  feature  maps;(2)  requires  no  extra  training  on  hard  samples,  no  extra  network  parameters  forattention  estimation,  and  no  testing  overheads.  Experiments  show  that  ourapproach  consistently  improved  both  two-stage  and  single-stage  detectors  onbenchmark  databases.</p>|2019-04-01  22:52:19.484855
http://arxiv.org/abs/1903.12258|Using  Deep  Learning  Neural  Networks  and  Candlestick  Chart  Representation  to  Predict  Stock  Market.  (arXiv:1903.12258v1  [q-fin.GN])|<p>Stock  market  prediction  is  still  a  challenging  problem  because  there  are  manyfactors  effect  to  the  stock  market  price  such  as  company  news  and  performance,industry  performance,  investor  sentiment,  social  media  sentiment  and  economicfactors.  This  work  explores  the  predictability  in  the  stock  market  using  DeepConvolutional  Network  and  candlestick  charts.  The  outcome  is  utilized  to  designa  decision  support  framework  that  can  be  used  by  traders  to  provide  suggestedindications  of  future  stock  price  direction.  We  perform  this  work  using  varioustypes  of  neural  networks  like  convolutional  neural  network,  residual  networkand  visual  geometry  group  network.  From  stock  market  historical  data,  weconverted  it  to  candlestick  charts.  Finally,  these  candlestick  charts  will  befeed  as  input  for  training  a  Convolutional  Neural  Network  model.  ThisConvolutional  Neural  Network  model  will  help  us  to  analyze  the  patterns  insidethe  candlestick  chart  and  predict  the  future  movements  of  stock  market.  Theeffectiveness  of  our  method  is  evaluated  in  stock  market  prediction  with  apromising  results  92.2%  and  92.1%  accuracy  for  Taiwan  and  Indonesian  stockmarket  dataset  respectively.  The  constructed  model  have  been  implemented  as  aweb-based  system  freely  available  at  <a  href="http://140.138.155.216/deepcandle/">this  http  URL</a>  forpredicting  stock  market  using  candlestick  chart  and  deep  learning  neuralnetworks.</p>|2019-04-01  22:52:19.484886
http://arxiv.org/abs/1903.12259|Efficient  Use  of  Spectral  Resources  in  Wireless  Communication  Using  Training  Data  Optimization.  (arXiv:1903.12259v1  [eess.SP])|<p>Wireless  communication  applications  has  acquired  a  vastly  increasing  rangeover  the  past  decade.  This  rapidly  increasing  demand  implies  limitations  onutilizing  wireless  resources.  One  of  the  most  important  resources  in  wirelesscommunication  is  frequency  spectrum.  This  thesis  provides  different  solutionstowards  increasing  the  spectral  efficiency.  The  first  solution  provided  in  thisthesis  is  to  use  a  more  accurate  optimization  metric:  maximal  acheivable  rate(compared  to  traditional  metric:  ergodic  capacity)  to  optimize  training  datasize  in  wireless  communication.  Training  data  symbols  are  previously  knownsymbols  to  the  receiver  inserted  in  data  packets  which  are  used  by  receiver  toacquire  channel  state  information  (CSI).  Optimizing  training  data  size  withrespect  to  our  proposed  tight  optimization  metric,  we  could  achieve  higherrates  especially  for  short  packet  and  ultra  reliable  applications.  Our  secondproposed  solution  to  increase  spectral  efficiency  is  to  design  a  multifunctioncommunication  and  sensing  platform  utilizing  a  special  training  sequencedesign.  We  proposed  a  platform  where  two  training  sequences  are  designed,  onefor  the  base-station  and  the  other  for  the  user.  By  designing  these  twotraining  sequence  such  that  they  are  uncorrelated  to  each  other,  the  basestation  will  be  able  to  distinguish  between  the  two  training  sequence.  Havingone  of  the  sequences  especially  designed  for  radar  purposes  (by  designing  itsuch  that  it  has  an  impulse-like  autocorrelation),  the  system  will  be  able  tosense  the  environment,  transmit  and  receive  the  communication  datasimultaneously.</p>|2019-04-01  22:52:19.484918
http://arxiv.org/abs/1903.12260|Digital  Signal  Processing  Techniques  for  High-Speed  Optical  Communications  Links.  (arXiv:1903.12260v1  [eess.SP])|<p>The  main  topic  of  this  thesis  is  the  application  of  advanced  Digital  SignalProcessing  (DSP)  techniques  to  high  data-rate  optical  links.  This  thesis  isdivided  in  two  parts:  Direct-Detection  systems,  and  Coherent  systems.  In  thefirst  part,  it  is  proposed  a  novel  bi-directional  architecture  for  &lt;2kmIntra-DC  link  and  a  detailed  analysis  of  self-coherent  single-sidebandtransmission  for  &lt;80km  dispersion-uncompensated  Inter-DC  link.  The  second  partinstead  focuses  on  Probabilistic  Constellation  Shaping  techniques,  and  theirimpact  on  long-haul  optical  communication  links.</p>|2019-04-01  22:52:19.484949
http://arxiv.org/abs/1903.12261|Benchmarking  Neural  Network  Robustness  to  Common  Corruptions  and  Perturbations.  (arXiv:1903.12261v1  [cs.LG])|<p>In  this  paper  we  establish  rigorous  benchmarks  for  image  classifierrobustness.  Our  first  benchmark,  ImageNet-C,  standardizes  and  expands  thecorruption  robustness  topic,  while  showing  which  classifiers  are  preferable  insafety-critical  applications.  Then  we  propose  a  new  dataset  called  ImageNet-Pwhich  enables  researchers  to  benchmark  a  classifier's  robustness  to  commonperturbations.  Unlike  recent  robustness  research,  this  benchmark  evaluatesperformance  on  common  corruptions  and  perturbations  not  worst-case  adversarialperturbations.  We  find  that  there  are  negligible  changes  in  relative  corruptionrobustness  from  AlexNet  classifiers  to  ResNet  classifiers.  Afterward  wediscover  ways  to  enhance  corruption  and  perturbation  robustness.  We  even  findthat  a  bypassed  adversarial  defense  provides  substantial  common  perturbationrobustness.  Together  our  benchmarks  may  aid  future  work  toward  networks  thatrobustly  generalize.</p>|2019-04-01  22:52:19.484980
http://arxiv.org/abs/1903.12262|Towards  Standardization  of  Data  Licenses:  The  Montreal  Data  License.  (arXiv:1903.12262v1  [cs.CY])|<p>This  paper  provides  a  taxonomy  for  the  licensing  of  data  in  the  fields  ofartificial  intelligence  and  machine  learning.  The  paper's  goal  is  to  buildtowards  a  common  framework  for  data  licensing  akin  to  the  licensing  of  opensource  software.  Increased  transparency  and  resolving  conceptual  ambiguities  inexisting  licensing  language  are  two  noted  benefits  of  the  approach  proposed  inthe  paper.  In  parallel,  such  benefits  may  help  foster  fairer  and  more  efficientmarkets  for  data  through  bringing  about  clearer  tools  and  concepts  that  betterdefine  how  data  can  be  used  in  the  fields  of  AI  and  ML.  The  paper's  approach  issummarized  in  a  new  family  of  data  license  language  -  \textit{the  Montreal  DataLicense  (MDL)}.  Alongside  this  new  license,  the  authors  and  their  collaboratorshave  developed  a  web-based  tool  to  generate  license  language  espousing  thetaxonomies  articulated  in  this  paper.</p>|2019-04-01  22:52:19.485146
http://arxiv.org/abs/1903.12264|Validation  of  a  recommender  system  for  prompting  omitted  foods  in  online  dietary  assessment  surveys.  (arXiv:1903.12264v1  [cs.CY])|<p>Recall  assistance  methods  are  among  the  key  aspects  that  improve  the  accuracyof  online  dietary  assessment  surveys.  These  methods  still  mainly  rely  onexperience  of  trained  interviewers  with  nutritional  background,  but  data  drivenapproaches  could  improve  cost-efficiency  and  scalability  of  automated  dietaryassessment.  We  evaluated  the  effectiveness  of  a  recommender  algorithm  developedfor  an  online  dietary  assessment  system  called  Intake24,  that  automates  themultiple-pass  24-hour  recall  method.  The  recommender  builds  a  model  of  eatingbehavior  from  recalls  collected  in  past  surveys.  Based  on  foods  they  havealready  selected,  the  model  is  used  to  remind  respondents  of  associated  foodsthat  they  may  have  omitted  to  report.  The  performance  of  prompts  generated  bythe  model  was  compared  to  that  of  prompts  hand-coded  by  nutritionists  in  twodietary  studies.  The  results  of  our  studies  demonstrate  that  the  recommendersystem  is  able  to  capture  a  higher  number  of  foods  omitted  by  respondents  ofonline  dietary  surveys  than  prompts  hand-coded  by  nutritionists.  However,  theconsiderably  lower  precision  of  generated  prompts  indicates  an  opportunity  forfurther  improvement  of  the  system.</p>|2019-04-01  22:52:19.485187
http://arxiv.org/abs/1903.12266|Generative  Adversarial  Networks:  recent  developments.  (arXiv:1903.12266v1  [cs.LG])|<p>In  traditional  generative  modeling,  good  data  representation  is  very  often  abase  for  a  good  machine  learning  model.  It  can  be  linked  to  goodrepresentations  encoding  more  explanatory  factors  that  are  hidden  in  theoriginal  data.  With  the  invention  of  Generative  Adversarial  Networks  (GANs),  asubclass  of  generative  models  that  are  able  to  learn  representations  in  anunsupervised  and  semi-supervised  fashion,  we  are  now  able  to  adversariallylearn  good  mappings  from  a  simple  prior  distribution  to  a  target  datadistribution.  This  paper  presents  an  overview  of  recent  developments  in  GANswith  a  focus  on  learning  latent  space  representations.</p>|2019-04-01  22:52:19.485226
http://arxiv.org/abs/1903.12269|Bit-Flip  Attack:  Crushing  Neural  Network  withProgressive  Bit  Search.  (arXiv:1903.12269v1  [cs.CV])|<p>Several  important  security  issues  of  Deep  Neural  Network  (DNN)  have  beenraised  recently  associated  with  different  applications  and  components.  The  mostwidely  investigated  security  concern  of  DNN  is  from  its  malicious  input,  a.k.aadversarial  example.  Nevertheless,  the  security  challenge  of  DNN's  parametersis  not  well  explored  yet.  In  this  work,  we  are  the  first  to  propose  a  novel  DNNweight  attack  methodology  called  Bit-Flip  Attack  (BFA)  which  can  crush  a  neuralnetwork  through  maliciously  flipping  extremely  small  amount  of  bits  within  itsweight  storage  memory  system  (i.e.,  DRAM).  The  bit-flip  operations  could  beconducted  through  well-known  Row-Hammer  attack,  while  our  main  contribution  isto  develop  an  algorithm  to  identify  the  most  vulnerable  bits  of  DNN  weightparameters  (stored  in  memory  as  binary  bits),  that  could  maximize  the  accuracydegradation  with  a  minimum  number  of  bit-flips.  Our  proposed  BFA  utilizes  aProgressive  Bit  Search  (PBS)  method  which  combines  gradient  ranking  andprogressive  search  to  identify  the  most  vulnerable  bit  to  be  flipped.  With  theaid  of  PBS,  we  can  successfully  attack  a  ResNet-18  fully  malfunction  (i.e.,top-1  accuracy  degrade  from  69.8%  to  0.1%)  only  through  13  bit-flips  out  of  93million  bits,  while  randomly  flipping  100  bits  merely  degrades  the  accuracy  byless  than  1%.</p>|2019-04-01  22:52:19.485259
http://arxiv.org/abs/1903.12270|Implementing  Noise  with  Hash  functions  for  Graphics  Processing  Units.  (arXiv:1903.12270v1  [cs.GR])|<p>We  propose  a  modification  to  Perlin  noise  which  use  computable  hash  functionsinstead  of  textures  as  lookup  tables.  We  implemented  the  FNV1,  Jenkins  andMurmur  hashes  on  Shader  Model  4.0  Graphics  Processing  Units  for  noisegeneration.  Modified  versions  of  the  FNV1  and  Jenkins  hashes  provide  very  closeperformance  compared  to  a  texture  based  Perlin  noise  implementation.  Our  noisemodification  enables  noise  function  evaluation  without  any  texture  fetches,trading  computational  power  for  memory  bandwidth.</p>|2019-04-01  22:52:19.485289
http://arxiv.org/abs/1903.12271|In  Search  of  Meaning:  Lessons,  Resources  and  Next  Steps  for  Computational  Analysis  of  Financial  Discourse.  (arXiv:1903.12271v1  [cs.CL])|<p>We  critically  assess  mainstream  accounting  and  finance  research  applyingmethods  from  computational  linguistics  (CL)  to  study  financial  discourse.  Wealso  review  common  themes  and  innovations  in  the  literature  and  assess  theincremental  contributions  of  work  applying  CL  methods  over  manual  contentanalysis.  Key  conclusions  emerging  from  our  analysis  are:  (a)  accounting  andfinance  research  is  behind  the  curve  in  terms  of  CL  methods  generally  and  wordsense  disambiguation  in  particular;  (b)  implementation  issues  mean  the  proposedbenefits  of  CL  are  often  less  pronounced  than  proponents  suggest;  (c)structural  issues  limit  practical  relevance;  and  (d)  CL  methods  and  highquality  manual  analysis  represent  complementary  approaches  to  analyzingfinancial  discourse.  We  describe  four  CL  tools  that  have  yet  to  gain  tractionin  mainstream  AF  research  but  which  we  believe  offer  promising  ways  to  enhancethe  study  of  meaning  in  financial  discourse.  The  four  tools  are  named  entityrecognition  (NER),  summarization,  semantics  and  corpus  linguistics.</p>|2019-04-01  22:52:19.485320
http://arxiv.org/abs/1903.12272|Deep  Convolutional  Spiking  Neural  Networks  for  Image  Classification.  (arXiv:1903.12272v1  [cs.NE])|<p>Spiking  neural  networks  are  biologically  plausible  counterparts  of  theartificial  neural  networks,  artificial  neural  networks  are  usually  trained  withstochastic  gradient  descent  and  spiking  neural  networks  are  trained  with  spiketiming  dependant  plasticity.  Training  deep  convolutional  neural  networks  is  amemory  and  power  intensive  job.  Spiking  networks  could  potentially  help  inreducing  the  power  usage.  There  is  a  large  pool  of  tools  for  one  to  chose  totrain  artificial  neural  networks  of  any  size,  on  the  other  hand  all  theavailable  tools  to  simulate  spiking  neural  networks  are  geared  towardscomputational  neuroscience  applications  and  they  are  not  suitable  for  real  lifeapplications.  In  this  work  we  focus  on  implementing  a  spiking  CNN  usingTensorflow  to  examine  behaviour  of  the  network  and  empirically  study  the  effectof  various  parameters  on  learning  capabilities  and  also  study  catastrophicforgetting  in  the  spiking  CNN  and  weight  initialization  problem  in  R-STDP  usingMNIST  and  N-MNIST  data  sets.</p>|2019-04-01  22:52:19.485351
http://arxiv.org/abs/1903.12282|An  Empirical  Study  of  Obsolete  Answers  on  Stack  Overflow.  (arXiv:1903.12282v1  [cs.SE])|<p>Stack  Overflow  accumulates  an  enormous  amount  of  software  engineeringknowledge.  However,  as  time  passes,  certain  knowledge  in  answers  may  becomeobsolete.  Such  obsolete  answers,  if  not  identified  or  documented  clearly,  maymislead  answer  seekers  and  cause  unexpected  problems  (e.g.,  using  an  out-datedsecurity  protocol).  In  this  paper,  we  investigate  how  the  knowledge  in  answersbecomes  obsolete  and  identify  the  characteristics  of  such  obsolete  answers.  Wefind  that:  1)  More  than  half  of  the  obsolete  answers  (58.4%)  were  probablyalready  obsolete  when  they  were  first  posted.  2)  When  an  obsolete  answer  isobserved,  only  a  small  proportion  (20.5%)  of  such  answers  are  ever  updated.  3)Answers  to  questions  in  certain  tags  (e.g.,  node.js,  ajax,  android,  andobjective-c)  are  more  likely  to  become  obsolete.  Our  findings  suggest  thatStack  Overflow  should  develop  mechanisms  to  encourage  the  whole  community  tomaintain  answers  (to  avoid  obsolete  answers)  and  answer  seekers  are  encouragedto  carefully  go  through  all  information  (e.g.,  comments)  in  answer  threads.</p>|2019-04-01  22:52:19.485428
http://arxiv.org/abs/1903.12286|Toroidal  AutoEncoder.  (arXiv:1903.12286v1  [stat.ML])|<p>Enforcing  distributions  of  latent  variables  in  neural  networks  is  an  activesubject.  It  is  vital  in  all  kinds  of  generative  models,  where  we  want  to  beable  to  interpolate  between  points  in  the  latent  space,  or  sample  from  it.Modern  generative  AutoEncoders  (AE)  like  WAE,  SWAE,  CWAE  add  a  regularizer  tothe  standard  (deterministic)  AE,  which  allows  to  enforce  Gaussian  distributionin  the  latent  space.  Enforcing  different  distributions,  especiallytopologically  nontrivial,  might  bring  some  new  interesting  possibilities,  butthis  subject  seems  unexplored  so  far.</p><p>This  article  proposes  a  new  approach  to  enforce  uniform  distribution  ond-dimensional  torus.  We  introduce  a  circular  spring  loss,  which  enforcesminibatch  points  to  be  equally  spaced  and  satisfy  cyclic  boundary  conditions.</p><p>As  example  of  application  we  propose  multiple-path  morphing.  Minimal  distancegeodesic  between  two  points  in  uniform  distribution  on  latent  space  of  anglesbecomes  a  line,  however,  torus  topology  allows  us  to  choose  such  lines  inalternative  ways,  going  through  different  edges  of  $[-\pi,\pi]^d$.</p><p>Further  applications  to  explore  can  be  for  example  trying  to  learn  real-lifetopologically  nontrivial  spaces  of  features,  like  rotations  to  automaticallyrecognize  2D  rotation  of  an  object  in  picture  by  training  on  relative  angles,or  even  3D  rotations  by  additionally  using  spherical  features  -  this  waymorphing  should  be  close  to  object  rotation.</p>|2019-04-01  22:52:19.485516
http://arxiv.org/abs/1903.12287|PyTorch-BigGraph:  A  Large-scale  Graph  Embedding  System.  (arXiv:1903.12287v1  [cs.LG])|<p>Graph  embedding  methods  produce  unsupervised  node  features  from  graphs  thatcan  then  be  used  for  a  variety  of  machine  learning  tasks.  Modern  graphs,particularly  in  industrial  applications,  contain  billions  of  nodes  andtrillions  of  edges,  which  exceeds  the  capability  of  existing  embedding  systems.We  present  PyTorch-BigGraph  (PBG),  an  embedding  system  that  incorporatesseveral  modifications  to  traditional  multi-relation  embedding  systems  thatallow  it  to  scale  to  graphs  with  billions  of  nodes  and  trillions  of  edges.  PBGuses  graph  partitioning  to  train  arbitrarily  large  embeddings  on  either  asingle  machine  or  in  a  distributed  environment.  We  demonstrate  comparableperformance  with  existing  embedding  systems  on  common  benchmarks,  whileallowing  for  scaling  to  arbitrarily  large  graphs  and  parallelization  onmultiple  machines.  We  train  and  evaluate  embeddings  on  several  large  socialnetwork  graphs  as  well  as  the  full  Freebase  dataset,  which  contains  over  100million  nodes  and  2  billion  edges.</p>|2019-04-01  22:52:19.485579
http://arxiv.org/abs/1903.12289|Above  the  Nyquist  Rate,  Modulo  Folding  Does  Not  Hurt.  (arXiv:1903.12289v1  [cs.IT])|<p>We  consider  the  problem  of  recovering  a  continuous-time  bandlimited  signalfrom  the  discrete-time  signal  obtained  from  sampling  it  every  $T_s$  seconds  andreducing  the  result  modulo  $\Delta$,  for  some  $\Delta&gt;0$.  For  $\Delta=\infty$the  celebrated  Shannon-Nyquist  sampling  theorem  guarantees  that  perfectrecovery  is  possible  provided  that  the  sampling  rate  $1/T_s$  exceeds  theso-called  Nyquist  rate.  Recent  work  by  Bhandari  et  al.  has  shown  that  for  any$\Delta&gt;0$  perfect  reconstruction  is  still  possible  if  the  sampling  rateexceeds  the  Nyquist  rate  by  a  factor  of  $\pi  e$.  In  this  letter  we  improve  uponthis  result  and  show  that  for  finite  energy  signals,  perfect  recovery  ispossible  for  any  $\Delta&gt;0$  and  any  sampling  rate  above  the  Nyquist  rate.  Thus,modulo  folding  does  not  degrade  the  signal,  provided  that  the  sampling  rateexceeds  the  Nyquist  rate.  This  claim  is  proved  by  establishing  a  connectionbetween  the  recovery  problem  of  a  discrete-time  signal  from  its  modulo  reducedversion  and  the  problem  of  predicting  the  next  sample  of  a  discrete-time  signalfrom  its  past,  and  leveraging  the  fact  that  for  a  bandlimited  signal  theprediction  error  can  be  made  arbitrarily  small.</p>|2019-04-01  22:52:19.485643
http://arxiv.org/abs/1903.12290|Revisiting  Local  Descriptor  based  Image-to-Class  Measure  for  Few-shot  Learning.  (arXiv:1903.12290v1  [cs.CV])|<p>Few-shot  learning  in  image  classification  aims  to  learn  a  classifier  toclassify  images  when  only  few  training  examples  are  available  for  each  class.Recent  work  has  achieved  promising  classification  performance,  where  animage-level  feature  based  measure  is  usually  used.  In  this  paper,  we  argue  thata  measure  at  such  a  level  may  not  be  effective  enough  in  light  of  the  scarcityof  examples  in  few-shot  learning.  Instead,  we  think  a  local  descriptor  basedimage-to-class  measure  should  be  taken,  inspired  by  its  surprising  success  inthe  heydays  of  local  invariant  features.  Specifically,  building  upon  the  recentepisodic  training  mechanism,  we  propose  a  Deep  Nearest  Neighbor  Neural  Network(DN4  in  short)  and  train  it  in  an  end-to-end  manner.  Its  key  difference  fromthe  literature  is  the  replacement  of  the  image-level  feature  based  measure  inthe  final  layer  by  a  local  descriptor  based  image-to-class  measure.  Thismeasure  is  conducted  online  via  a  $k$-nearest  neighbor  search  over  the  deeplocal  descriptors  of  convolutional  feature  maps.  The  proposed  DN4  not  onlylearns  the  optimal  deep  local  descriptors  for  the  image-to-class  measure,  butalso  utilizes  the  higher  efficiency  of  such  a  measure  in  the  case  of  examplescarcity,  thanks  to  the  exchangeability  of  visual  patterns  across  the  images  inthe  same  class.  Our  work  leads  to  a  simple,  effective,  and  computationallyefficient  framework  for  few-shot  learning.  Experimental  study  on  benchmarkdatasets  consistently  shows  its  superiority  over  the  related  state-of-the-art,with  the  largest  absolute  improvement  of  $17\%$  over  the  next  best.  The  sourcecode  can  be  available  from  \UrlFont{https://github.com/WenbinLee/DN4.git}.</p>|2019-04-01  22:52:19.485680
http://arxiv.org/abs/1903.12294|Multifaceted  4D  Feature  Segmentation  and  Extraction  in  Point  and  Field-based  Datasets.  (arXiv:1903.12294v1  [cs.CV])|<p>The  use  of  large-scale  multifaceted  data  is  common  in  a  wide  variety  ofscientific  applications.  In  many  cases,  this  multifaceted  data  takes  the  formof  a  field-based  (Eulerian)  and  point/trajectory-based  (Lagrangian)representation  as  each  has  a  unique  set  of  advantages  in  characterizing  asystem  of  study.  Furthermore,  studying  the  increasing  scale  and  complexity  ofthese  multifaceted  datasets  is  limited  by  perceptual  ability  and  availablecomputational  resources,  necessitating  sophisticated  data  reduction  and  featureextraction  techniques.  In  this  work,  we  present  a  new  4D  featuresegmentation/extraction  scheme  that  can  operate  on  both  the  field  andpoint/trajectory  data  types  simultaneously.  The  resulting  features  aretime-varying  data  subsets  that  have  both  a  field  and  point-based  component,  andwere  extracted  based  on  underlying  patterns  from  both  data  types.  This  enablesresearchers  to  better  explore  both  the  spatial  and  temporal  interplay  betweenthe  two  data  representations  and  study  underlying  phenomena  from  newperspectives.  We  parallelize  our  approach  using  GPU  acceleration  and  apply  itto  real  world  multifaceted  datasets  to  illustrate  the  types  of  features  thatcan  be  extracted  and  explored.</p>|2019-04-01  22:52:19.485713
http://arxiv.org/abs/1903.12296|Attention-Guided  Generative  Adversarial  Networks  for  Unsupervised  Image-to-Image  Translation.  (arXiv:1903.12296v1  [cs.CV])|<p>The  state-of-the-art  approaches  in  Generative  Adversarial  Networks  (GANs)  areable  to  learn  a  mapping  function  from  one  image  domain  to  another  with  unpairedimage  data.  However,  these  methods  often  produce  artifacts  and  can  only  be  ableto  convert  low-level  information,  but  fail  to  transfer  high-level  semantic  partof  images.  The  reason  is  mainly  that  generators  do  not  have  the  ability  todetect  the  most  discriminative  semantic  part  of  images,  which  thus  makes  thegenerated  images  with  low-quality.  To  handle  the  limitation,  in  this  paper  wepropose  a  novel  Attention-Guided  Generative  Adversarial  Network  (AGGAN),  whichcan  detect  the  most  discriminative  semantic  object  and  minimize  changes  ofunwanted  part  for  semantic  manipulation  problems  without  using  extra  data  andmodels.  The  attention-guided  generators  in  AGGAN  are  able  to  produce  attentionmasks  via  a  built-in  attention  mechanism,  and  then  fuse  the  input  image  withthe  attention  mask  to  obtain  a  target  image  with  high-quality.  Moreover,  wepropose  a  novel  attention-guided  discriminator  which  only  considers  attendedregions.  The  proposed  AGGAN  is  trained  by  an  end-to-end  fashion  with  anadversarial  loss,  cycle-consistency  loss,  pixel  loss  and  attention  loss.  Bothqualitative  and  quantitative  results  demonstrate  that  our  approach  is  effectiveto  generate  sharper  and  more  accurate  images  than  existing  models.</p>|2019-04-01  22:52:19.485745
http://arxiv.org/abs/1903.12297|An  analysis  of  the  cost  of  hyper-parameter  selection  via  split-sample  validation,  with  applications  to  penalized  regression.  (arXiv:1903.12297v1  [stat.ML])|<p>In  the  regression  setting,  given  a  set  of  hyper-parameters,  amodel-estimation  procedure  constructs  a  model  from  training  data.  The  optimalhyper-parameters  that  minimize  generalization  error  of  the  model  are  usuallyunknown.  In  practice  they  are  often  estimated  using  split-sample  validation.  Upto  now,  there  is  an  open  question  regarding  how  the  generalization  error  of  theselected  model  grows  with  the  number  of  hyper-parameters  to  be  estimated.  Toanswer  this  question,  we  establish  finite-sample  oracle  inequalities  forselection  based  on  a  single  training/test  split  and  based  on  cross-validation.We  show  that  if  the  model-estimation  procedures  are  smoothly  parameterized  bythe  hyper-parameters,  the  error  incurred  from  tuning  hyper-parameters  shrinksat  nearly  a  parametric  rate.  Hence  for  semi-  and  non-parametricmodel-estimation  procedures  with  a  fixed  number  of  hyper-parameters,  thisadditional  error  is  negligible.  For  parametric  model-estimation  procedures,adding  a  hyper-parameter  is  roughly  equivalent  to  adding  a  parameter  to  themodel  itself.  In  addition,  we  specialize  these  ideas  for  penalized  regressionproblems  with  multiple  penalty  parameters.  We  establish  that  the  fitted  modelsare  Lipschitz  in  the  penalty  parameters  and  thus  our  oracle  inequalities  apply.This  result  encourages  development  of  regularization  methods  with  many  penaltyparameters.</p>|2019-04-01  22:52:19.485776
http://arxiv.org/abs/1903.12301|Dronecrypt  -  An  Efficient  Cryptographic  Framework  for  Small  Aerial  Drones.  (arXiv:1903.12301v1  [cs.CR])|<p>Aerial  drones  are  becoming  an  integral  part  of  application  domains  includingbut  not  limited  to,  military  operations,  package  delivery,  construction,monitoring  and  search/rescue  operations.  It  is  critical  to  ensure  the  cybersecurity  of  networked  aerial  drone  systems  in  these  applications.  Standardcryptographic  services  can  be  deployed  to  provide  basic  security  services;however,  they  have  been  shown  to  be  inefficient  in  terms  of  energy  and  timeconsumption,  especially  for  small  aerial  drones  with  resource-limitedprocessors.  Therefore,  there  is  a  significant  need  for  an  efficientcryptographic  framework  that  can  meet  the  requirements  of  small  aerial  drones.</p><p>We  propose  an  improved  cryptographic  framework  for  small  aerial  drones,  whichoffers  significant  energy  efficiency  and  speed  advantages  over  standardcryptographic  techniques.  (i)  We  create  (to  the  best  of  our  knowledge)  thefirst  optimized  public  key  infrastructure  (PKI)  based  framework  for  smallaerial  drones,  which  provides  energy  efficient  techniques  by  harnessing  specialprecomputation  methods  and  optimized  elliptic  curves.  (ii)  We  also  integraterecent  light-weight  symmetric  primitives  into  our  PKI  techniques  to  provide  afull-fledged  cryptographic  framework.  (iii)  We  implemented  standardcounterparts  and  our  proposed  techniques  on  an  actual  small  aerial  drone(Crazyflie  2.0),  and  provided  an  in-depth  energy  analysis.  Our  experimentsshowed  that  our  improved  cryptographic  framework  achieves  up  to  35x  lowerenergy  consumption  than  its  standard  counterpart.</p>|2019-04-01  22:52:19.485807
http://arxiv.org/abs/1903.12302|Amortized  Object  and  Scene  Perception  for  Long-term  Robot  Manipulation.  (arXiv:1903.12302v1  [cs.RO])|<p>Mobile  robots,  performing  long-term  manipulation  activities  in  humanenvironments,  have  to  perceive  a  wide  variety  of  objects  possessing  verydifferent  visual  characteristics  and  need  to  reliably  keep  track  of  thesethroughout  the  execution  of  a  task.  In  order  to  be  efficient,  robot  perceptioncapabilities  need  to  go  beyond  what  is  currently  perceivable  and  should  be  ableto  answer  queries  about  both  current  and  past  scenes.  In  this  paper  weinvestigate  a  perception  system  for  long-term  robot  manipulation  that  keepstrack  of  the  changing  environment  and  builds  a  representation  of  the  perceivedworld.  Specifically  we  introduce  an  amortized  component  that  spreads  perceptiontasks  throughout  the  execution  cycle.  The  resulting  query  driven  perceptionsystem  asynchronously  integrates  results  from  logged  images  into  a  symbolic  andnumeric  (what  we  call  sub-symbolic)  representation  that  forms  the  perceptualbelief  state  of  the  robot.</p>|2019-04-01  22:52:19.485838
http://arxiv.org/abs/1903.12303|Nonlinear  Moment  Matching  for  the  Simulation-Free  Reduction  of  Structural  Systems.  (arXiv:1903.12303v1  [cs.CE])|<p>This  paper  transfers  the  concept  of  moment  matching  to  nonlinear  structuralsystems  and  further  provides  a  simulation-free  reduction  scheme  for  suchnonlinear  second-order  models.  After  first  presenting  the  steady-stateinterpretation  of  linear  moment  matching,  we  then  extend  this  reduction  conceptto  the  nonlinear  second-order  case  based  on  Astolfi  [2010].  Then,  similarsimplifications  as  in  Cruz  Varona  et  al.  [2019]  are  proposed  to  achieve  asimulation-free  nonlinear  moment  matching  algorithm.  A  discussion  on  thesimplifications  and  their  limitations  is  presented,  as  well  as  a  numericalexample  which  illustrates  the  efficiency  of  the  algorithm.</p>|2019-04-01  22:52:19.485869
http://arxiv.org/abs/1903.12305|FrameNet:  Learning  Local  Canonical  Frames  of  3D  Surfaces  from  a  Single  RGB  Image.  (arXiv:1903.12305v1  [cs.CV])|<p>In  this  work,  we  introduce  the  novel  problem  of  identifying  dense  canonical3D  coordinate  frames  from  a  single  RGB  image.  We  observe  that  each  pixel  in  animage  corresponds  to  a  surface  in  the  underlying  3D  geometry,  where  a  canonicalframe  can  be  identified  as  represented  by  three  orthogonal  axes,  one  along  itsnormal  direction  and  two  in  its  tangent  plane.  We  propose  an  algorithm  topredict  these  axes  from  RGB.  Our  first  insight  is  that  canonical  framescomputed  automatically  with  recently  introduced  direction  field  synthesismethods  can  provide  training  data  for  the  task.  Our  second  insight  is  thatnetworks  designed  for  surface  normal  prediction  provide  better  results  whentrained  jointly  to  predict  canonical  frames,  and  even  better  when  trained  toalso  predict  2D  projections  of  canonical  frames.  We  conjecture  this  is  becauseprojections  of  canonical  tangent  directions  often  align  with  local  gradients  inimages,  and  because  those  directions  are  tightly  linked  to  3D  canonical  framesthrough  projective  geometry  and  orthogonality  constraints.  In  our  experiments,we  find  that  our  method  predicts  3D  canonical  frames  that  can  be  used  inapplications  ranging  from  surface  normal  estimation,  feature  matching,  andaugmented  reality.</p>|2019-04-01  22:52:19.485900
http://arxiv.org/abs/1903.12306|Acoustically  Grounded  Word  Embeddings  for  Improved  Acoustics-to-Word  Speech  Recognition.  (arXiv:1903.12306v1  [cs.CL])|<p>Direct  acoustics-to-word  (A2W)  systems  for  end-to-end  automatic  speechrecognition  are  simpler  to  train,  and  more  efficient  to  decode  with,  thansub-word  systems.  However,  A2W  systems  can  have  difficulties  at  training  timewhen  data  is  limited,  and  at  decoding  time  when  recognizing  words  outside  thetraining  vocabulary.  To  address  these  shortcomings,  we  investigate  the  use  ofrecently  proposed  acoustic  and  acoustically  grounded  word  embedding  techniquesin  A2W  systems.  The  idea  is  based  on  treating  the  final  pre-softmax  weightmatrix  of  an  AWE  recognizer  as  a  matrix  of  word  embedding  vectors,  and  using  anexternally  trained  set  of  word  embeddings  to  improve  the  quality  of  thismatrix.  In  particular  we  introduce  two  ideas:  (1)  Enforcing  similarity  attraining  time  between  the  external  embeddings  and  the  recognizer  weights,  and(2)  using  the  word  embeddings  at  test  time  for  predicting  out-of-vocabularywords.  Our  word  embedding  model  is  acoustically  grounded,  that  is  it  is  learnedjointly  with  acoustic  embeddings  so  as  to  encode  the  words'  acoustic-phoneticcontent;  and  it  is  parametric,  so  that  it  can  embed  any  arbitrary  (potentiallyout-of-vocabulary)  sequence  of  characters.  We  find  that  both  techniques  improvethe  performance  of  an  A2W  recognizer  on  conversational  telephone  speech.</p>|2019-04-01  22:52:19.485931
http://arxiv.org/abs/1903.12307|Expanding  across  time  to  deliver  bandwidth  efficiency  and  low  latency.  (arXiv:1903.12307v1  [cs.NI])|<p>Datacenters  need  networks  that  support  both  low-latency  and  high-bandwidthpacket  delivery  to  meet  the  stringent  requirements  of  modern  applications.  Wepresent  Opera,  a  dynamic  network  that  delivers  latency-sensitive  trafficquickly  by  relying  on  multi-hop  forwarding  in  the  same  way  asexpander-graph-based  approaches,  but  provides  near-optimal  bandwidth  for  bulkflows  through  direct  forwarding  over  time-varying  source-to-destinationcircuits.  The  key  to  Opera's  design  is  the  rapid  and  deterministicreconfiguration  of  the  network,  piece-by-piece,  such  that  at  any  moment  in  timethe  network  implements  an  expander  graph,  yet,  integrated  across  time,  thenetwork  provides  bandwidth-efficient  single-hop  paths  between  all  racks.  Weshow  that  Opera  supports  low-latency  traffic  with  flow  completion  timescomparable  to  cost-equivalent  static  topologies,  while  delivering  up  to  4x  thebandwidth  for  all-to-all  traffic  and  supporting  60%  higher  load  for  publisheddatacenter  workloads.</p>|2019-04-01  22:52:19.485962
http://arxiv.org/abs/1903.12311|Mesh-based  Tools  to  Analyze  Deep  Reinforcement  Learning  Policies  for  Underactuated  Biped  Locomotion.  (arXiv:1903.12311v1  [cs.RO])|<p>In  this  paper,  we  present  a  mesh-based  approach  to  analyze  stability  androbustness  of  the  policies  obtained  via  deep  reinforcement  learning  for  variousbiped  gaits  of  a  five-link  planar  model.  Intuitively,  one  would  expect  thatincluding  perturbations  and/or  other  types  of  noise  during  training  wouldlikely  result  in  more  robustness  of  the  resulting  control  policy.  However,  onewould  like  to  have  a  quantitative  and  computationally-efficient  means  ofevaluating  the  degree  to  which  this  might  be  so.  Rather  than  relying  on  MonteCarlo  simulations,  our  goal  is  to  provide  more  sophisticated  tools  to  assessrobustness  properties  of  such  policies.  Our  work  is  motivated  by  the  twinhypotheses  that  contraction  of  dynamics,  when  achievable,  can  simplify  controland  that  control  policies  obtained  via  deep  learning  may  therefore  exhibittendency  to  contract  to  lower-dimensional  manifolds  within  the  full  statespace,  as  a  result.  The  tractability  of  our  mesh-based  tools  in  this  workprovides  some  evidence  that  this  may  be  so.</p>|2019-04-01  22:52:19.485993
http://arxiv.org/abs/1903.12312|Data  structures  to  represent  sets  of  k-long  DNA  sequences.  (arXiv:1903.12312v1  [cs.DS])|<p>The  analysis  of  biological  sequencing  data  has  been  one  of  the  biggestapplications  of  string  algorithms.  The  approaches  used  in  many  suchapplications  are  based  on  the  analysis  of  k-mers,  which  are  short  fixed-lengthstrings  present  in  a  dataset.  While  these  approaches  are  rather  diverse,storing  and  querying  k-mer  sets  has  emerged  as  a  shared  underlying  component.Sets  of  k-mers  have  unique  features  and  applications  that,  over  the  last  tenyears,  have  resulted  in  many  specialized  approaches  for  their  representation.In  this  survey,  we  give  a  unified  presentation  and  comparison  of  the  datastructures  that  have  been  proposed  to  store  and  query  k-mer  sets.  We  hope  thissurvey  will  not  only  serve  as  a  resource  for  researchers  in  the  field  but  alsomake  the  area  more  accessible  to  outsiders</p>|2019-04-01  22:52:19.486123
http://arxiv.org/abs/1903.12314|Relation-aware  Graph  Attention  Network  for  Visual  Question  Answering.  (arXiv:1903.12314v1  [cs.CV])|<p>In  order  to  answer  semantically-complicated  questions  about  an  image,  aVisual  Question  Answering  (VQA)  model  needs  to  fully  understand  the  visualscene  in  the  image,  especially  the  interactive  dynamics  between  differentobjects.  We  propose  a  Relation-aware  Graph  Attention  Network  (ReGAT),  whichencodes  each  image  into  a  graph  and  models  multi-type  inter-object  relationsvia  a  graph  attention  mechanism,  to  learn  question-adaptive  relationrepresentations.  Two  types  of  visual  object  relations  are  explored:  (i)Explicit  Relations  that  represent  geometric  positions  and  semantic  interactionsbetween  objects;  and  (ii)  Implicit  Relations  that  capture  the  hidden  dynamicsbetween  image  regions.  Experiments  demonstrate  that  ReGAT  outperforms  priorstate-of-the-art  approaches  on  both  VQA  2.0  and  VQA-CP  v2  datasets.  We  furthershow  that  ReGAT  is  compatible  to  existing  VQA  architectures,  and  can  be  used  asa  generic  relation  encoder  to  boost  the  model  performance  for  VQA.</p>|2019-04-01  22:52:19.486166
http://arxiv.org/abs/1903.12316|Does  the  Lombard  Effect  Improve  Emotional  Communication  in  Noise?  -  Analysis  of  Emotional  Speech  Acted  in  Noise  -.  (arXiv:1903.12316v1  [eess.AS])|<p>Speakers  usually  adjust  their  way  of  talking  in  noisy  environmentsinvoluntarily  for  effective  communication.  This  adaptation  is  known  as  theLombard  effect.  Although  speech  accompanying  the  Lombard  effect  can  improve  theintelligibility  of  a  speaker's  voice,  the  changes  in  acoustic  features  (e.g.fundamental  frequency,  speech  intensity,  and  spectral  tilt)  caused  by  theLombard  effect  may  also  affect  the  listener's  judgment  of  emotional  content.  Tothe  best  of  our  knowledge,  there  is  no  published  study  on  the  influence  of  theLombard  effect  in  emotional  speech.  Therefore,  we  recorded  parallel  emotionalspeech  waveforms  uttered  by  12  speakers  under  both  quiet  and  noisy  conditionsin  a  professional  recording  studio  in  order  to  explore  how  the  Lombard  effectinteracts  with  emotional  speech.  By  analyzing  confusion  matrices  and  acousticfeatures,  we  aim  to  answer  the  following  questions:  1)  Can  speakers  expresstheir  emotions  correctly  even  under  adverse  conditions?  2)  Can  listenersrecognize  the  emotion  contained  in  speech  signals  even  under  noise?  3)  How  doesemotional  speech  uttered  in  noise  differ  from  emotional  speech  uttered  in  quietconditions  in  terms  of  acoustic  characteristic?</p>|2019-04-01  22:52:19.486236
http://arxiv.org/abs/1903.12318|User  Preference  Aware  Lossless  Data  Compression  at  the  Edge.  (arXiv:1903.12318v1  [cs.IT])|<p>Data  compression  is  an  efficient  technique  to  save  data  storage  andtransmission  costs.  However,  traditional  data  compression  methods  always  ignorethe  impact  of  user  preferences  on  the  statistical  distributions  of  symbolstransmitted  over  the  links.  Notice  that  the  development  of  big  datatechnologies  and  popularization  of  smart  devices  enable  analyses  on  userpreferences  based  on  data  collected  from  personal  handsets.  This  paper  presentsa  user  preference  aware  lossless  data  compression  method,  termed  edge  sourcecoding,  to  compress  data  at  the  network  edge.  An  optimization  problem  isformulated  to  minimize  the  expected  number  of  bits  needed  to  represent  arequested  content  item  in  edge  source  coding.  For  edge  source  coding  underdiscrete  user  preferences,  DCA  (difference  of  convex  functions  programmingalgorithm)  based  and  k-means++  based  algorithms  are  proposed  to  give  codebookdesigns.  For  edge  source  coding  under  continuous  user  preferences,  a  samplingmethod  is  applied  to  give  codebook  designs.  In  addition,  edge  source  coding  isextended  to  the  two-user  case  and  codebooks  are  elaborately  designed  to  utilizemulticasting  opportunities.  Both  theoretical  analysis  and  simulationsdemonstrate  the  optimal  codebook  design  should  take  into  account  userpreferences.</p>|2019-04-01  22:52:19.486270
http://arxiv.org/abs/1903.12322|Implicit  Langevin  Algorithms  for  Sampling  From  Log-concave  Densities.  (arXiv:1903.12322v1  [stat.ML])|<p>For  sampling  from  a  log-concave  density,  we  study  implicit  integratorsresulting  from  $\theta$-method  discretization  of  the  overdamped  Langevindiffusion  stochastic  differential  equation.  Theoretical  and  algorithmicproperties  of  the  resulting  sampling  methods  for  $  \theta  \in  [0,1]  $  and  arange  of  step  sizes  are  established.  Our  results  generalize  and  extend  priorworks  in  several  directions.  In  particular,  for  $\theta\ge1/2$,  we  provegeometric  ergodicity  and  stability  of  the  resulting  methods  for  all  step  sizes.We  show  that  obtaining  subsequent  samples  amounts  to  solving  a  strongly-convexoptimization  problem,  which  is  readily  achievable  using  one  of  numerousexisting  methods.  Numerical  examples  supporting  our  theoretical  analysis  arealso  presented.</p>|2019-04-01  22:52:19.486302
http://arxiv.org/abs/1903.12325|Entropy  flow  and  De  Bruijn's  identity  for  a  class  of  stochastic  differential  equations  driven  by  fractional  Brownian  motion.  (arXiv:1903.12325v1  [math.PR])|<p>Motivated  by  the  classical  De  Bruijn's  identity  for  the  additive  Gaussiannoise  channel,  in  this  paper  we  consider  a  generalized  setting  where  thechannel  is  modelled  via  stochastic  differential  equations  driven  by  fractionalBrownian  motion  with  Hurst  parameter  $H\in(1/4,1)$.  We  derive  generalized  DeBruijn's  identity  for  Shannon  entropy  and  Kullback-Leibler  divergence  by  meansof  It\^o's  formula,  and  present  two  applications  where  we  relax  the  assumptionto  $H  \in  (0,1)$.  In  the  first  application  we  demonstrate  its  equivalence  withStein's  identity  for  Gaussian  distributions,  while  in  the  second  application,we  show  that  for  $H  \in  (0,1/2]$,  the  entropy  power  is  concave  in  time  whilefor  $H  \in  (1/2,1)$  it  is  convex  in  time  when  the  initial  distribution  isGaussian.  Compared  with  the  classical  case  of  $H  =  1/2$,  the  time  parameterplays  an  interesting  and  significant  role  in  the  analysis  of  these  quantities.</p>|2019-04-01  22:52:19.486333
http://arxiv.org/abs/1903.12328|Improved  Reinforcement  Learning  with  Curriculum.  (arXiv:1903.12328v1  [cs.LG])|<p>Humans  tend  to  learn  complex  abstract  concepts  faster  if  examples  arepresented  in  a  structured  manner.  For  instance,  when  learning  how  to  play  aboard  game,  usually  one  of  the  first  concepts  learned  is  how  the  game  ends,i.e.  the  actions  that  lead  to  a  terminal  state  (win,  lose  or  draw).  Theadvantage  of  learning  end-games  first  is  that  once  the  actions  which  lead  to  aterminal  state  are  understood,  it  becomes  possible  to  incrementally  learn  theconsequences  of  actions  that  are  further  away  from  a  terminal  state  -  we  callthis  an  end-game-first  curriculum.  Currently  the  state-of-the-art  machinelearning  player  for  general  board  games,  AlphaZero  by  Google  DeepMind,  does  notemploy  a  structured  training  curriculum;  instead  learning  from  the  entire  gameat  all  times.  By  employing  an  end-game-first  training  curriculum  to  train  anAlphaZero  inspired  player,  we  empirically  show  that  the  rate  of  learning  of  anartificial  player  can  be  improved  during  the  early  stages  of  training  whencompared  to  a  player  not  using  a  training  curriculum.</p>|2019-04-01  22:52:19.486366
http://arxiv.org/abs/1903.12329|Averager-copier-voter  models  for  hybrid  opinion  dynamics  in  complex  networks.  (arXiv:1903.12329v1  [cs.SY])|<p>A  hybrid  model  for  opinion  dynamics  in  complex  multi-agent  networks  isintroduced,  wherein  some  continuous-valued  agents  average  neighbors'  opinionsto  update  their  own,  while  other  discrete-valued  agents  use  stochastic  copyingand  voting  protocols.  A  statistical  and  graph-theoretic  analysis  of  the  modelis  undertaken,  and  consensus  is  shown  to  be  achieved  whenever  the  networkmatrix  is  ergodic.  Also,  the  time  required  for  consensus  is  characterized,  interms  of  the  network's  graph  and  the  distribution  of  agents  of  different  types.</p>|2019-04-01  22:52:19.486415
http://arxiv.org/abs/1903.12330|Neuromorphic  In-Memory  Computing  Framework  using  Memtransistor  Cross-bar  based  Support  Vector  Machines.  (arXiv:1903.12330v1  [cs.NE])|<p>This  paper  presents  a  novel  framework  for  designing  support  vector  machines(SVMs),  which  does  not  impose  restriction  on  the  SVM  kernel  to  bepositive-definite  and  allows  the  user  to  define  memory  constraint  in  terms  offixed  template  vectors.  This  makes  the  framework  scalable  and  enables  itsimplementation  for  low-power,  high-density  and  memory  constrained  embeddedapplication.  An  efficient  hardware  implementation  of  the  same  is  alsodiscussed,  which  utilizes  novel  low  power  memtransistor  based  cross-bararchitecture,  and  is  robust  to  device  mismatch  and  randomness.  We  usedmemtransistor  measurement  data,  and  showed  that  the  designed  SVMs  can  achievestate-of-the-art  classification  accuracy  on  both  synthetic  and  real-worldbenchmark  datasets.  This  framework  would  be  beneficial  for  design  of  SVM  basedwake-up  systems  for  internet  of  things  (IoTs)  and  edge  devices  wherememtransistors  can  be  used  to  optimize  system's  energy-efficiency  and  performin-memory  matrix-vector  multiplication  (MVM).</p>|2019-04-01  22:52:19.486480
http://arxiv.org/abs/1903.12331|A  Deep  Dive  into  Understanding  Tumor  Foci  Classification  using  Multiparametric  MRI  Based  on  Convolutional  Neural  Network.  (arXiv:1903.12331v1  [cs.CV])|<p>Data  scarcity  has  refrained  deep  learning  models  from  making  greater  progressin  prostate  images  analysis  using  multiparametric  MRI.  In  this  paper,  anefficient  convolutional  neural  network  (CNN)  was  developed  to  classify  lesionmalignancy  for  prostate  cancer  patients,  based  on  which  model  interpretationwas  systematically  analyzed  to  bridge  the  gap  between  natural  images  and  MRimages,  which  is  the  first  one  of  its  kind  in  the  literature.  The  problem  ofsmall  sample  size  was  addressed  and  successfully  tackled  by  feeding  theintermediate  features  into  a  traditional  classification  algorithm  known  asweighted  extreme  learning  machine,  with  imbalanced  distribution  among  outputcategories  taken  into  consideration.  Model  trained  on  public  data  set  was  ableto  generalize  to  data  from  an  independent  institution  to  make  accurateprediction.  The  generated  saliency  map  was  found  to  overlay  well  with  thelesion  and  could  benefit  clinicians  for  diagnosing  purpose.</p>|2019-04-01  22:52:19.486534
http://arxiv.org/abs/1903.12337|ESFNet:  Efficient  Network  for  Building  Extraction  from  High-Resolution  Aerial  Images.  (arXiv:1903.12337v1  [cs.CV])|<p>Building  footprint  extraction  from  high-resolution  aerial  images  is  always  anessential  part  of  urban  dynamic  monitoring,  planning  and  management.  It  hasalso  been  a  challenging  task  in  remote  sensing  research,  due  to  complexenvironments  and  land  cover  objects  in  the  high-resolution  aerial  images.  Inrecent  years,  deep  neural  networks  have  made  great  achievement  in  improvingaccuracy  of  building  extraction  from  remote  sensing  imagery.  However,  most  ofexisting  approaches  usually  requiring  a  large  number  of  parameters  and  floatingpoint  operations  for  high  accuracy,  it  leads  to  high  memory  consumption  and  lowinference  speed  which  are  harmful  to  research.  In  this  paper,  we  proposed  anovel  deep  architecture  named  ESFNet  which  employs  separable  factorizedresidual  block  and  utilizes  the  dilated  convolutions,  aiming  to  preserve  slightaccuracy  loss  with  low  computational  cost  and  memory  consumption.  This  is  thefirst  time  introducing  efficiency  view  of  deep  neural  networks  in  remotesensing  area.  Our  ESFNet  is  able  to  run  at  over  100  FPS  on  single  Tesla  V100,requires  6x  less  FLOPs  and  has  18x  less  parameters  than  state-of-the-artreal-time  architecture  ERFNet  while  preserving  similar  accuracy  without  anyadditional  context  module,  post-processing  and  pre-trained  scheme.  We  evaluatedour  networks  on  WHU  Building  Dataset  and  compared  it  with  otherstate-of-the-art  architectures.  The  result  and  comprehensive  analysis  show  thatour  networks  are  benefit  to  efficient  remote  sensing  researches  andapplications,  and  can  further  extended  to  other  areas.  The  code  is  publicavailable  at:  https://github.com/mrluin/ESFNet-Pytorch</p>|2019-04-01  22:52:19.486568
http://arxiv.org/abs/1903.12340|A  Machine  Learning  Framework  for  Biometric  Authentication  using  Electrocardiogram.  (arXiv:1903.12340v1  [cs.CR])|<p>This  paper  introduces  a  framework  for  how  to  appropriately  adopt  and  adjustMachine  Learning  (ML)  techniques  used  to  construct  Electrocardiogram  (ECG)based  biometric  authentication  schemes.  The  proposed  framework  can  helpinvestigators  and  developers  on  ECG  based  biometric  authentication  mechanismsdefine  the  boundaries  of  required  datasets  and  get  training  data  with  goodquality.  To  determine  the  boundaries  of  datasets,  use  case  analysis  is  adopted.Based  on  various  application  scenarios  on  ECG  based  authentication,  threedistinct  use  cases  (or  authentication  categories)  are  developed.  With  morequalified  training  data  given  to  corresponding  machine  learning  schemes,  theprecision  on  ML-based  ECG  biometric  authentication  mechanisms  is  increased  inconsequence.  ECG  time  slicing  technique  with  the  R-peak  anchoring  is  utilizedin  this  framework  to  acquire  ML  training  data  with  good  quality.  In  theproposed  framework  four  new  measure  metrics  are  introduced  to  evaluate  thequality  of  ML  training  and  testing  data.  In  addition,  a  Matlab  toolbox,containing  all  proposed  mechanisms,  metrics  and  sample  data  with  demonstrationsusing  various  ML  techniques,  is  developed  and  publicly  available  for  furtherinvestigation.  For  developing  ML-based  ECG  biometric  authentication,  theproposed  framework  can  guide  researchers  to  prepare  the  proper  ML  setups  andthe  ML  training  datasets  along  with  three  identified  user  case  scenarios.  Forresearchers  adopting  ML  techniques  to  design  new  schemes  in  other  researchdomains,  the  proposed  framework  is  still  useful  for  generating  ML-basedtraining  and  testing  datasets  with  good  quality  and  utilizing  new  measuremetrics.</p>|2019-04-01  22:52:19.486600
http://arxiv.org/abs/1903.12344|Learning  Good  Representation  via  Continuous  Attention.  (arXiv:1903.12344v1  [cs.LG])|<p>In  this  paper  we  present  our  scientific  discovery  that  good  representationcan  be  learned  via  continuous  attention  during  the  interaction  betweenUnsupervised  Learning(UL)  and  Reinforcement  Learning(RL)  modules  driven  byintrinsic  motivation.  Specifically,  we  designed  intrinsic  rewards  generatedfrom  UL  modules  for  driving  the  RL  agent  to  focus  on  objects  for  a  period  oftime  and  to  learn  good  representations  of  objects  for  later  object  recognitiontask.  We  evaluate  our  proposed  algorithm  in  both  with  and  without  extrinsicreward  settings.  Experiments  with  end-to-end  training  in  simulated  environmentswith  applications  to  few-shot  object  recognition  demonstrated  the  effectivenessof  the  proposed  algorithm.</p>|2019-04-01  22:52:19.486674
http://arxiv.org/abs/1903.12347|The  Challenge  of  Predicting  Meal-to-meal  Blood  Glucose  Concentrations  for  Patients  with  Type  I  Diabetes.  (arXiv:1903.12347v1  [cs.LG])|<p>Patients  with  Type  I  Diabetes  (T1D)  must  take  insulin  injections  to  preventthe  serious  long  term  effects  of  hyperglycemia  -  high  blood  glucose  (BG).Patients  must  also  be  careful  not  to  inject  too  much  insulin  because  this  couldinduce  hypoglycemia  (low  BG),  which  can  potentially  be  fatal.  Patientstherefore  follow  a  "regimen"  that  determines  how  much  insulin  to  inject  atcertain  times.  Current  methods  for  managing  this  disease  require  adjusting  thepatient's  regimen  over  time  based  on  the  disease's  behavior  (recorded  in  thepatient's  diabetes  diary).  If  we  can  accurately  predict  a  patient's  future  BGvalues  from  his/her  current  features  (e.g.,  predicting  today's  lunch  BG  valuegiven  today's  diabetes  diary  entry  for  breakfast,  including  insulin  injections,and  perhaps  earlier  entries),  then  it  is  relatively  easy  to  produce  aneffective  regimen.  This  study  explores  the  challenges  of  BG  modeling  byapplying  several  machine  learning  algorithms  and  various  data  preprocessingvariations  (corresponding  to  312  [learner,  preprocessed-dataset]  combinations),to  a  new  T1D  dataset  containing  29  601  entries  from  47  different  patients.  Ourmost  accurate  predictor  is  a  weighted  ensemble  of  two  Gaussian  ProcessRegression  models,  which  achieved  an  errL1  loss  of  2.70  mmol/L  (48.65  mg/dl).This  was  an  unexpectedly  poor  result  given  that  one  can  obtain  an  errL1  of  2.91mmol/L  (52.43  mg/dl)  using  the  naive  approach  of  simply  predicting  thepatient's  average  BG.  For  each  of  data-variant/model  combination  we  reportseveral  evaluation  metrics,  including  glucose-specific  metrics,  and  findsimilarly  disappointing  results  (the  best  model  was  only  incrementally  betterthan  the  simplest  measure).  These  results  suggest  that  the  diabetes  diary  datathat  is  typically  collected  may  not  be  sufficient  to  produce  accurate  BGprediction  models;  additional  data  may  be  necessary  to  build  accurate  BGprediction  models.</p>|2019-04-01  22:52:19.486741
http://arxiv.org/abs/1903.12348|Reinforcement  Learning  for  Traffic  Control  with  Adaptive  Horizon.  (arXiv:1903.12348v1  [cs.SY])|<p>This  paper  proposes  a  reinforcement  learning  approach  for  traffic  controlwith  the  adaptive  horizon.  To  build  the  controller  for  the  traffic  network,  aQ-learning-based  strategy  that  controls  the  green  light  passing  time  at  thenetwork  intersections  is  applied.  The  controller  includes  two  components:  theregular  Q-learning  controller  that  controls  the  traffic  light  signal,  and  theadaptive  controller  that  continuously  optimizes  the  action  space  for  theQ-learning  algorithm  in  order  to  improve  the  efficiency  of  the  Q-learningalgorithm.  The  regular  Q-learning  controller  uses  the  control  cost  function  asa  reward  function  to  determine  the  action  to  choose.  The  adaptive  controllerexamines  the  control  cost  and  updates  the  action  space  of  the  controller  bydetermining  the  subset  of  actions  that  are  most  likely  to  obtain  optimalresults  and  shrinking  the  action  space  to  that  subset.  Uncertainties  in  trafficinflux  and  turning  rate  are  introduced  to  test  the  robustness  of  the  controllerunder  a  stochastic  environment.  Compared  with  those  with  model  predictivecontrol  (MPC),  the  results  show  that  the  proposed  Q-learning-based  controlleroutperforms  the  MPC  method  by  reaching  a  stable  solution  in  a  shorter  periodand  achieves  lower  control  costs.  The  proposed  Q-learning-based  controller  isalso  robust  under  30%  traffic  demand  uncertainty  and  15%  turning  rateuncertainty.</p>|2019-04-01  22:52:19.486802
http://arxiv.org/abs/1903.12349|A  User-centered  Design  Study  in  Scientific  Visualization  Targeting  Domain  Experts.  (arXiv:1903.12349v1  [cs.HC])|<p>The  development  and  design  of  visualization  solutions  that  are  truly  usableis  essential  for  ensuring  both  their  adoption  and  effectiveness.  User-centereddesign  principles,  which  focus  on  involving  users  throughout  the  entiredevelopment  process,  are  well  suited  for  visualization  and  have  been  shown  tobe  effective  in  numerous  information  visualization  endeavors.  In  this  paper,  wereport  a  two  year  long  collaboration  with  combustion  scientists  that,  byapplying  these  design  principles,  generated  multiple  results  including  an  insitu  visualization  technique  and  a  post  hoc  probability  distribution  function(PDF)  exploration  tool.  Furthermore,  we  examine  the  importance  of  user-centereddesign  principles  and  describe  lessons  learned  over  the  design  process  in  aneffort  to  aid  others  who  also  seek  to  work  with  scientists  for  developingeffective  and  usable  scientific  visualization  solutions.</p>|2019-04-01  22:52:19.486890
http://arxiv.org/abs/1903.12351|Lending  Orientation  to  Neural  Networks  for  Cross-view  Geo-localization.  (arXiv:1903.12351v1  [cs.CV])|<p>This  paper  studies  image-based  geo-localization  (IBL)  problem  usingground-to-aerial  cross-view  matching.  The  goal  is  to  predict  the  spatiallocation  of  a  ground-level  query  image  by  matching  it  to  a  large  geotaggedaerial  image  database  (e.g.,  satellite  imagery).  This  is  a  challenging  task  dueto  the  drastic  differences  in  their  viewpoints  and  visual  appearances.  Existingdeep  learning  methods  for  this  problem  have  been  focused  on  maximizing  featuresimilarity  between  spatially  close-by  image  pairs,  while  minimizing  otherimages  pairs  which  are  far  apart.  They  do  so  by  deep  feature  embedding  based  onvisual  appearance  in  those  ground-and-aerial  images.  However,  in  everyday  life,humans  commonly  use  {\em  orientation}  information  as  an  important  cue  for  thetask  of  spatial  localization.  Inspired  by  this  insight,  this  paper  proposes  anovel  method  which  endows  deep  neural  networks  with  the  `commonsense'  oforientation.  Given  a  ground-level  spherical  panoramic  image  as  query  input  (anda  large  georeferenced  satellite  image  database),  we  design  a  Siamese  networkwhich  explicitly  encodes  the  orientation  (i.e.,  spherical  directions)  of  eachpixel  of  the  images.  Our  method  significantly  boosts  the  discriminative  powerof  the  learned  deep  features,  leading  to  a  much  higher  recall  and  precisionoutperforming  all  previous  methods.  Our  network  is  also  more  compact  using  only1/5th  number  of  parameters  than  a  previously  best-performing  network.  Toevaluate  the  generalization  of  our  method,  we  also  created  a  large-scalecross-view  localization  benchmark  containing  100K  geotagged  ground-aerial  pairscovering  a  city.  Our  codes  and  datasets  are  available  at\url{https://github.com/Liumouliu/OriCNN}.</p>|2019-04-01  22:52:19.487031
http://arxiv.org/abs/1903.12354|Out-of-the  box  neural  networks  can  support  combinatorial  generalization.  (arXiv:1903.12354v1  [cs.AI])|<p>Combinatorial  generalization  -  the  ability  to  understand  and  produce  novelcombinations  of  already  familiar  elements  -  is  considered  to  be  a  core  capacityof  the  human  mind  and  a  major  challenge  to  neural  network  models.  A  significantbody  of  research  suggests  that  conventional  neural  networks  can't  solve  thisproblem  unless  they  are  endowed  with  mechanisms  specifically  engineered  for  thepurpose  of  representing  symbols.  In  this  paper  we  introduce  a  novel  way  ofrepresenting  symbolic  structures  in  connectionist  terms  -  the  vectors  approachto  representing  symbols  (VARS),  which  allows  training  standard  neuralarchitectures  to  encode  symbolic  knowledge  explicitly  at  their  output  layers.In  two  simulations  ,  we  show  that  out-of-the-box  neural  networks  not  only  canlearn  to  produce  VARS  representations,  but  in  doing  so  they  achievecombinatorial  generalization.  This  adds  to  other  recent  work  that  has  shownimproved  combinatorial  generalization  under  specific  training  conditions,  andraises  the  question  of  whether  special  mechanisms  are  indeed  needed  to  supportsymbolic  processing.</p>|2019-04-01  22:52:19.487085
http://arxiv.org/abs/1903.12355|Local  Aggregation  for  Unsupervised  Learning  of  Visual  Embeddings.  (arXiv:1903.12355v1  [cs.CV])|<p>Unsupervised  approaches  to  learning  in  neural  networks  are  of  substantialinterest  for  furthering  artificial  intelligence,  both  because  they  would  enablethe  training  of  networks  without  the  need  for  large  numbers  of  expensiveannotations,  and  because  they  would  be  better  models  of  the  kind  ofgeneral-purpose  learning  deployed  by  humans.  However,  unsupervised  networkshave  long  lagged  behind  the  performance  of  their  supervised  counterparts,especially  in  the  domain  of  large-scale  visual  recognition.  Recent  developmentsin  training  deep  convolutional  embeddings  to  maximize  non-parametric  instanceseparation  and  clustering  objectives  have  shown  promise  in  closing  this  gap.Here,  we  describe  a  method  that  trains  an  embedding  function  to  maximize  ametric  of  local  aggregation,  causing  similar  data  instances  to  move  together  inthe  embedding  space,  while  allowing  dissimilar  instances  to  separate.  Thisaggregation  metric  is  dynamic,  allowing  soft  clusters  of  different  scales  toemerge.  We  evaluate  our  procedure  on  several  large-scale  visual  recognitiondatasets,  achieving  state-of-the-art  unsupervised  transfer  learning  performanceon  object  recognition  in  ImageNet,  scene  recognition  in  Places  205,  and  objectdetection  in  PASCAL  VOC.</p>|2019-04-01  22:52:19.487118
http://arxiv.org/abs/1903.12356|A  General  FOFE-net  Framework  for  Simple  and  Effective  Question  Answering  over  Knowledge  Bases.  (arXiv:1903.12356v1  [cs.CL])|<p>Question  answering  over  knowledge  base  (KB-QA)  has  recently  become  a  popularresearch  topic  in  NLP.  One  popular  way  to  solve  the  KB-QA  problem  is  to  makeuse  of  a  pipeline  of  several  NLP  modules,  including  entity  discovery  andlinking  (EDL)  and  relation  detection.  Recent  success  on  KB-QA  task  usuallyinvolves  complex  network  structures  with  sophisticated  heuristics.  Inspired  bya  previous  work  that  builds  a  strong  KB-QA  baseline,  we  propose  a  simple  butgeneral  neural  model  composed  of  fixed-size  ordinally  forgetting  encoding(FOFE)  and  deep  neural  networks,  called  FOFE-net  to  solve  KB-QA  problem  atdifferent  stages.  For  evaluation,  we  use  two  popular  KB-QA  datasets,SimpleQuestions  and  WebQSP,  and  a  newly  created  dataset,  FreebaseQA.  Theexperimental  results  show  that  FOFE-net  performs  well  on  KB-QA  subtasks,  entitydiscovery  and  linking  (EDL)  and  relation  detection,  and  in  turn  pushing  overallKB-QA  system  to  achieve  strong  results  on  all  datasets.</p>|2019-04-01  22:52:19.487151
http://arxiv.org/abs/1903.12359|Parallelizable  global  conformal  parameterization  of  simply-connected  surfaces  via  partial  welding.  (arXiv:1903.12359v1  [cs.CG])|<p>Conformal  surface  parameterization  is  useful  in  graphics,  imaging  andvisualization,  with  applications  to  texture  mapping,  atlas  construction,registration,  remeshing  and  so  on.  With  the  increasing  capability  in  scanningand  storing  data,  dense  3D  surface  meshes  are  common  nowadays.  While  mesheswith  higher  resolution  better  resemble  smooth  surfaces,  they  pose  computationaldifficulties  for  the  existing  parameterization  algorithms.  In  this  work,  wepropose  a  novel  parallelizable  algorithm  for  computing  the  global  conformalparameterization  of  simply-connected  surfaces  via  partial  welding  maps.  A  givensimply-connected  surface  is  first  partitioned  into  smaller  subdomains.  Thelocal  conformal  parameterizations  of  all  subdomains  are  then  computed  inparallel.  The  boundaries  of  the  parameterized  subdomains  are  subsequentlyintegrated  consistently  using  a  novel  technique  called  partial  welding,  whichis  developed  based  on  conformal  welding  theory.  Finally,  by  solving  the  Laplaceequation  for  each  subdomain  using  the  updated  boundary  conditions,  we  obtain  aglobal  conformal  parameterization  of  the  given  surface,  with  bijectivityguaranteed  by  quasi-conformal  theory.  By  including  additional  shapeconstraints,  our  method  can  be  easily  extended  to  achieve  disk  conformalparameterization  for  simply-connected  open  surfaces  and  spherical  conformalparameterization  for  genus-0  closed  surfaces.  Experimental  results  arepresented  to  demonstrate  the  effectiveness  of  our  proposed  algorithm.  Whencompared  to  the  state-of-the-art  conformal  parameterization  methods,  our  methodachieves  a  significant  improvement  in  both  computational  time  and  accuracy.</p>|2019-04-01  22:52:19.487184
http://arxiv.org/abs/1903.12360|Capacity  of  Fading  Channels  without  Channel  Side  Information.  (arXiv:1903.12360v1  [cs.IT])|<p>There  are  currently  a  plurality  of  capacity  theories  of  fading  channels,including  the  ergodic  capacity  for  fast  fading  channels  and  outage  capacity  forslow  fading  channels.  However,  analyses  show  that  the  outage  capacity  is  amisconception.  In  this  paper  we  use  the  1st  order  Gaussian-Markov  process  withcoherence  coefficient  $\alpha$  as  the  unified  model  for  slow  and  fast  fadingchannels,  the  capacity  of  which  without  channel  side  information  is  studied.  Wedemonstrate  that  the  information  rate  of  a  fading  channel  has  a  structure  thatthe  rate  of  user  message  is  always  accompanied  by  a  rate  of  channelinformation.  The  formula  for  the  channel  information  rate  is  derived  and  turnsout  to  be  a  non-increasing  function  of  $\alpha$.  We  prove  that  there  is  anasymptotically  monotonic  behavior  of  the  user  information  rate  with  respect  to$\alpha$  when  the  input  is  independent,  identically  distributed  and  Gaussian  inthe  high  signal  to  noise  ratio  regime.  It  is  further  conjectured  that  themonotonic  behavior  of  the  user  information  rate  with  respect  to  $\alpha$  isuniversal.</p>|2019-04-01  22:52:19.487216
http://arxiv.org/abs/1903.12363|CUTIE:  Learning  to  Understand  Documents  with  Convolutional  Universal  Text  Information  Extractor.  (arXiv:1903.12363v1  [cs.CV])|<p>Extracting  key  information  from  documents,  such  as  receipts  or  invoices,  andpreserving  the  interested  texts  to  structured  data  is  crucial  in  thedocument-intensive  streamline  processes  of  office  automation  in  areas  thatincludes  but  not  limited  to  accounting,  financial,  and  taxation  areas.  To  avoiddesigning  expert  rules  for  each  specific  type  of  document,  some  published  worksattempt  to  tackle  the  problem  by  learning  a  model  to  explore  the  semanticcontext  in  text  sequences  based  on  the  Named  Entity  Recognition  (NER)  method  inthe  NLP  field.  In  this  paper,  we  propose  to  harness  the  effective  informationfrom  both  semantic  meaning  and  spatial  distribution  of  texts  in  documents.Specifically,  our  proposed  model,  Convolutional  Universal  Text  InformationExtractor  (CUTIE),  applies  convolutional  neural  networks  on  gridded  texts  wheretexts  are  embedded  as  features  with  semantical  connotations.  We  further  explorethe  effect  of  employing  different  structures  of  convolutional  neural  networkand  propose  a  fast  and  portable  structure.  We  demonstrate  the  effectiveness  ofthe  proposed  method  on  a  dataset  with  up  to  6,980  labelled  receipts,  withoutany  pre-training  or  post-processing,  achieving  state  of  the  art  performancethat  is  much  higher  than  BERT  but  with  only  1/10  parameters  and  withoutrequiring  the  3,300M  word  dataset  for  pre-training.  Experimental  results  alsodemonstrate  that  the  CUTIE  being  able  to  achieve  state  of  the  art  performancewith  much  smaller  amount  of  training  data.</p>|2019-04-01  22:52:19.487249
http://arxiv.org/abs/1903.12364|Synthesizing  a  4D  Spatio-Angular  Consistent  Light  Field  from  a  Single  Image.  (arXiv:1903.12364v1  [cs.CV])|<p>Synthesizing  a  densely  sampled  light  field  from  a  single  image  is  highlybeneficial  for  many  applications.  The  conventional  method  reconstructs  a  depthmap  and  relies  on  physical-based  rendering  and  a  secondary  network  to  improvethe  synthesized  novel  views.  Simple  pixel-based  loss  also  limits  the  network  bymaking  it  rely  on  pixel  intensity  cue  rather  than  geometric  reasoning.  In  thisstudy,  we  show  that  a  different  geometric  representation,  namely,  appearanceflow,  can  be  used  to  synthesize  a  light  field  from  a  single  image  robustly  anddirectly.  A  single  end-to-end  deep  neural  network  that  does  not  require  aphysical-based  approach  nor  a  post-processing  subnetwork  is  proposed.  Two  novelloss  functions  based  on  known  light  field  domain  knowledge  are  presented  toenable  the  network  to  preserve  the  spatio-angular  consistency  betweensub-aperture  images  effectively.  Experimental  results  show  that  the  proposedmodel  successfully  synthesizes  dense  light  fields  and  qualitatively  andquantitatively  outperforms  the  previous  model  .  The  method  can  be  generalizedto  arbitrary  scenes,  rather  than  focusing  on  a  particular  class  of  object.  Thesynthesized  light  field  can  be  used  for  various  applications,  such  as  depthestimation  and  refocusing.</p>|2019-04-01  22:52:19.487281
http://arxiv.org/abs/1903.12365|Testing  zero-dimensionality  of  varieties  at  a  point.  (arXiv:1903.12365v1  [cs.SC])|<p>Effective  methods  are  introduced  for  testing  zero-dimensionality  of  varietiesat  a  point.  The  motivation  of  this  paper  is  to  compute  and  analyze  deformationsof  isolated  hypersurface  singularities.  As  an  application,  methods  forcomputing  local  dimensions  are  also  described.  For  the  case  where  a  given  idealcontains  parameters,  the  proposed  algorithms  can  output  in  particular  adecomposition  of  a  parameter  space  into  strata  according  to  the  local  dimensionat  a  point  of  the  associated  varieties.  The  key  of  the  proposed  algorithms  isthe  use  of  the  notion  of  comprehensive  Gr\"obner  systems.</p>|2019-04-01  22:52:19.487312
http://arxiv.org/abs/1903.12366|Using  Structured  Input  and  Modularity  for  Improved  Learning.  (arXiv:1903.12366v1  [cs.NE])|<p>We  describe  a  method  for  utilizing  the  known  structure  of  input  data  to  makelearning  more  efficient.  Our  work  is  in  the  domain  of  programming  languages,and  we  use  deep  neural  networks  to  do  program  analysis.  Computer  programsinclude  a  lot  of  structural  information  (such  as  loop  nests,  conditionalblocks,  and  data  scopes),  which  is  pertinent  to  program  analysis.  In  this  case,the  neural  network  has  to  learn  to  recognize  the  structure,  and  also  learn  thetarget  function  for  the  problem.  However,  the  structural  information  in  thisdomain  is  readily  accessible  to  software  with  the  availability  of  compilertools  and  parsers  for  well-defined  programming  languages.</p><p>Our  method  for  utilizing  the  known  structure  of  input  data  includes:  (1)pre-processing  the  input  data  to  expose  relevant  structures,  and  (2)constructing  neural  networks  by  incorporating  the  structure  of  the  input  dataas  an  integral  part  of  the  network  design.  The  method  has  the  effect  ofmodularizing  the  neural  network  which  helps  break  down  complexity,  and  resultsin  more  efficient  training  of  the  overall  network.  We  apply  this  method  to  anexample  code  analysis  problem,  and  show  that  it  can  achieve  higher  accuracywith  a  smaller  network  size  and  fewer  training  examples.  Further,  the  method  isrobust,  performing  equally  well  on  input  data  with  different  distributions.</p>|2019-04-01  22:52:19.487349
http://arxiv.org/abs/1903.12368|DenseAttentionSeg:  Segment  Hands  from  Interacted  Objects  Using  Depth  Input.  (arXiv:1903.12368v1  [cs.CV])|<p>We  propose  a  real-time  DNN-based  technique  to  segment  hand  and  object  ofinteracting  motions  from  depth  inputs.  Our  model  is  called  DenseAttentionSeg,which  contains  a  dense  attention  mechanism  to  fuse  information  in  differentscales  and  improves  the  results  quality  with  skip-connections.  Besides,  weintroduce  a  contour  loss  in  model  training,  which  helps  to  generate  accuratehand  and  object  boundaries.  Finally,  we  propose  and  will  release  ourInterSegHands  dataset,  a  fine-scale  hand  segmentation  dataset  containing  about52k  depth  maps  of  hand-object  interactions.  Our  experiments  evaluate  theeffectiveness  of  our  techniques  and  datasets,  and  indicate  that  our  methodoutperforms  the  current  state-of-the-art  deep  segmentation  methods  oninteraction  segmentation.</p>|2019-04-01  22:52:19.487382
http://arxiv.org/abs/1903.12370|On  the  Anatomy  of  MCMC-based  Maximum  Likelihood  Learning  of  Energy-Based  Models.  (arXiv:1903.12370v1  [stat.ML])|<p>This  study  investigates  the  effects  Markov  Chain  Monte  Carlo  (MCMC)  samplingin  unsupervised  Maximum  Likelihood  (ML)  learning.  Our  attention  is  restrictedto  the  family  unnormalized  probability  densities  for  which  the  negative  logdensity  (or  energy  function)  is  a  ConvNet.  In  general,  we  find  that  themajority  of  techniques  used  to  stabilize  training  in  previous  studies  can  theopposite  effect.  Stable  ML  learning  with  a  ConvNet  potential  can  be  achievedwith  only  a  few  hyper-parameters  and  no  regularization.  With  this  minimalframework,  we  identify  a  variety  of  ML  learning  outcomes  depending  on  theimplementation  of  MCMC  sampling.</p><p>On  one  hand,  we  show  that  it  is  easy  to  train  an  energy-based  model  which  cansample  realistic  images  with  short-run  Langevin.  ML  can  be  effective  and  stableeven  when  MCMC  samples  have  much  higher  energy  than  true  steady-state  samplesthroughout  training.  Based  on  this  insight,  we  introduce  an  ML  method  withnoise  initialization  for  MCMC,  high-quality  short-run  synthesis,  and  the  samebudget  as  ML  with  informative  MCMC  initialization  such  as  CD  or  PCD.  Unlikeprevious  models,  this  model  can  obtain  realistic  high-diversity  samples  from  anoise  signal  after  training  with  no  auxiliary  models.</p><p>On  the  other  hand,  models  learned  with  highly  non-convergent  MCMC  do  not  havea  valid  steady-state  and  cannot  be  considered  approximate  unnormalizeddensities  of  the  training  data  because  long-run  MCMC  samples  differ  greatlyfrom  the  data.  We  show  that  it  is  much  harder  to  train  an  energy-based  modelwhere  long-run  and  steady-state  MCMC  samples  have  realistic  appearance.  To  ourknowledge,  long-run  MCMC  samples  of  all  previous  models  result  in  unrealisticimages.  With  correct  tuning  of  Langevin  noise,  we  train  the  first  models  forwhich  long-run  and  steady-state  MCMC  samples  are  realistic  images.</p>|2019-04-01  22:52:19.487415
http://arxiv.org/abs/1903.12371|Cyber-Social  Systems:  Modeling,  Inference,  and  Optimal  Design.  (arXiv:1903.12371v1  [cs.SY])|<p>This  paper  models  the  cyber-social  system  as  a  cyber-network  of  agentsmonitoring  states  of  individuals  in  a  social  network.  The  state  of  eachindividual  is  represented  by  a  social  node  and  the  interactions  amongindividuals  are  represented  by  a  social  link.  In  the  cyber-network  each  noderepresents  an  agent  and  the  links  represent  information  sharing  among  agents.Agents  make  an  observation  of  social  states  and  perform  distributed  inference.In  this  direction,  the  contribution  of  this  work  is  threefold:  (i)  A  noveldistributed  inference  protocol  is  proposed  that  makes  no  assumption  on  the  rankof  the  underlying  social  system.  This  is  significant  as  most  protocols  in  theliterature  only  work  on  full-rank  systems.  (ii)  A  novel  agent  classification  isdeveloped,  where  it  is  shown  that  connectivity  requirement  on  the  cyber-networkdiffers  for  each  type.  This  is  particularly  important  in  finding  the  minimalnumber  of  observations  and  minimal  connectivity  of  the  cyber-network  as  thenext  contribution.  (iii)  The  cost-optimal  design  of  cyber-network  constraintwith  distributed  observability  is  addressed.  This  problem  is  subdivided  intosensing  cost  optimization  and  networking  cost  optimization  where  both  areclaimed  to  be  NP-hard.  We  solve  both  problems  for  certain  types  of  socialnetworks  and  find  polynomial-order  solutions.</p>|2019-04-01  22:52:19.487449
http://arxiv.org/abs/1903.12384|Deep  Representation  with  ReLU  Neural  Networks.  (arXiv:1903.12384v1  [cs.LG])|<p>We  consider  deep  feedforward  neural  networks  with  rectified  linear  units  froma  signal  processing  perspective.  In  this  view,  such  representations  mark  thetransition  from  using  a  single  (data-driven)  linear  representation  to  utilizinga  large  collection  of  affine  linear  representations  tailored  to  particularregions  of  the  signal  space.  This  paper  provides  a  precise  description  of  theindividual  affine  linear  representations  and  corresponding  domain  regions  thatthe  (data-driven)  neural  network  associates  to  each  signal  of  the  input  space.In  particular,  we  describe  atomic  decompositions  of  the  representations  and,based  on  estimating  their  Lipschitz  regularity,  suggest  some  conditions  thatcan  stabilize  learning  independent  of  the  network  depth.  Such  an  analysis  maypromote  further  theoretical  insight  from  both  the  signal  processing  and  machinelearning  communities.</p>|2019-04-01  22:52:19.487494
http://arxiv.org/abs/1903.12385|Fractional  matchings  and  component-factors  of  (edge-chromatic  critical)  graphs.  (arXiv:1903.12385v1  [math.CO])|<p>The  paper  studies  component-factors  of  graphs  which  can  be  characterized  interms  of  their  fractional  matching  number.  These  results  are  used  to  prove  thatevery  edge-chromatic  critical  graph  has  a  $[1,2]$-factor.  Furthermore,fractional  matchings  of  edge-chromatic  critical  graphs  are  studied  and  somequestions  are  related  to  Vizing's  conjectures  on  the  independence  number  and2-factors  of  edge-chromatic  critical  graphs.</p>|2019-04-01  22:52:19.487527
http://arxiv.org/abs/1903.12386|G\'EANT  Software  Maturity  Model.  (arXiv:1903.12386v1  [cs.SE])|<p>G\'EANT  project  is  an  example  of  a  large  organization  with  around  30  softwareprojects  and  around  20  software  development  teams.  Software  development  teamsconsist  of  many  skilled  associates  coming  from  all  members  National  Researchand  Education  Networks.  Three  main  issues  that  are  common  for  all  thesesoftware  development  teams  and  their  members  are:  geographical  distribution,scattered  manpower  percentage,  and  parallel  involvement  in  other  high  priorityprojects  in  their  native  organizations.  This  paper  presents  a  novel  softwarematurity  model  that  is  designed  specifically  for  G\'EANT  software  developmentteams  and  aims  to  address  the  described  issues.</p>|2019-04-01  22:52:19.487560
http://arxiv.org/abs/1903.12388|Predictability  of  diffusion-based  recommender  systems.  (arXiv:1903.12388v1  [physics.soc-ph])|<p>The  recommendation  methods  based  on  network  diffusion  have  been  shown  toperform  well  in  both  recommendation  accuracy  and  diversity.  Nowdays,  numerousextensions  have  been  made  to  further  improve  the  performance  of  such  methods.However,  to  what  extent  can  items  be  predicted  by  diffusion-based  algorithmsstill  lack  of  understanding.  Here,  we  mainly  propose  a  method  to  quantify  thepredictability  of  diffusion-based  algorithms.  Accordingly,  we  conductexperiments  on  Movielens  and  Netflix  data  sets.  The  results  show  that  thehigher  recommendation  accuracy  based  on  diffusion  algorithms  can  still  beachieved  by  optimizing  the  way  of  resource  allocation  on  a  density  network.  Ona  sparse  network,  the  possibility  of  improving  accuracy  is  relatively  low  dueto  the  fact  that  the  current  accuracy  of  diffusion-based  methods  is  very  closeits  predictability.  In  this  case,  we  find  that  the  predictability  can  beimproved  significantly  by  multi-steps  diffusion,  especially  for  users  with  lesshistorical  information.  In  contrast  to  common  belief,  there  are  plausiblecircumstances  where  the  higher  predictability  of  diffusion-based  methods  do  notcorrespond  to  those  users  with  more  historical  recording.  Thus,  we  proposed  thediffusion  coverage  and  item  average  degree  to  explain  this  phenomenon.  Inaddition,  we  demonstrate  the  recommendation  accuracy  in  real  online  system  isoverestimated  by  random  partition  used  in  the  literature,  suggesting  therecommendation  in  real  online  system  may  be  a  harder  task.</p>|2019-04-01  22:52:19.487592
http://arxiv.org/abs/1903.12389|Joint  training  framework  for  text-to-speech  and  voice  conversion  using  multi-source  Tacotron  and  WaveNet.  (arXiv:1903.12389v1  [eess.AS])|<p>We  investigated  the  training  of  a  shared  model  for  both  text-to-speech  (TTS)and  voice  conversion  (VC)  tasks.  We  propose  using  an  extended  modelarchitecture  of  Tacotron,  that  is  a  multi-source  sequence-to-sequence  modelwith  a  dual  attention  mechanism  as  the  shared  model  for  both  the  TTS  and  VCtasks.  This  model  can  accomplish  these  two  different  tasks  respectivelyaccording  to  the  type  of  input.  An  end-to-end  speech  synthesis  task  isconducted  when  the  model  is  given  text  as  the  input  while  asequence-to-sequence  voice  conversion  task  is  conducted  when  it  is  given  thespeech  of  a  source  speaker  as  the  input.  Waveform  signals  are  generated  byusing  WaveNet,  which  is  conditioned  by  using  a  predicted  mel-spectrogram.  Wepropose  jointly  training  a  shared  model  as  a  decoder  for  a  target  speaker  thatsupports  multiple  sources.  Listening  experiments  show  that  our  proposedmulti-source  encoder-decoder  model  can  efficiently  achieve  both  the  TTS  and  VCtasks.</p>|2019-04-01  22:52:19.487625
http://arxiv.org/abs/1903.12392|Training  a  Neural  Speech  Waveform  Model  using  Spectral  Losses  of  Short-Time  Fourier  Transform  and  Continuous  Wavelet  Transform.  (arXiv:1903.12392v1  [eess.AS])|<p>Recently,  we  proposed  short-time  Fourier  transform  (STFT)-based  lossfunctions  for  training  a  neural  speech  waveform  model.  In  this  paper,  wegeneralize  the  above  framework  and  propose  a  training  scheme  for  such  modelsbased  on  spectral  amplitude  and  phase  losses  obtained  by  either  STFT  orcontinuous  wavelet  transform  (CWT),  or  both  of  them.  Since  CWT  is  capable  ofhaving  time  and  frequency  resolutions  different  from  those  of  STFT  and  is  cableof  considering  those  closer  to  human  auditory  scales,  the  proposed  lossfunctions  could  provide  complementary  information  on  speech  signals.Experimental  results  showed  that  it  is  possible  to  train  a  high-quality  modelby  using  the  proposed  CWT  spectral  loss  and  is  as  good  as  one  using  STFT-basedloss.</p>|2019-04-01  22:52:19.487676
http://arxiv.org/abs/1903.12394|Informed  Machine  Learning  -  Towards  a  Taxonomy  of  Explicit  Integration  of  Knowledge  into  Machine  Learning.  (arXiv:1903.12394v1  [stat.ML])|<p>Despite  the  great  successes  of  machine  learning,  it  can  have  its  limits  whendealing  with  insufficient  training  data.A  potential  solution  is  to  incorporateadditional  knowledge  into  the  training  process  which  leads  to  the  idea  ofinformed  machine  learning.  We  present  a  research  survey  and  structured  overviewof  various  approaches  in  this  field.  We  aim  to  establish  a  taxonomy  which  canserve  as  a  classification  framework  that  considers  the  kind  of  additionalknowledge,  its  representation,and  its  integration  into  the  machine  learningpipeline.  The  evaluation  of  numerous  papers  on  the  bases  of  the  taxonomyuncovers  key  methods  in  this  field.</p>|2019-04-01  22:52:19.487740
http://arxiv.org/abs/1903.12395|Few-Shot  Deep  Adversarial  Learning  for  Video-based  Person  Re-identification.  (arXiv:1903.12395v1  [cs.CV])|<p>Video-based  person  re-identification  (re-ID)  refers  to  matching  people  acrosscamera  views  from  arbitrary  unaligned  video  footages.  Existing  methods  rely  onsupervision  signals  to  optimise  a  projected  space  under  which  the  distancesbetween  inter/intra-videos  are  maximised/minimised.  However,  this  demandsexhaustively  labelling  people  across  camera  views,  rendering  them  unable  to  bescaled  in  large  networked  cameras.  Also,  it  is  noticed  that  learning  effectivevideo  representations  with  view  invariance  is  not  explicitly  addressed  forwhich  features  exhibit  different  distributions  otherwise.  Thus,  matching  videosfor  person  re-ID  demands  flexible  models  to  capture  the  dynamics  in  time-seriesobservations  and  learn  view-invariant  representations  with  access  to  limitedlabeled  training  samples.  In  this  paper,  we  propose  a  novel  few-shot  deeplearning  approach  to  video-based  person  re-ID,  to  learn  comparablerepresentations  that  are  discriminative  and  view-invariant.  The  proposed  methodis  developed  on  the  variational  recurrent  neural  networks  (VRNNs)  and  trainedadversarially  to  produce  latent  variables  with  temporal  dependencies  that  arehighly  discriminative  yet  view-invariant  in  matching  persons.  Through  extensiveexperiments  conducted  on  three  benchmark  datasets,  we  empirically  show  thecapability  of  our  method  in  creating  view-invariant  temporal  features  andstate-of-the-art  performance  achieved  by  our  method.</p>|2019-04-01  22:52:19.487798
http://arxiv.org/abs/1903.12398|Identification  and  Analysis  of  Cascading  Failures  in  Power  Grids  with  Protective  Actions.  (arXiv:1903.12398v1  [cs.SY])|<p>This  paper  aims  to  identify  and  analyze  the  initial  contingencies  ordisturbances  that  could  lead  to  the  worst-case  cascading  failures  of  powergrids.  An  optimal  control  approach  is  proposed  to  determine  the  most  disruptivedisturbances  on  the  branch  of  power  transmission  system  by  regarding  thedisturbances  as  the  control  inputs.  Moreover,  protective  actions  such  as  loadshedding  and  generation  dispatch  are  taken  into  account  in  a  convexoptimization  framework  to  prevent  the  cascading  outages  of  power  grids.  Intheory,  the  necessary  conditions  for  identifying  the  most  disruptivedisturbances  are  obtained  by  solving  an  integrated  system  of  algebraicequations.  Finally,  numerical  simulations  are  carried  out  to  validate  theproposed  approach  on  the  IEEE  RTS  24  Bus  System.</p>|2019-04-01  22:52:19.487832
http://arxiv.org/abs/1903.12399|A  Study  on  the  Characteristics  of  Douyin  Short  Videos  and  Implications  for  Edge  Caching.  (arXiv:1903.12399v1  [cs.MM])|<p>Douyin,  internationally  known  as  TikTok,  has  become  one  of  the  mostsuccessful  short-video  platforms.  To  maintain  its  popularity,  Douyin  has  toprovide  better  Quality  of  Experience  (QoE)  to  its  growing  user  base.Understanding  the  characteristics  of  Douyin  videos  is  thus  critical  to  itsservice  improvement  and  system  design.  In  this  paper,  we  present  an  initialstudy  on  the  fundamental  characteristics  of  Douyin  videos  based  on  a  dataset  ofover  260  thousand  short  videos  collected  across  three  months.  Thecharacteristics  of  Douyin  videos  are  found  to  be  significantly  different  fromtraditional  online  videos,  ranging  from  video  bitrate,  size,  to  popularity.  Inparticular,  the  distributions  of  the  bitrate  and  size  of  videos  follow  Weibulldistribution.  We  further  observe  that  the  most  popular  Douyin  videos  followZifp's  law  on  video  popularity,  but  the  rest  of  the  videos  do  not.  We  alsoinvestigate  the  correlation  between  popularity  metrics  used  for  Douyin  videos.It  is  found  that  the  correlation  between  the  number  of  views  and  the  number  oflikes  are  strong,  while  other  correlations  are  relatively  low.  Finally,  byusing  a  case  study,  we  demonstrate  that  the  above  findings  can  provideimportant  guidance  on  designing  an  efficient  edge  caching  system.</p>|2019-04-01  22:52:19.487865
http://arxiv.org/abs/1903.12400|A  Force-Directed  Approach  for  Offline  GPS  Trajectory  Map  Matching.  (arXiv:1903.12400v1  [cs.DS])|<p>We  present  a  novel  algorithm  to  match  GPS  trajectories  onto  maps  offline  (inbatch  mode)  using  techniques  borrowed  from  the  field  of  force-directed  graphdrawing.  We  consider  a  simulated  physical  system  where  each  GPS  trajectory  isattracted  or  repelled  by  the  underlying  road  network  via  electrical-likeforces.  We  let  the  system  evolve  under  the  action  of  these  physical  forces  suchthat  individual  trajectories  are  attracted  towards  candidate  roads  to  obtain  amap  matching  path.  Our  approach  has  several  advantages  compared  to  traditional,routing-based,  algorithms  for  map  matching,  including  the  ability  to  accountfor  noise  and  to  avoid  large  detours  due  to  outliers  in  the  data  whilst  takinginto  account  the  underlying  topological  restrictions  (such  as  one-way  roads).Our  empirical  evaluation  using  real  GPS  traces  shows  that  our  method  producesbetter  map  matching  results  compared  to  alternative  offline  map  matchingalgorithms  on  average,  especially  for  routes  in  dense,  urban  areas.</p>|2019-04-01  22:52:19.487897
http://arxiv.org/abs/1903.12402|Proceedings  7th  International  Workshop  on  Theorem  proving  components  for  Educational  software.  (arXiv:1903.12402v1  [cs.LO])|<p>The  7th  International  Workshop  on  Theorem  proving  components  for  Educationalsoftware  (ThEdu'18)  was  held  in  Oxford,  United  Kingdom,  on  18  July  2018.  It  wasassociated  to  the  conference,  Federated  Logic  Conference  2018  (FLoC2018).</p><p>The  major  aim  of  the  ThEdu  workshop  series  was  to  link  developers  interestedin  adapting  Computer  Theorem  Proving  (TP)  to  the  needs  of  education  and  toinform  mathematicians  and  mathematics  educators  about  TP's  potential  foreducational  software.  Topics  of  interest  include:  methods  of  automateddeduction  applied  to  checking  students'  input;  methods  of  automated  deductionapplied  to  prove  post-conditions  for  particular  problem  solutions;  combinationsof  deduction  and  computation  enabling  systems  to  propose  next  steps;  automatedprovers  specific  for  dynamic  geometry  systems;  proof  and  proving  in  mathematicseducation.</p><p>ThEdu'18  was  a  vibrant  workshop,  with  one  invited  talk  and  six  contributions.It  triggered  the  post-proceedings  at  hand.</p>|2019-04-01  22:52:19.487930
http://arxiv.org/abs/1903.12411|MCTS-based  Automated  Negotiation  Agent  (Extended  Abstract).  (arXiv:1903.12411v1  [cs.AI])|<p>This  paper  introduces  a  new  Negotiating  Agent  for  automated  negotiation  oncontinuous  domains  and  without  considering  a  specified  deadline.  The  agentbidding  strategy  relies  on  Monte  Carlo  Tree  Search,  which  is  a  trendy  methodsince  it  has  been  used  with  success  on  games  with  high  branching  factor  such  asGo.  It  uses  two  opponent  modeling  techniques  for  its  bidding  strategy  and  itsutility:  Gaussian  process  regression  and  Bayesian  learning.  Evaluation  is  doneby  confronting  the  existing  agents  that  are  able  to  negotiate  in  such  context:Random  Walker,  Tit-for-tat  and  Nice  Tit-for-Tat.  None  of  those  agents  succeedsin  beating  our  agent;  moreover  the  modular  and  adaptive  nature  of  our  approachis  a  huge  advantage  when  it  comes  to  optimize  it  in  specific  applicativecontexts.</p>|2019-04-01  22:52:19.487962
http://arxiv.org/abs/1903.12416|Online  Variance  Reduction  with  Mixtures.  (arXiv:1903.12416v1  [cs.LG])|<p>Adaptive  importance  sampling  for  stochastic  optimization  is  a  promisingapproach  that  offers  improved  convergence  through  variance  reduction.  In  thiswork,  we  propose  a  new  framework  for  variance  reduction  that  enables  the  use  ofmixtures  over  predefined  sampling  distributions,  which  can  naturally  encodeprior  knowledge  about  the  data.  While  these  sampling  distributions  are  fixed,the  mixture  weights  are  adapted  during  the  optimization  process.  We  proposeVRM,  a  novel  and  efficient  adaptive  scheme  that  asymptotically  recovers  thebest  mixture  weights  in  hindsight  and  can  also  accommodate  samplingdistributions  over  sets  of  points.  We  empirically  demonstrate  the  versatilityof  VRM  in  a  range  of  applications.</p>|2019-04-01  22:52:19.487993
http://arxiv.org/abs/1903.12417|Nonlinear  fourth  order  Taylor  expansion  of  lattice  Boltzmann  schemes.  (arXiv:1903.12417v1  [math.NA])|<p>We  propose  a  formal  expansion  of  multiple  relaxation  times  lattice  Boltzmannschemes  in  terms  of  a  single  infinitesimal  numerical  variable.  The  result  is  asystem  of  partial  differential  equations  for  the  conserved  moments  of  thelattice  Boltzmann  scheme.  The  expansion  is  presented  in  the  nonlinear  case  upto  fourth  order  accuracy.  The  asymptotic  corrections  of  the  nonconservedmoments  are  developed  in  terms  of  equilibrium  values  and  partial  differentialsof  the  conserved  moments.  Both  expansions  are  coupled  and  conduct  to  explicitcompact  formulas.  The  new  algebraic  expressions  are  validated  with  previousresults  obtained  with  this  approach.  The  example  of  isothermal  D2Q9  latticeBoltzmann  scheme  illustrates  the  theoretical  framework.</p>|2019-04-01  22:52:19.488078
http://arxiv.org/abs/1903.12422|Snore-GANs:  Improving  Automatic  Snore  Sound  Classification  with  Synthesized  Data.  (arXiv:1903.12422v1  [cs.LG])|<p>One  of  the  frontier  issues  that  severely  hamper  the  development  of  automaticsnore  sound  classification  (ASSC)  associates  to  the  lack  of  sufficientsupervised  training  data.  To  cope  with  this  problem,  we  propose  a  novel  dataaugmentation  approach  based  on  semi-supervised  conditional  GenerativeAdversarial  Networks  (scGANs),  which  aims  to  automatically  learn  a  mappingstrategy  from  a  random  noise  space  to  original  data  distribution.  The  proposedapproach  has  the  capability  of  well  synthesizing  'realistic'  high-dimensionaldata,  while  requiring  no  additional  annotation  process.  To  handle  the  modecollapse  problem  of  GANs,  we  further  introduce  an  ensemble  strategy  to  enhancethe  diversity  of  the  generated  data.  The  systematic  experiments  conducted  on  awidely  used  Munich-Passau  snore  sound  corpus  demonstrate  that  the  scGANs-basedsystems  can  remarkably  outperform  other  classic  data  augmentation  systems,  andare  also  competitive  to  other  recently  reported  systems  for  ASSC.</p>|2019-04-01  22:52:19.488115
http://arxiv.org/abs/1903.12424|Attention-Augmented  End-to-End  Multi-Task  Learning  for  Emotion  Prediction  from  Speech.  (arXiv:1903.12424v1  [cs.CL])|<p>Despite  the  increasing  research  interest  in  end-to-end  learning  systems  forspeech  emotion  recognition,  conventional  systems  either  suffer  from  theoverfitting  due  in  part  to  the  limited  training  data,  or  do  not  explicitlyconsider  the  different  contributions  of  automatically  learnt  representationsfor  a  specific  task.  In  this  contribution,  we  propose  a  novel  end-to-endframework  which  is  enhanced  by  learning  other  auxiliary  tasks  and  an  attentionmechanism.  That  is,  we  jointly  train  an  end-to-end  network  with  severaldifferent  but  related  emotion  prediction  tasks,  i.e.,  arousal,  valence,  anddominance  predictions,  to  extract  more  robust  representations  shared  amongvarious  tasks  than  traditional  systems  with  the  hope  that  it  is  able  to  relievethe  overfitting  problem.  Meanwhile,  an  attention  layer  is  implemented  on  top  ofthe  layers  for  each  task,  with  the  aim  to  capture  the  contribution  distributionof  different  segment  parts  for  each  individual  task.  To  evaluate  theeffectiveness  of  the  proposed  system,  we  conducted  a  set  of  experiments  on  thewidely  used  database  IEMOCAP.  The  empirical  results  show  that  the  proposedsystems  significantly  outperform  corresponding  baseline  systems.</p>|2019-04-01  22:52:19.488167
http://arxiv.org/abs/1903.12427|Computing  huge  Groebner  basis  like  cyclic10  over  $\Q$  with  Giac.  (arXiv:1903.12427v1  [cs.SC])|<p>We  present  a  short  description  on  how  to  fine-tune  the  modular  algorithmimplemented  in  the  Giac  computer  algebra  system  to  reconstruct  huge  Groebnerbasis  over  $\Q$.The  classical  cyclic10  benchmark  will  serve  as  example.</p>|2019-04-01  22:52:19.488203
http://arxiv.org/abs/1903.12431|Train  One  Get  One  Free:  Partially  Supervised  Neural  Network  for  Bug  Report  Duplicate  Detection  and  Clustering.  (arXiv:1903.12431v1  [cs.CL])|<p>Tracking  user  reported  bugs  requires  considerable  engineering  effort  in  goingthrough  many  repetitive  reports  and  assigning  them  to  the  correct  teams.  Thispaper  proposes  a  neural  architecture  that  can  jointly  (1)  detect  if  two  bugreports  are  duplicates,  and  (2)  aggregate  them  into  latent  topics.  Leveragingthe  assumption  that  learning  the  topic  of  a  bug  is  a  sub-task  for  detectingduplicates,  we  design  a  loss  function  that  can  jointly  perform  both  tasks  butneeds  supervision  for  only  duplicate  classification,  achieving  topic  clusteringin  an  unsupervised  fashion.  We  use  a  two-step  attention  module  that  usesself-attention  for  topic  clustering  and  conditional  attention  for  duplicatedetection.  We  study  the  characteristics  of  two  types  of  real  world  datasetsthat  have  been  marked  for  duplicate  bugs  by  engineers  and  by  non-technicalannotators.  The  results  demonstrate  that  our  model  not  only  can  outperformstate-of-the-art  methods  for  duplicate  classification  on  both  cases,  but  canalso  learn  meaningful  latent  clusters  without  additional  supervision.</p>|2019-04-01  22:52:19.488236
http://arxiv.org/abs/1903.12432|Color  Refinement,  Homomorphisms,  and  Hypergraphs.  (arXiv:1903.12432v1  [cs.DM])|<p>Recent  results  show  that  the  structural  similarity  of  graphs  can  becharacterized  by  counting  homomorphisms  to  them:  the  Tree  Theorem  states  thatthe  well-known  color-refinement  algorithm  does  not  distinguish  two  graphs  G  andH  if  and  only  if,  for  every  tree  T,  the  number  of  homomorphisms  Hom(T,G)  from  Tto  G  is  equal  to  the  corresponding  number  Hom(T,H)  from  T  to  H  (Dell,  Grohe,Rattan  2018).  We  show  how  this  approach  transfers  to  hypergraphs  by  introducinga  generalization  of  color  refinement.  We  prove  that  it  does  not  distinguish  twohypergraphs  G  and  H  if  and  only  if,  for  every  connected  Berge-acyclichypergraph  B,  we  have  Hom(B,G)  =  Hom(B,H).  To  this  end,  we  show  howhomomorphisms  of  hypergraphs  and  of  a  colored  variant  of  their  incidence  graphsare  related  to  each  other.  This  reduces  the  above  statement  to  one  aboutvertex-colored  graphs.</p>|2019-04-01  22:52:19.488269
http://arxiv.org/abs/1903.12436|From  Variational  to  Deterministic  Autoencoders.  (arXiv:1903.12436v1  [cs.LG])|<p>Variational  Autoencoders  (VAEs)  provide  a  theoretically-backed  framework  fordeep  generative  models.  However,  they  often  produce  "blurry"  images,  which  islinked  to  their  training  objective.  Sampling  in  the  most  popularimplementation,  the  Gaussian  VAE,  can  be  interpreted  as  simply  injecting  noiseto  the  input  of  a  deterministic  decoder.  In  practice,  this  simply  enforces  asmooth  latent  space  structure.  We  challenge  the  adoption  of  the  full  VAEframework  on  this  specific  point  in  favor  of  a  simpler,  deterministic  one.Specifically,  we  investigate  how  substituting  stochasticity  with  other  explicitand  implicit  regularization  schemes  can  lead  to  a  meaningful  latent  spacewithout  having  to  force  it  to  conform  to  an  arbitrarily  chosen  prior.  Toretrieve  a  generative  mechanism  for  sampling  new  data  points,  we  propose  toemploy  an  efficient  ex-post  density  estimation  step  that  can  be  readily  adoptedboth  for  the  proposed  deterministic  autoencoders  as  well  as  to  improve  samplequality  of  existing  VAEs.  We  show  in  a  rigorous  empirical  study  thatregularized  deterministic  autoencoding  achieves  state-of-the-art  sample  qualityon  the  common  MNIST,  CIFAR-10  and  CelebA  datasets.</p>|2019-04-01  22:52:19.488305
http://arxiv.org/abs/1903.12449|Multiplication  method  for  factoring  natural  numbers.  (arXiv:1903.12449v1  [cs.DS])|<p>We  offer  multiplication  method  for  factoring  big  natural  numbers  whichextends  the  group  of  the  Fermat's  and  Lehman's  factorization  algorithms  and  hasrun-time  complexity  $O(n^{1/3})$.  This  paper  is  argued  the  finiteness  ofproposed  algorithm  depending  on  the  value  of  the  factorizable  number  n.  Weprovide  here  comparative  tests  results  of  related  algorithms  on  a  large  amountof  computational  checks.  We  describe  identified  advantages  of  the  proposedalgorithm  over  others.  The  possibilities  of  algorithm  optimization  for  reducingthe  complexity  of  factorization  are  also  shown  here.</p>|2019-04-01  22:52:19.488337
http://arxiv.org/abs/1903.12451|Energy-Efficient  Distributed  Processing  in  Vehicular  Cloud  Architecture.  (arXiv:1903.12451v1  [cs.NI])|<p>Facilitating  the  revolution  for  smarter  cities,  vehicles  are  getting  smarterand  equipped  with  more  resources  to  go  beyond  transportation  functionality.On-Board  Units  (OBU)  are  efficient  computers  inside  vehicles  that  serve  safetyand  non-safety  based  applications.  However,  much  of  these  resources  areunderutilised.  On  the  other  hand,  more  users  are  relying  now  on  cloud  computingwhich  is  becoming  costly  and  energy  consuming.  In  this  paper,  we  develop  aMixed  Integer  linear  Programming  (MILP)  model  that  optimizes  the  allocation  ofprocessing  demands  in  an  architecture  that  encompasses  the  vehicles,  edge  andcloud  computing  with  the  objective  of  minimizing  power  consumption.  The  resultsshow  power  savings  of  70%-90%  compared  to  conventional  clouds  for  smalldemands.  For  medium  and  large  demand  sizes,  the  results  show  20%-30%  powersaving  as  the  cloud  was  used  partially  due  to  capacity  limitations  on  thevehicular  and  edge  nodes.</p>|2019-04-01  22:52:19.488370
http://arxiv.org/abs/1903.12452|A  framework  for  fake  review  detection  in  online  consumer  electronics  retailers.  (arXiv:1903.12452v1  [cs.CL])|<p>The  impact  of  online  reviews  on  businesses  has  grown  significantly  duringlast  years,  being  crucial  to  determine  business  success  in  a  wide  array  ofsectors,  ranging  from  restaurants,  hotels  to  e-commerce.  Unfortunately,  someusers  use  unethical  means  to  improve  their  online  reputation  by  writing  fakereviews  of  their  businesses  or  competitors.  Previous  research  has  addressedfake  review  detection  in  a  number  of  domains,  such  as  product  or  businessreviews  in  restaurants  and  hotels.  However,  in  spite  of  its  economicalinterest,  the  domain  of  consumer  electronics  businesses  has  not  yet  beenthoroughly  studied.  This  article  proposes  a  feature  framework  for  detectingfake  reviews  that  has  been  evaluated  in  the  consumer  electronics  domain.  Thecontributions  are  fourfold:  (i)  Construction  of  a  dataset  for  classifying  fakereviews  in  the  consumer  electronics  domain  in  four  different  cities  based  onscraping  techniques;  (ii)  definition  of  a  feature  framework  for  fake  reviewdetection;  (iii)  development  of  a  fake  review  classification  method  based  onthe  proposed  framework  and  (iv)  evaluation  and  analysis  of  the  results  for  eachof  the  cities  under  study.  We  have  reached  an  82%  F-Score  on  the  classificationtask  and  the  Ada  Boost  classifier  has  been  proven  to  be  the  best  one  bystatistical  means  according  to  the  Friedman  test.</p>|2019-04-01  22:52:19.488402
http://arxiv.org/abs/1903.12453|Frowning  Frodo,  Wincing  Leia,  and  a  Seriously  Great  Friendship:  Learning  to  Classify  Emotional  Relationships  of  Fictional  Characters.  (arXiv:1903.12453v1  [cs.CL])|<p>The  development  of  a  fictional  plot  is  centered  around  characters  who  closelyinteract  with  each  other  forming  dynamic  social  networks.  In  literatureanalysis,  such  networks  have  mostly  been  analyzed  without  particular  relationtypes  or  focusing  on  roles  which  the  characters  take  with  respect  to  eachother.  We  argue  that  an  important  aspect  for  the  analysis  of  stories  and  theirdevelopment  is  the  emotion  between  characters.  In  this  paper,  we  combine  theseaspects  into  a  unified  framework  to  classify  emotional  relationships  offictional  characters.  We  formalize  it  as  a  new  task  and  describe  the  annotationof  a  corpus,  based  on  fan-fiction  short  stories.  The  extraction  pipeline  whichwe  propose  consists  of  character  identification  (which  we  treat  as  given  by  anoracle  here)  and  the  relation  classification.  For  the  latter,  we  provideresults  using  several  approaches  previously  proposed  for  relationidentification  with  neural  methods.  The  best  result  of  0.45  F1  is  achieved  witha  GRU  with  character  position  indicators  on  the  task  of  predicting  undirectedemotion  relations  in  the  associated  social  network  graph.</p>|2019-04-01  22:52:19.488434
http://arxiv.org/abs/1903.12457|Towards  Knowledge-Based  Personalized  Product  Description  Generation  in  E-commerce.  (arXiv:1903.12457v1  [cs.CL])|<p>Quality  product  descriptions  are  critical  for  providing  competitive  customerexperience  in  an  E-commerce  platform.  An  accurate  and  attractive  descriptionnot  only  helps  customers  make  an  informed  decision  but  also  improves  thelikelihood  of  purchase.  However,  crafting  a  successful  product  description  istedious  and  highly  time-consuming.  Due  to  its  importance,  automating  theproduct  description  generation  has  attracted  considerable  interests  from  bothresearch  and  industrial  communities.  Existing  methods  mainly  use  templates  orstatistical  methods,  and  their  performance  could  be  rather  limited.</p><p>In  this  paper,  we  explore  a  new  way  to  generate  the  personalized  productdescription  by  combining  the  power  of  neural  networks  and  knowledge  base.Specifically,  we  propose  a  KnOwledge  Based  pEronalized  (or  KOBE)  productdescription  generation  model  in  the  context  of  E-commerce.  In  KOBE,  we  extendthe  encoder-decoder  framework,  the  Transformer,  to  a  sequence  modelingformulation  using  self-attention.  In  order  to  make  the  description  bothinformative  and  personalized,  KOBE  considers  a  variety  of  important  factorsduring  text  generation,  including  product  aspects,  user  categories,  andknowledge  base,  etc.  Experiments  on  real-world  datasets  demonstrate  that  theproposed  method  out-performs  the  baseline  on  various  metrics.  KOBE  can  achievean  improvement  of  9.7%  over  state-of-the-arts  in  terms  of  BLEU.  We  also  presentseveral  case  studies  as  the  anecdotal  evidence  to  further  prove  theeffectiveness  of  the  proposed  approach.  The  framework  has  been  deployed  inTaobao,  the  largest  online  E-commerce  platform  in  China.</p>|2019-04-01  22:52:19.488467
http://arxiv.org/abs/1903.12458|Market  Manipulation  as  a  Security  Problem.  (arXiv:1903.12458v1  [q-fin.TR])|<p>Order  matching  systems  form  the  backbone  of  modern  equity  exchanges,  used  bymillions  of  investors  daily.  Thus,  their  operation  is  strictly  controlledthrough  numerous  regulatory  directives  to  ensure  that  markets  are  fair  andtransparent.  Despite  these  efforts,  market  manipulation  remains  an  openproblem.</p><p>In  this  work,  we  focus  on  a  class  of  market  manipulation  techniques  thatexploit  technical  details  and  glitches  in  the  operation  of  the  exchanges  (i.e.,mechanical  arbitrage).  Such  techniques  are  used  by  predatory  traders  with  deepknowledge  of  the  exchange's  structure  to  gain  an  advantage  over  the  othermarket  participants.  We  argue  that  technical  solutions  to  the  problem  ofmechanical  arbitrage  have  the  potential  to  significantly  thwart  thesepractices.  Our  work  provides  the  first  overview  of  the  threat  landscape,  modelsfair  markets  and  their  security  assumptions,  and  discusses  various  mitigationmeasures.</p>|2019-04-01  22:52:19.488499
http://arxiv.org/abs/1903.12466|Distributed  Ledger  Technology  for  Smart  Mobility:  Variable  Delay  Models.  (arXiv:1903.12466v1  [cs.SY])|<p>Recently,  Directed  Acyclic  Graph  (DAG)  based  Distributed  Ledgers  have  beenproposed  for  various  applications  in  the  smart  mobility  domain  [1].  While  manyapplication  studies  have  been  described  in  the  literature,  an  open  problem  inthe  DLT  community  concerns  the  lack  of  mathematical  models  describing  theirbehaviour,  and  their  validation.  Building  on  a  previous  work  in  [1],  wepresent,  in  this  paper,  a  fluid  based  approximation  for  the  IOTA  Foundation  DAGbased  DLT  that  incorporates  varying  transaction  delays.  This  extension,  namelythe  inclusion  of  varying  delays,  is  important  for  feedback  control  applications(such  as  transactive  control  [2]).  Extensive  simulations  are  presented  toillustrate  the  efficacy  of  our  approach.</p>|2019-04-01  22:52:19.488531
http://arxiv.org/abs/1903.12467|Deep,  spatially  coherent  Occupancy  Maps  based  on  Radar  Measurements.  (arXiv:1903.12467v1  [cs.RO])|<p>One  essential  step  to  realize  modern  driver  assistance  technology  is  theaccurate  knowledge  about  the  location  of  static  objects  in  the  environment.  Inthis  work,  we  use  artificial  neural  networks  to  predict  the  occupation  state  ofa  whole  scene  in  an  end-to-end  manner.  This  stands  in  contrast  to  thetraditional  approach  of  accumulating  each  detection's  influence  on  theoccupancy  state  and  allows  to  learn  spatial  priors  which  can  be  used  tointerpolate  the  environment's  occupancy  state.  We  show  that  these  priors  makeour  method  suitable  to  predict  dense  occupancy  estimations  from  sparse,  highlyuncertain  inputs,  as  given  by  automotive  radars,  even  for  complex  urbanscenarios.  Furthermore,  we  demonstrate  that  these  estimations  can  be  used  forlarge-scale  mapping  applications.</p>|2019-04-01  22:52:19.488562
http://arxiv.org/abs/1903.12468|Automatic  Failure  Explanation  in  CPS  Models.  (arXiv:1903.12468v1  [cs.SE])|<p>Debugging  Cyber-Physical  System  (CPS)  models  can  be  extremely  complex.Indeed,  only  the  detection  of  a  failure  is  insuffcient  to  know  how  to  correct  afaulty  model.  Faults  can  propagate  in  time  and  in  space  producing  observablemisbehaviours  in  locations  completely  different  from  the  location  of  the  fault.Understanding  the  reason  of  an  observed  failure  is  typically  a  challenging  andlaborious  task  left  to  the  experience  and  domain  knowledge  of  the  designer.  \nIn  this  paper,  we  propose  CPSDebug,  a  novel  approach  that  by  combining  testing,specification  mining,  and  failure  analysis,  can  automatically  explain  failuresin  Simulink/Stateflow  models.  We  evaluate  CPSDebug  on  two  case  studies,involving  two  use  scenarios  and  several  classes  of  faults,  demonstrating  thepotential  value  of  our  approach.</p>|2019-04-01  22:52:19.488596
http://arxiv.org/abs/1903.12469|Corrigendum  to  "Counting  Database  Repairs  that  Satisfy  Conjunctive  Queries  with  Self-Joins".  (arXiv:1903.12469v1  [cs.DB])|<p>The  helping  Lemma  7  in  [Maslowski  and  Wijsen,  ICDT,  2014]  is  false.  The  lemmais  used  in  (and  only  in)  the  proof  of  Theorem  3  of  that  same  paper.  In  thiscorrigendum,  we  provide  a  new  proof  for  the  latter  theorem.</p>|2019-04-01  22:52:19.488627
http://arxiv.org/abs/1903.12470|Trustworthy  Experimentation  Under  Telemetry  Loss.  (arXiv:1903.12470v1  [cs.OH])|<p>Failure  to  accurately  measure  the  outcomes  of  an  experiment  can  lead  to  biasand  incorrect  conclusions.  Online  controlled  experiments  (aka  AB  tests)  areincreasingly  being  used  to  make  decisions  to  improve  websites  as  well  as  mobileand  desktop  applications.  We  argue  that  loss  of  telemetry  data  (during  uploador  post-processing)  can  skew  the  results  of  experiments,  leading  to  loss  ofstatistical  power  and  inaccurate  or  erroneous  conclusions.  By  systematicallyinvestigating  the  causes  of  telemetry  loss,  we  argue  that  it  is  not  practicalto  entirely  eliminate  it.  Consequently,  experimentation  systems  need  to  berobust  to  its  effects.  Furthermore,  we  note  that  it  is  nontrivial  to  measurethe  absolute  level  of  telemetry  loss  in  an  experimentation  system.  In  thispaper,  we  take  a  top-down  approach  towards  solving  this  problem.  We  motivatethe  impact  of  loss  qualitatively  using  experiments  in  real  applicationsdeployed  at  scale,  and  formalize  the  problem  by  presenting  a  theoreticalbreakdown  of  the  bias  introduced  by  loss.  Based  on  this  foundation,  we  presenta  general  framework  for  quantitatively  evaluating  the  impact  of  telemetry  loss,and  present  two  solutions  to  measure  the  absolute  levels  of  loss.  Thisframework  is  used  by  well-known  applications  at  Microsoft,  with  millions  ofusers  and  billions  of  sessions.  These  general  principles  can  be  adopted  by  anyapplication  to  improve  the  overall  trustworthiness  of  experimentation  anddata-driven  decision  making.</p>|2019-04-01  22:52:19.488659
http://arxiv.org/abs/1903.12472|Real-Time  Remote  Estimation  with  Hybrid  ARQ  in  Wireless  Networked  Control.  (arXiv:1903.12472v1  [cs.IT])|<p>Real-time  remote  estimation  is  critical  for  mission-critical  applicationsincluding  industrial  automation,  smart  grid  and  tactile  Internet.  In  thispaper,  we  propose  a  hybrid  automatic  repeat  request  (HARQ)-based  real-timeremote  estimation  framework  for  linear  time-invariant  (LTI)  dynamic  systems.Considering  the  estimation  quality  of  such  a  system,  there  is  a  fundamentaltradeoff  between  the  reliability  and  freshness  of  the  sensor's  measurementtransmission.  We  formulate  a  new  problem  to  optimize  the  sensor's  onlinetransmission  control  policy  for  static  and  Markov  fading  channels,  whichdepends  on  both  the  current  estimation  quality  of  the  remote  estimator  and  thecurrent  number  of  retransmissions  of  the  sensor,  so  as  to  minimize  thelong-term  remote  estimation  mean  squared  error  (MSE).  This  problem  isnon-trivial.  In  particular,  it  is  challenging  to  derive  the  condition  in  termsof  the  communication  channel  quality  and  the  LTI  system  parameters,  to  ensure  abounded  long-term  estimation  MSE.  We  derive  an  elegant  sufficient  condition  ofthe  existence  of  a  stationary  and  deterministic  optimal  policy  that  stabilizesthe  remote  estimation  system  and  minimizes  the  MSE.  Also,  we  prove  that  theoptimal  policy  has  a  switching  structure,  and  accordingly  derive  alow-complexity  suboptimal  policy.  Numerical  results  show  that  the  proposedoptimal  policy  significantly  improves  the  performance  of  the  remote  estimationsystem  compared  to  the  conventional  non-HARQ  policy.</p>|2019-04-01  22:52:19.488692
http://arxiv.org/abs/1903.12473|Shape  Robust  Text  Detection  with  Progressive  Scale  Expansion  Network.  (arXiv:1903.12473v1  [cs.CV])|<p>Scene  text  detection  has  witnessed  rapid  progress  especially  with  the  recentdevelopment  of  convolutional  neural  networks.  However,  there  still  exists  twochallenges  which  prevent  the  algorithm  into  industry  applications.  On  the  onehand,  most  of  the  state-of-art  algorithms  require  quadrangle  bounding  box  whichis  in-accurate  to  locate  the  texts  with  arbitrary  shape.  On  the  other  hand,  twotext  instances  which  are  close  to  each  other  may  lead  to  a  false  detectionwhich  covers  both  instances.  Traditionally,  the  segmentation-based  approach  canrelieve  the  first  problem  but  usually  fail  to  solve  the  second  challenge.  Toaddress  these  two  challenges,  in  this  paper,  we  propose  a  novel  ProgressiveScale  Expansion  Network  (PSENet),  which  can  precisely  detect  text  instanceswith  arbitrary  shapes.  More  specifically,  PSENet  generates  the  different  scaleof  kernels  for  each  text  instance,  and  gradually  expands  the  minimal  scalekernel  to  the  text  instance  with  the  complete  shape.  Due  to  the  fact  that  thereare  large  geometrical  margins  among  the  minimal  scale  kernels,  our  method  iseffective  to  split  the  close  text  instances,  making  it  easier  to  usesegmentation-based  methods  to  detect  arbitrary-shaped  text  instances.  Extensiveexperiments  on  CTW1500,  Total-Text,  ICDAR  2015  and  ICDAR  2017  MLT  validate  theeffectiveness  of  PSENet.  Notably,  on  CTW1500,  a  dataset  full  of  long  curvetexts,  PSENet  achieves  a  F-measure  of  74.3%  at  27  FPS,  and  our  best  F-measure(82.2%)  outperforms  state-of-art  algorithms  by  6.6%.  The  code  will  be  releasedin  the  future.</p>|2019-04-01  22:52:19.488725
http://arxiv.org/abs/1903.12476|DNA:  Deeply-supervised  Nonlinear  Aggregation  for  Salient  Object  Detection.  (arXiv:1903.12476v1  [cs.CV])|<p>Recent  progress  on  salient  object  detection  mainly  aims  at  exploiting  how  toeffectively  integrate  multi-scale  convolutional  features  in  convolutionalneural  networks  (CNNs).  Many  state-of-the-art  methods  impose  deep  supervisionto  perform  side-output  predictions  that  are  linearly  aggregated  for  finalsaliency  prediction.  In  this  paper,  we  theoretically  and  experimentallydemonstrate  that  linear  aggregation  of  side-output  predictions  is  suboptimal,and  it  only  makes  limited  use  of  the  side-output  information  obtained  by  deepsupervision.  To  solve  this  problem,  we  propose  Deeply-supervised  NonlinearAggregation  (DNA)  for  better  leveraging  the  complementary  information  ofvarious  side-outputs.  Compared  with  existing  methods,  it  i)  aggregatesside-output  features  rather  than  predictions,  and  ii)  adopts  nonlinear  insteadof  linear  transformations.  Experiments  demonstrate  that  DNA  can  successfullybreak  through  the  bottleneck  of  current  linear  approaches.  Specifically,  theproposed  saliency  detector,  a  modified  U-Net  architecture  with  DNA,  performsfavorably  against  state-of-the-art  methods  on  various  datasets  and  evaluationmetrics  without  bells  and  whistles.  Code  and  data  will  be  released  upon  paperacceptance.</p>|2019-04-01  22:52:19.488782
http://arxiv.org/abs/1903.12480|Data-driven  multiscale  decompositions  for  forecasting  and  model  discovery.  (arXiv:1903.12480v1  [cs.SY])|<p>We  present  a  data-driven  method  for  separating  complex,  multiscale  systemsinto  their  constituent  time-scale  components  using  a  recursive  implementationof  dynamic  mode  decomposition  (DMD).  Local  linear  models  are  built  fromwindowed  subsets  of  the  data,  and  dominant  time  scales  are  discovered  usingspectral  clustering  on  their  eigenvalues.  This  approach  produces  time  seriesdata  for  each  identified  component,  which  sum  to  a  faithful  reconstruction  ofthe  input  signal.  It  differs  from  most  other  methods  in  the  field  ofmultiresolution  analysis  (MRA)  in  that  it  1)  accounts  for  spatial  and  temporalcoherencies  simultaneously,  making  it  more  robust  to  scale  overlap  betweencomponents,  and  2)  yields  a  closed-form  expression  for  local  dynamics  at  eachscale,  which  can  be  used  for  short-term  prediction  of  any  or  all  components.Our  technique  is  an  extension  of  multi-resolution  dynamic  mode  decomposition(mrDMD),  generalized  to  treat  a  broader  variety  of  multiscale  systems  and  morefaithfully  reconstruct  their  isolated  components.  In  this  paper  we  present  anoverview  of  our  algorithm  and  its  results  on  two  example  physical  systems,  andbriefly  discuss  some  advantages  and  potential  forecasting  applications  for  thetechnique.</p>|2019-04-01  22:52:19.488818
http://arxiv.org/abs/1903.12482|COFFEE  -  An  MPI-parallelized  Python  package  for  the  numerical  evolution  of  differential  equations.  (arXiv:1903.12482v1  [cs.MS])|<p>COFFEE  (ConFormal  Field  Equation  Evolver)  is  a  Python  package  primarilydeveloped  to  numerically  evolve  systems  of  partial  differential  equations  overtime  using  the  method  of  lines.  It  includes  a  variety  of  time  integrators  andfinite  differencing  stencils  with  the  summation-by-parts  property,  as  well  aspseudo-spectral  functionality  for  angular  derivatives  of  spin-weightedfunctions.  Some  additional  capabilities  include  being  MPI-parallelisable  onavariety  of  different  geometries,  HDF  data  output  and  post  processing  scriptsto  visualize  data,  and  an  actions  class  that  allows  users  to  create  code  foranalysis  after  each  timestep.</p>|2019-04-01  22:52:19.488851
http://arxiv.org/abs/1903.12483|Online  Multi-target  regression  trees  with  stacked  leaf  models.  (arXiv:1903.12483v1  [cs.LG])|<p>The  amount  of  available  data  raises  at  large  steps.  Developing  machinelearning  strategies  to  cope  with  the  high  throughput  and  changing  data  streamsis  a  scope  of  high  relevance.  Among  the  prediction  tasks  in  online  machinelearning,  multi-target  regression  has  gained  increased  attention  due  to  itshigh  applicability  and  relation  with  real-world  problems.  While  reliable  andeffective  solutions  have  been  proposed  for  batch  multi-target  regression,  thefew  existing  solutions  in  the  online  scenario  present  gaps  which  should  befurther  investigated.  Among  these  problems,  none  of  the  existing  solutionsconsider  the  occurrence  of  inter-target  correlations  when  making  predictions.In  this  work,  we  propose  an  extension  to  existing  decision  tree  based  solutionsin  online  multi-target  regression  which  tackles  the  problem  mentioned  above.Our  proposal,  called  Stacked  Single-target  Hoeffding  Tree  (SST-HT)  uses  theinter-target  dependencies  as  an  additional  information  source  to  enhanceaccuracy.  Throughout  an  extensive  experimental  setup,  we  evaluate  our  proposalagainst  state-of-the-art  decision  tree-based  solutions  for  online  multi-targetregression  tasks  on  sixteen  datasets.  Our  observations  show  that  SST-HT  iscapable  of  achieving  significantly  smaller  errors  than  the  other  methods,whereas  only  increasing  the  needed  time  and  memory  requirements  in  smallamounts.</p>|2019-04-01  22:52:19.488884
http://arxiv.org/abs/1903.12487|Network  Structure  Effects  in  Reservoir  Computers.  (arXiv:1903.12487v1  [cs.ET])|<p>A  reservoir  computer  is  a  complex  nonlinear  dynamical  system  that  has  beenshown  to  be  useful  for  solving  certain  problems,  such  as  prediction  of  chaoticsignals,  speech  recognition  or  control  of  robotic  systems.  Typically  areservoir  computer  is  constructed  by  connecting  a  large  number  of  nonlinearnodes  in  a  network,  driving  the  nodes  with  an  input  signal  and  using  the  nodeoutputs  to  fit  a  training  signal.  In  this  work,  we  set  up  reservoirs  where  theedges  (or  connections)  between  all  the  network  nodes  are  either  +1  or  0,  andproceed  to  alter  the  network  structure  by  flipping  some  of  these  edges  from  +1to  -1.  We  use  this  simple  network  because  it  turns  out  to  be  easy  tocharacterize;  we  may  use  the  fraction  of  edges  flipped  as  a  measure  of  how  muchwe  have  altered  the  network.  In  some  cases,  the  network  can  be  rearranged  in  afinite  number  of  ways  without  changing  its  structure;  these  rearrangements  aresymmetries  of  the  network,  and  the  number  of  symmetries  is  also  useful  forcharacterizing  the  network.  We  find  that  changing  the  number  of  edges  flippedin  the  network  changes  the  rank  of  the  covariance  of  a  matrix  consisting  of  thetime  series  from  the  different  nodes  in  the  network,  and  speculate  that  thisrank  is  important  for  understanding  the  reservoir  computer  performance.</p>|2019-04-01  22:52:19.488916
http://arxiv.org/abs/1903.12489|Cross-Subject  Transfer  Learning  in  Human  Activity  Recognition  Systems  using  Generative  Adversarial  Networks.  (arXiv:1903.12489v1  [cs.LG])|<p>Application  of  intelligent  systems  especially  in  smart  homes  andhealth-related  topics  has  been  drawing  more  attention  in  the  last  decades.Training  Human  Activity  Recognition  (HAR)  models  --  as  a  major  module  --requires  a  fair  amount  of  labeled  data.  Despite  training  with  large  datasets,most  of  the  existing  models  will  face  a  dramatic  performance  drop  when  they  aretested  against  unseen  data  from  new  users.  Moreover,  recording  enough  data  foreach  new  user  is  unviable  due  to  the  limitations  and  challenges  of  working  withhuman  users.  Transfer  learning  techniques  aim  to  transfer  the  knowledge  whichhas  been  learned  from  the  source  domain  (subject)  to  the  target  domain  in  orderto  decrease  the  models'  performance  loss  in  the  target  domain.  This  paperpresents  a  novel  method  of  adversarial  knowledge  transfer  named  SA-GAN  standsfor  Subject  Adaptor  GAN  which  utilizes  Generative  Adversarial  Network  frameworkto  perform  cross-subject  transfer  learning  in  the  domain  of  wearablesensor-based  Human  Activity  Recognition.  SA-GAN  outperformed  otherstate-of-the-art  methods  in  more  than  66%  of  experiments  and  showed  the  secondbest  performance  in  the  remaining  25%  of  experiments.  In  some  cases,  it  reachedup  to  90%  of  the  accuracy  which  can  be  obtained  by  supervised  training  over  thesame  domain  data.</p>|2019-04-01  22:52:19.488949
http://arxiv.org/abs/1903.12493|Asymmetric  Deep  Semantic  Quantization  for  Image  Retrieval.  (arXiv:1903.12493v1  [cs.CV])|<p>Due  to  its  fast  retrieval  and  storage  efficiency  capabilities,  hashing  hasbeen  widely  used  in  nearest  neighbor  retrieval  tasks.  By  using  deep  learningbased  techniques,  hashing  can  outperform  non-learning  based  hashing  in  manyapplications.  However,  there  are  some  limitations  to  previous  learning  basedhashing  methods  (e.g.,  the  learned  hash  codes  are  not  discriminative  due  to  thehashing  methods  being  unable  to  discover  rich  semantic  information  and  thetraining  strategy  having  difficulty  optimizing  the  discrete  binary  codes).  Inthis  paper,  we  propose  a  novel  learning  based  hashing  method,  named\textbf{\underline{A}}symmetric  \textbf{\underline{D}}eep\textbf{\underline{S}}emantic  \textbf{\underline{Q}}uantization(\textbf{ADSQ}).  \textbf{ADSQ}  is  implemented  using  three  stream  frameworks,which  consists  of  one  \emph{LabelNet}  and  two  \emph{ImgNets}.  The\emph{LabelNet}  leverages  three  fully-connected  layers,  which  is  used  tocapture  rich  semantic  information  between  image  pairs.  For  the  two\emph{ImgNets},  they  each  adopt  the  same  convolutional  neural  networkstructure,  but  with  different  weights  (i.e.,  asymmetric  convolutional  neuralnetworks).  The  two  \emph{ImgNets}  are  used  to  generate  discriminative  compacthash  codes.  Specifically,  the  function  of  the  \emph{LabelNet}  is  to  capturerich  semantic  information  that  is  used  to  guide  the  two  \emph{ImgNets}  inminimizing  the  gap  between  the  real-continuous  features  and  discrete  binarycodes.  By  doing  this,  \textbf{ADSQ}  can  make  full  use  of  the  most  criticalsemantic  information  to  guide  the  feature  learning  process  and  consider  theconsistency  of  the  common  semantic  space  and  Hamming  space.  Results  from  ourexperiments  demonstrate  that  \textbf{ADSQ}  can  generate  high  discriminativecompact  hash  codes  and  it  outperforms  current  state-of-the-art  methods  on  threebenchmark  datasets,  CIFAR-10,  NUS-WIDE,  and  ImageNet.</p>|2019-04-01  22:52:19.488982
http://arxiv.org/abs/1903.12495|Crowd  Sourced  Data  Analysis:  Mapping  of  Programming  Concepts  to  Syntactical  Patterns.  (arXiv:1903.12495v1  [cs.IR])|<p>Since  programming  concepts  do  not  match  their  syntactic  representations,  codesearch  is  a  very  tedious  task.  For  instance  in  Java  or  C,  array  doesn't  match[],  so  using  "array"  as  a  query,  one  cannot  find  what  they  are  looking  for.Often  developers  have  to  search  code  whether  to  understand  any  code,  or  toreuse  some  part  of  that  code,  or  just  to  read  it,  without  natural  languagesearching,  developers  have  to  often  scroll  back  and  forth  or  use  variable  namesas  their  queries.  In  our  work,  we  have  used  Stackoverflow  (SO)  question  andanswers  to  make  a  mapping  of  programming  concepts  with  their  respective  naturallanguage  keywords,  and  then  tag  these  natural  language  terms  to  every  line  ofcode,  which  can  further  we  used  in  searching  using  natural  language  keywords.</p>|2019-04-01  22:52:19.489035
http://arxiv.org/abs/1903.12497|A  Stochastic  Model  Predictive  Control  Approach  for  Driver-Aided  Intersection  Crossing  With  Uncertain  Driver  Time  Delay.  (arXiv:1903.12497v1  [math.OC])|<p>We  investigate  the  problem  of  coordinating  human-driven  vehicles  in  roadintersections  without  any  traffic  lights  or  signs  by  issuing  speed  advices.  Thevehicles  in  the  intersection  are  assumed  to  move  along  an  a  priori  known  pathand  to  be  connected  via  vehicle-to-vehicle  communication.  The  challenge  ariseswith  the  uncertain  driver  reaction  to  a  speed  advice,  especially  in  terms  ofthe  driver  reaction  time  delay,  as  it  might  lead  to  unstable  system  dynamics.For  this  control  problem,  a  distributed  stochastic  model  predictive  controlconcept  is  designed  which  accounts  for  driver  uncertainties.  By  optimizing  overscenarios,  which  are  sequences  of  independent  and  identically  distributedsamples  of  the  uncertainty  over  the  prediction  horizon,  we  can  giveprobabilistic  guarantees  on  constraint  satisfaction.  Simulation  resultsdemonstrate  that  the  scenario-based  approach  is  able  to  avoid  collisions  inspite  of  uncertainty  while  the  non-stochastic  baseline  controller  is  not.</p>|2019-04-01  22:52:19.489070
http://arxiv.org/abs/1903.12505|BootKeeper:  Validating  Software  Integrity  Properties  on  Boot  Firmware  Images.  (arXiv:1903.12505v1  [cs.CR])|<p>Boot  firmware,  like  UEFI-compliant  firmware,  has  been  the  target  of  numerousattacks,  giving  the  attacker  control  over  the  entire  system  while  beingundetected.  The  measured  boot  mechanism  of  a  computer  platform  ensures  itsintegrity  by  using  cryptographic  measurements  to  detect  such  attacks.  This  istypically  performed  by  relying  on  a  Trusted  Platform  Module  (TPM).  Recent  work,however,  shows  that  vendors  do  not  respect  the  specifications  that  have  beendevised  to  ensure  the  integrity  of  the  firmware's  loading  process.  As  a  result,attackers  may  bypass  such  measurement  mechanisms  and  successfully  load  amodified  firmware  image  while  remaining  unnoticed.  In  this  paper  we  introduceBootKeeper,  a  static  analysis  approach  verifying  a  set  of  key  securityproperties  on  boot  firmware  images  before  deployment,  to  ensure  the  integrityof  the  measured  boot  process.  We  evaluate  BootKeeper  against  several  attacks  oncommon  boot  firmware  implementations  and  demonstrate  its  applicability.</p>|2019-04-01  22:52:19.489102
http://arxiv.org/abs/1903.12508|A  Local  Approach  to  Forward  Model  Learning:  Results  on  the  Game  of  Life  Game.  (arXiv:1903.12508v1  [cs.AI])|<p>This  paper  investigates  the  effect  of  learning  a  forward  model  on  theperformance  of  a  statistical  forward  planning  agent.  We  transform  Conway's  Gameof  Life  simulation  into  a  single-player  game  where  the  objective  can  be  eitherto  preserve  as  much  life  as  possible  or  to  extinguish  all  life  as  quickly  aspossible.</p><p>In  order  to  learn  the  forward  model  of  the  game,  we  formulate  the  problem  ina  novel  way  that  learns  the  local  cell  transition  function  by  creating  a  set  ofsupervised  training  data  and  predicting  the  next  state  of  each  cell  in  the  gridbased  on  its  current  state  and  immediate  neighbours.  Using  this  method  we  areable  to  harvest  sufficient  data  to  learn  perfect  forward  models  by  observingonly  a  few  complete  state  transitions,  using  either  a  look-up  table,  a  decisiontree  or  a  neural  network.</p><p>In  contrast,  learning  the  complete  state  transition  function  is  a  much  hardertask  and  our  initial  efforts  to  do  this  using  deep  convolutional  auto-encoderswere  less  successful.</p><p>We  also  investigate  the  effects  of  imperfect  learned  models  on  predictionerrors  and  game-playing  performance,  and  show  that  even  models  with  significanterrors  can  provide  good  performance.</p>|2019-04-01  22:52:19.489153
http://arxiv.org/abs/1903.12509|Exploring  Micro-Services  for  Enhancing  Internet  QoS.  (arXiv:1903.12509v1  [cs.NI])|<p>With  the  enhancements  in  the  field  of  software-defined  networking  andvirtualization  technologies,  novel  networking  paradigms  such  as  networkfunction  virtualization  (NFV)  and  the  Internet  of  things  (IoT)  are  rapidlygaining  ground.  Development  of  IoT  as  well  as  5G  networks  and  explosion  inonline  services  has  resulted  in  an  exponential  growth  of  devices  connected  tothe  network.  As  a  result,  application  service  providers  (ASPs)  and  Internetservice  providers  (ISPs)  are  being  confronted  with  the  unprecedented  challengeof  accommodating  increasing  service  and  traffic  demands  from  the  geographicallydistributed  users.  To  tackle  this  problem,  many  ASPs  and  ISPs,  such  as  Netflix,Facebook,  AT&amp;T  and  others  are  increasingly  adopting  micro-services  (MS)application  architecture.  Despite  the  success  of  MS  in  the  industry,  there  isno  specific  standard  or  research  work  for  service  providers  as  guidelines,especially  from  the  perspective  of  basic  micro-service  operations.  In  thiswork,  we  aim  to  bridge  this  gap  between  industry  and  academia  and  discussdifferent  micro-service  deployment,  discovery  and  communication  options  forservice  providers  as  a  means  to  forming  complete  service  chains.  In  addition,we  address  the  problem  of  scheduling  micro-services  across  multiple  clouds,including  micro-clouds.  We  consider  different  user-level  SLAs,  such  as  latencyand  cost,  while  scheduling  such  services.  We  aim  to  reduce  overall  turnaroundtime  as  well  as  costs  for  the  deployment  of  complete  end-to-end  service.  Inthis  work,  we  present  a  novel  affinity-based  fair  weighted  scheduling  heuristicto  solve  this  problem.  We  also  compare  the  results  of  proposed  solution  withstandard  greedy  scheduling  algorithms  presented  in  the  literature  and  observesignificant  improvements.</p>|2019-04-01  22:52:19.489184
http://arxiv.org/abs/1903.12510|Degrees  of  Laziness  in  Grounding:  Effects  of  Lazy-Grounding  Strategies  on  ASP  Solving.  (arXiv:1903.12510v1  [cs.AI])|<p>The  traditional  ground-and-solve  approach  to  Answer  Set  Programming  (ASP)suffers  from  the  grounding  bottleneck,  which  makes  large-scale  probleminstances  unsolvable.  Lazy  grounding  is  an  alternative  approach  thatinterleaves  grounding  with  solving  and  thus  uses  space  more  efficiently.  Thelimited  view  on  the  search  space  in  lazy  grounding  poses  unique  challenges,however,  and  can  have  adverse  effects  on  solving  performance.  In  this  paper  wepresent  a  novel  characterization  of  degrees  of  laziness  in  grounding  for  ASP,i.e.  of  compromises  between  lazily  grounding  as  little  as  possible  and  thetraditional  full  grounding  upfront.  We  investigate  how  these  degrees  oflaziness  compare  to  each  other  formally  as  well  as,  by  means  of  an  experimentalanalysis  using  a  number  of  benchmarks,  in  terms  of  their  effects  on  solvingperformance.  Our  contributions  are  the  introduction  of  a  range  of  novel  lazygrounding  strategies,  a  formal  account  on  their  relationships  and  theircorrectness,  and  an  investigation  of  their  effects  on  solving  performance.Experiments  show  that  our  approach  performs  significantly  better  thanstate-of-the-art  lazy  grounding  in  many  cases.</p>|2019-04-01  22:52:19.489215
http://arxiv.org/abs/1903.12514|Evaluating  Built-in  ECC  of  FPGA  on-chip  Memories  for  the  Mitigation  of  Undervolting  Faults.  (arXiv:1903.12514v1  [cs.AR])|<p>Voltage  underscaling  below  the  nominal  level  is  an  effective  solution  forimproving  energy  efficiency  in  digital  circuits,  e.g.,  Field  Programmable  GateArrays  (FPGAs).  However,  further  undervolting  below  a  safe  voltage  level  andwithout  accompanying  frequency  scaling  leads  to  timing  related  faults,potentially  undermining  the  energy  savings.  Through  experimental  voltageunderscaling  studies  on  commercial  FPGAs,  we  observed  that  the  rate  of  thesefaults  exponentially  increases  for  on-chip  memories,  or  Block  RAMs  (BRAMs).  Tomitigate  these  faults,  we  evaluated  the  efficiency  of  the  built-inError-Correction  Code  (ECC)  and  observed  that  more  than  90%  of  the  faults  arecorrectable  and  further  7%  are  detectable  (but  not  correctable).  Thisefficiency  is  the  result  of  the  single-bit  type  of  these  faults,  which  are  theneffectively  covered  by  the  Single-Error  Correction  and  Double-Error  Detection(SECDED)  design  of  the  built-in  ECC.  Finally,  motivated  by  the  aboveexperimental  observations,  we  evaluated  an  FPGA-based  Neural  Network  (NN)accelerator  under  low-voltage  operations,  while  built-in  ECC  is  leveraged  tomitigate  undervolting  faults  and  thus,  prevent  NN  significant  accuracy  loss.  Inconsequence,  we  achieve  40%  of  the  BRAM  power  saving  through  undervolting  belowthe  minimum  safe  voltage  level,  with  a  negligible  NN  accuracy  loss,  thanks  tothe  substantial  fault  coverage  by  the  built-in  ECC.</p>|2019-04-01  22:52:19.489246
http://arxiv.org/abs/1903.12516|Ham-Sandwich  cuts  and  center  transversals  in  subspaces.  (arXiv:1903.12516v1  [cs.CG])|<p>The  Ham-Sandwich  theorem  is  a  well-known  result  in  geometry.  It  states  thatany  $d$  mass  distributions  in  $\mathbb{R}^d$  can  be  simultaneously  bisected  bya  hyperplane.  The  result  is  tight,  that  is,  there  are  examples  of  $d+1$  massdistributions  that  cannot  be  simultaneously  bisected  by  a  single  hyperplane.  Inthis  abstract  we  will  study  the  following  question:  given  a  continuousassignment  of  mass  distributions  to  certain  subsets  of  $\mathbb{R}^d$,  is  therea  subset  on  which  we  can  bisect  more  masses  than  what  is  guaranteed  by  theHam-Sandwich  theorem?</p><p>We  investigate  two  types  of  subsets.  The  first  type  are  linear  subspaces  of$\mathbb{R}^d$,  i.e.,  $k$-dimensional  flats  containing  the  origin.  We  show  thatfor  any  continuous  assignment  of  $d$  mass  distributions  to  the  $k$-dimensionallinear  subspaces  of  $\mathbb{R}^d$,  there  is  always  a  subspace  on  which  we  cansimultaneously  bisect  the  images  of  all  $d$  assignments.  We  extend  this  resultto  center  transversals,  a  generalization  of  Ham-Sandwich  cuts.  As  forHam-Sandwich  cuts,  we  further  show  that  for  $d-k+2$  masses,  we  can  choose  $k-1$of  the  vectors  defining  the  $k$-dimensional  subspace  in  which  the  solutionlies.</p><p>The  second  type  of  subsets  we  consider  are  subsets  that  are  determined  byfamilies  of  $n$  hyperplanes  in  $\mathbb{R}^d$.  Also  in  this  case,  we  find  aHam-Sandwich-type  result.  In  an  attempt  to  solve  a  conjecture  by  Langermanabout  bisections  with  several  cuts,  we  show  that  our  underlying  topologicalresult  can  be  used  to  prove  this  conjecture  in  a  relaxed  setting.</p>|2019-04-01  22:52:19.489277
http://arxiv.org/abs/1903.12517|Towards  Brain-inspired  System:  Deep  Recurrent  Reinforcement  Learning  for  Simulated  Self-driving  Agent.  (arXiv:1903.12517v1  [cs.AI])|<p>An  effective  way  to  achieve  intelligence  is  to  simulate  various  intelligentbehaviors  in  the  human  brain.  In  recent  years,  bio-inspired  learning  methodshave  emerged,  and  they  are  different  from  the  classical  mathematicalprogramming  principle.  In  the  perspective  of  brain  inspiration,  reinforcementlearning  has  gained  additional  interest  in  solving  decision-making  tasks  asincreasing  neuroscientific  research  demonstrates  that  significant  links  existbetween  reinforcement  learning  and  specific  neural  substrates.  Because  of  thetremendous  research  that  focuses  on  human  brains  and  reinforcement  learning,scientists  have  investigated  how  robots  can  autonomously  tackle  complex  tasksin  the  form  of  a  self-driving  agent  control  in  a  human-like  way.  In  this  study,we  propose  an  end-to-end  architecture  using  novel  deep-Q-network  architecturein  conjunction  with  a  recurrence  to  resolve  the  problem  in  the  field  ofsimulated  self-driving.  The  main  contribution  of  this  study  is  that  we  trainedthe  driving  agent  using  a  brain-inspired  trial-and-error  technique,  which  wasin  line  with  the  real  world  situation.  Besides,  there  are  three  innovations  inthe  proposed  learning  network:  raw  screen  outputs  are  the  only  informationwhich  the  driving  agent  can  rely  on,  a  weighted  layer  that  enhances  thedifferences  of  the  lengthy  episode,  and  a  modified  replay  mechanism  thatovercomes  the  problem  of  sparsity  and  accelerates  learning.  The  proposednetwork  was  trained  and  tested  under  a  third-partied  OpenAI  Gym  environment.After  training  for  several  episodes,  the  resulting  driving  agent  performedadvanced  behaviors  in  the  given  scene.  We  hope  that  in  the  future,  the  proposedbrain-inspired  learning  system  would  inspire  practicable  self-driving  controlsolutions.</p>|2019-04-01  22:52:19.489308
http://arxiv.org/abs/1903.12519|A  Provable  Defense  for  Deep  Residual  Networks.  (arXiv:1903.12519v1  [cs.LG])|<p>We  present  a  training  system,  which  can  provably  defend  significantly  largerneural  networks  than  previously  possible,  including  ResNet-34  and  DenseNet-100.Our  approach  is  based  on  differentiable  abstract  interpretation  and  introducestwo  novel  concepts:  (i)  abstract  layers  for  fine-tuning  the  precision  andscalability  of  the  abstraction,  (ii)  a  flexible  domain  specific  language  (DSL)for  describing  training  objectives  that  combine  abstract  and  concrete  losseswith  arbitrary  specifications.  Our  training  method  is  implemented  in  the  DiffAIsystem.</p>|2019-04-01  22:52:19.489338
http://arxiv.org/abs/1903.12520|Multimodal  Emotion  Classification.  (arXiv:1903.12520v1  [cs.CV])|<p>Most  NLP  and  Computer  Vision  tasks  are  limited  to  scarcity  of  labelled  data.In  social  media  emotion  classification  and  other  related  tasks,  hashtags  havebeen  used  as  indicators  to  label  data.  With  the  rapid  increase  in  emoji  usageof  social  media,  emojis  are  used  as  an  additional  feature  for  major  social  NLPtasks.  However,  this  is  less  explored  in  case  of  multimedia  posts  on  socialmedia  where  posts  are  composed  of  both  image  and  text.  At  the  same  time,  w.ehave  seen  a  surge  in  the  interest  to  incorporate  domain  knowledge  to  improvemachine  understanding  of  text.  In  this  paper,  we  investigate  whether  domainknowledge  for  emoji  can  improve  the  accuracy  of  emotion  classification  task.  Weexploit  the  importance  of  different  modalities  from  social  media  post  foremotion  classification  task  using  state-of-the-art  deep  learning  architectures.Our  experiments  demonstrate  that  the  three  modalities  (text,  emoji  and  images)encode  different  information  to  express  emotion  and  therefore  can  complementeach  other.  Our  results  also  demonstrate  that  emoji  sense  depends  on  thetextual  context,  and  emoji  combined  with  text  encodes  better  information  thanconsidered  separately.  The  highest  accuracy  of  71.98\%  is  achieved  with  atraining  data  of  550k  posts.</p>|2019-04-01  22:52:19.489369
http://arxiv.org/abs/1903.12525|Shed  More  Light  on  Bloom  Filter's  Variants.  (arXiv:1903.12525v1  [cs.DS])|<p>Bloom  Filter  is  a  probabilistic  membership  data  structure  and  it  isexcessively  used  data  structure  for  membership  query.  Bloom  Filter  becomes  thepredominant  data  structure  in  approximate  membership  filtering.  Bloom  Filterextremely  enhances  the  query  response  time,  and  the  response  time  is  very  fast.Bloom  filter  (BF)  is  used  to  detect  whether  an  element  belongs  to  a  given  setor  not.  The  Bloom  Filter  returns  True  Positive  (TP),  False  Positive  (FP),  orTrue  Negative  (TN).  The  Bloom  Filter  is  widely  adapted  in  numerous  areas  toenhance  the  performance  of  a  system.  In  this  paper,  we  present  a)  in-depthinsight  on  the  Bloom  Filter,and  b)  the  prominent  variants  of  the  Bloom  Filters.</p>|2019-04-01  22:52:19.489399
http://arxiv.org/abs/1903.12527|An  Upper  Bound  for  Minimum  True  Matches  in  Graph  Isomorphism  with  Simulated  Annealing.  (arXiv:1903.12527v1  [cs.NE])|<p>Graph  matching  is  one  of  the  most  important  problems  in  graph  theory  andcombinatorial  optimization,  with  many  applications  in  various  domains.  Althoughmeta-heuristic  algorithms  have  had  good  performance  on  many  NP-Hard  andNP-Complete  problems,  for  this  problem  there  are  not  reported  superiorsolutions  by  these  algorithms.  The  reason  of  this  inefficiency  has  not  beeninvestigated  yet.  In  this  paper  we  show  that  simulated  annealing  as  anstochastic  optimization  method  is  unlikely  to  be  even  close  to  the  optimalsolution  for  this  problem.  In  addition  to  theoretical  discussion,  theexperimental  results  also  verified  our  idea;  for  example,  in  two  sample  graphs,the  probability  of  reaching  to  a  solution  with  more  than  three  correct  matchesis  about  $0.02$  in  simulated  annealing.</p>|2019-04-01  22:52:19.489431
http://arxiv.org/abs/1903.12529|Deep  Plug-and-Play  Super-Resolution  for  Arbitrary  Blur  Kernels.  (arXiv:1903.12529v1  [cs.CV])|<p>While  deep  neural  networks  (DNN)  based  single  image  super-resolution  (SISR)methods  are  rapidly  gaining  popularity,  they  are  mainly  designed  for  thewidely-used  bicubic  degradation,  and  there  still  remains  the  fundamentalchallenge  for  them  to  super-resolve  low-resolution  (LR)  image  with  arbitraryblur  kernels.  In  the  meanwhile,  plug-and-play  image  restoration  has  beenrecognized  with  high  flexibility  due  to  its  modular  structure  for  easy  plug-inof  denoiser  priors.  In  this  paper,  we  propose  a  principled  formulation  andframework  by  extending  bicubic  degradation  based  deep  SISR  with  the  help  ofplug-and-play  framework  to  handle  LR  images  with  arbitrary  blur  kernels.Specifically,  we  design  a  new  SISR  degradation  model  so  as  to  take  advantage  ofexisting  blind  deblurring  methods  for  blur  kernel  estimation.  To  optimize  thenew  degradation  induced  energy  function,  we  then  derive  a  plug-and-playalgorithm  via  variable  splitting  technique,  which  allows  us  to  plug  anysuper-resolver  prior  rather  than  the  denoiser  prior  as  a  modular  part.Quantitative  and  qualitative  evaluations  on  synthetic  and  real  LR  imagesdemonstrate  that  the  proposed  deep  plug-and-play  super-resolution  framework  isflexible  and  effective  to  deal  with  blurry  LR  images.</p>|2019-04-01  22:52:19.489462
http://arxiv.org/abs/1903.12530|Photo-realistic  Monocular  Gaze  Redirection  using  Generative  Adversarial  Networks.  (arXiv:1903.12530v1  [cs.CV])|<p>Gaze  redirection  is  the  task  of  changing  the  gaze  to  a  desired  direction  fora  given  monocular  eye  patch  image.  Many  applications  such  as  videoconferencing,films  and  games,  and  generation  of  training  data  for  gaze  estimation  requireredirecting  the  gaze,  without  distorting  the  appearance  of  the  area  surroundingthe  eye  and  while  producing  photo-realistic  images.  Existing  methods  lack  theability  to  generate  perceptually  plausible  images.  In  this  work,  we  present  anovel  method  to  alleviate  this  problem  by  leveraging  generative  adversarialtraining  to  synthesize  an  eye  image  conditioned  on  a  target  gaze  direction.  Ourmethod  ensures  perceptual  similarity  and  consistency  of  synthesized  images  tothe  real  images.  Furthermore,  a  gaze  estimation  loss  is  used  to  control  thegaze  direction  accurately.  To  attain  high-quality  images,  we  incorporateperceptual  and  cycle  consistency  losses  into  our  architecture.  In  extensiveevaluations  we  show  that  the  proposed  method  outperforms  state-of-the-artapproaches  in  terms  of  both  image  quality  and  redirection  precision.  Finally,we  show  that  generated  images  can  bring  significant  improvement  for  the  gazeestimation  task  if  used  to  augment  real  training  data.</p>|2019-04-01  22:52:19.489492
http://arxiv.org/abs/1903.12536|Deep  Network  for  Capacitive  ECG  Denoising.  (arXiv:1903.12536v1  [cs.LG])|<p>Continuous  monitoring  of  cardiac  health  under  free  living  condition  iscrucial  to  provide  effective  care  for  patients  undergoing  post  operativerecovery  and  individuals  with  high  cardiac  risk  like  the  elderly.  CapacitiveElectrocardiogram  (cECG)  is  one  such  technology  which  allows  comfortable  andlong  term  monitoring  through  its  ability  to  measure  biopotential  in  conditionswithout  having  skin  contact.  cECG  monitoring  can  be  done  using  many  householdobjects  like  chairs,  beds  and  even  car  seats  allowing  for  seamless  monitoringof  individuals.  This  method  is  unfortunately  highly  susceptible  to  motionartifacts  which  greatly  limits  its  usage  in  clinical  practice.  The  current  useof  cECG  systems  has  been  limited  to  performing  rhythmic  analysis.  In  this  paperwe  propose  a  novel  end-to-end  deep  learning  architecture  to  perform  the  task  ofdenoising  capacitive  ECG.  The  proposed  network  is  trained  using  motioncorrupted  three  channel  cECG  and  a  reference  LEAD  I  ECG  collected  onindividuals  while  driving  a  car.  Further,  we  also  propose  a  novel  joint  lossfunction  to  apply  loss  on  both  signal  and  frequency  domain.  We  conductextensive  rhythmic  analysis  on  the  model  predictions  and  the  ground  truth.  Wefurther  evaluate  the  signal  denoising  using  Mean  Square  Error(MSE)  and  CrossCorrelation  between  model  predictions  and  ground  truth.  We  report  MSE  of  0.167and  Cross  Correlation  of  0.476.  The  reported  results  highlight  the  feasibilityof  performing  morphological  analysis  using  the  filtered  cECG.  The  proposedapproach  can  allow  for  continuous  and  comprehensive  monitoring  of  theindividuals  in  free  living  conditions.</p>|2019-04-01  22:52:19.489524
http://arxiv.org/abs/1903.12542|Re-Ranking  Words  to  Improve  Interpretability  of  Automatically  Generated  Topics.  (arXiv:1903.12542v1  [cs.CL])|<p>Topics  models,  such  as  LDA,  are  widely  used  in  Natural  Language  Processing.Making  their  output  interpretable  is  an  important  area  of  research  withapplications  to  areas  such  as  the  enhancement  of  exploratory  search  interfacesand  the  development  of  interpretable  machine  learning  models.  Conventionally,topics  are  represented  by  their  n  most  probable  words,  however,  theserepresentations  are  often  difficult  for  humans  to  interpret.  This  paperexplores  the  re-ranking  of  topic  words  to  generate  more  interpretable  topicrepresentations.  A  range  of  approaches  are  compared  and  evaluated  in  twoexperiments.  The  first  uses  crowdworkers  to  associate  topics  represented  bydifferent  word  rankings  with  related  documents.  The  second  experiment  is  anautomatic  approach  based  on  a  document  retrieval  task  applied  on  multipledomains.  Results  in  both  experiments  demonstrate  that  re-ranking  words  improvestopic  interpretability  and  that  the  most  effective  re-ranking  schemes  werethose  which  combine  information  about  the  importance  of  words  both  withintopics  and  their  relative  frequency  in  the  entire  corpus.  In  addition,  closecorrelation  between  the  results  of  the  two  evaluation  approaches  suggests  thatthe  automatic  method  proposed  here  could  be  used  to  evaluate  re-ranking  methodswithout  the  need  for  human  judgements.</p>|2019-04-01  22:52:19.489555
http://arxiv.org/abs/1903.12546|Robust  Data  Detection  for  MIMO  Systems  with  One-Bit  ADCs:  A  Reinforcement  Learning  Approach.  (arXiv:1903.12546v1  [eess.SP])|<p>The  use  of  one-bit  analog-to-digital  converters  (ADCs)  at  a  receiver  is  apower-efficient  solution  for  future  wireless  systems  operating  with  a  largesignal  bandwidth  and/or  a  massive  number  of  receive  radio  frequency  chains.This  solution,  however,  induces  a  high  channel  estimation  error  and  thereforemakes  it  difficult  to  perform  the  optimal  data  detection  that  requires  perfectknowledge  of  likelihood  functions  at  the  receiver.  In  this  paper,  we  propose  alikelihood  function  learning  method  for  multiple-input  multiple-output  (MIMO)systems  with  one-bit  ADCs  using  a  reinforcement  learning  approach.  The  key  ideais  to  exploit  input-output  samples  obtained  from  data  detection,  to  compensatethe  mismatch  in  the  likelihood  function.  The  underlying  difficulty  of  this  ideais  a  label  uncertainty  in  the  samples  caused  by  a  data  detection  error.  Toresolve  this  problem,  we  define  a  Markov  decision  process  (MDP)  to  maximize  theaccuracy  of  the  likelihood  function  learned  from  the  samples.  We  then  develop  areinforcement  learning  algorithm  that  efficiently  finds  the  optimal  policy  byapproximating  the  transition  function  and  the  optimal  state  of  the  MDP.Simulation  results  demonstrate  that  the  proposed  method  provides  significantperformance  gains  for  the  optimal  data  detection  methods  that  suffer  from  themismatch  in  the  likelihood  function.</p>|2019-04-01  22:52:19.489585
http://arxiv.org/abs/1903.12549|Probabilistic  Forecasting  of  Sensory  Data  with  Generative  Adversarial  Networks  -  ForGAN.  (arXiv:1903.12549v1  [cs.LG])|<p>Time  series  forecasting  is  one  of  the  challenging  problems  for  humankind.Traditional  forecasting  methods  using  mean  regression  models  have  severeshortcomings  in  reflecting  real-world  fluctuations.  While  new  probabilisticmethods  rush  to  rescue,  they  fight  with  technical  difficulties  like  quantilecrossing  or  selecting  a  prior  distribution.  To  meld  the  different  strengths  ofthese  fields  while  avoiding  their  weaknesses  as  well  as  to  push  the  boundary  ofthe  state-of-the-art,  we  introduce  ForGAN  -  one  step  ahead  probabilisticforecasting  with  generative  adversarial  networks.  ForGAN  utilizes  the  power  ofthe  conditional  generative  adversarial  network  to  learn  the  data  generatingdistribution  and  compute  probabilistic  forecasts  from  it.  We  argue  how  toevaluate  ForGAN  in  opposition  to  regression  methods.  To  investigateprobabilistic  forecasting  of  ForGAN,  we  create  a  new  dataset  and  demonstrateour  method  abilities  on  it.  This  dataset  will  be  made  publicly  available  forcomparison.  Furthermore,  we  test  ForGAN  on  two  publicly  available  datasets,namely  Mackey-Glass  dataset  and  Internet  traffic  dataset  (A5M)  where  theimpressive  performance  of  ForGAN  demonstrate  its  high  capability  in  forecastingfuture  values.</p>|2019-04-01  22:52:19.489616
http://arxiv.org/abs/1903.12551|What  obstruct  customer  acceptance  of  internet  banking?  Security  and  privacy,  risk,  trust  and  website  usability  and  the  role  of  moderators.  (arXiv:1903.12551v1  [cs.CY])|<p>Comparatively  a  little  attention  has  been  paid  to  the  factors  that  obstructthe  acceptance  of  Internet  banking  in  Sri  Lanka.  This  research  assimilatesconstructs  such  as  security  and  privacy,  perceived  trust,  perceived  risk,  andwebsite  usability.  To  test  the  conceptual  model,  we  collected  186  validresponses  from  customers  who  use  Internet  banking  in  Sri  Lanka.  The  structuralequation  modelling  technique  is  applied  and  hypotheses  are  validated.  Thefindings  show  perceived  trust  and  website  usability  are  the  possibleobstructing  factors  that  highly  concerned  by  Internet  banking  customers.  Whilesecurity  and  privacy,  and  perceived  risk  are  not  significant  and  these  are  nothighly  concerned  by  customers  in  Internet  banking  acceptance.  The  age  andgender  reveal  the  moderating  effect  in  each  exogenous  latent  constructsrelationship.  The  practical  and  managerial  implications  of  the  findings  arealso  discussed.  This  country  specific  study  contributes  to  the  advancement  ofInternet  banking  acceptance,  and  offers  some  useful  insights  to  researchers,practitioners  and  policy  makers  on  how  to  enhance  Internet  banking  acceptancefor  country  similar  in  context.</p>|2019-04-01  22:52:19.489646
http://arxiv.org/abs/1903.12552|On  the  Capacity  of  Private  Information  Retrieval  from  Coded,  Colluding,  and  Adversarial  Servers.  (arXiv:1903.12552v1  [cs.IT])|<p>In  this  work,  we  first  prove  the  capacity  of  coded,  linear  symmetric  privateinformation  retrieval  (SPIR)  in  the  presence  of  colluding,  adversarial,  andnonresponsive  servers,  giving  a  positive  closure  to  the  conjecture  stated  byTajeddine  et  al.  It  is  also  shown  that,  further  restricting  to  strongly-linearPIR  schemes  with  linear  interference  cancellation,  the  so-called  star  productscheme  proposed  by  Freij-Hollanti  et  al.  is  optimal.  This  observation  enablesto  prove  the  capacity  of  strongly-linear  (non-symmetric)  PIR  schemes  for  anynumber  of  files.  Further,  it  also  provides  a  positive  proof  in  this  practicalspecial  case  for  the  conjectures  stated  in  the  asymptotic  regime  byFreij-Hollanti  et  al.  and  Tajeddine  et  al.</p>|2019-04-01  22:52:19.489677
http://arxiv.org/abs/1903.12553|A  survey  of  blockchain  frameworks  and  applications.  (arXiv:1903.12553v1  [cs.CY])|<p>The  applications  of  the  blockchain  technology  are  still  being  discov-ered.When  a  new  potential  disruptive  technology  emerges,  there  is  a  tendency  to  tryto  solve  every  problem  with  that  technology.  However,  it  is  still  necessary  todetermine  what  approach  is  the  best  for  each  type  of  application.  To  find  howdistributed  ledgers  solve  existing  problems,  this  study  looks  for  blockchainframeworks  in  the  academic  world.  Identifying  the  existing  frameworks  candemonstrate  where  the  interest  in  the  technology  exists  and  where  it  can  bemiss-ing.  This  study  encountered  several  blockchain  frameworks  in  development.However,  there  are  few  references  to  operational  needs,  testing,  and  deploy  ofthe  technology.  With  the  widespread  use  of  the  technology,  either  integratingwith  pre-existing  solutions,  replacing  legacy  systems,  or  new  implementations,the  need  for  testing,  deploying,  exploration,  and  maintenance  is  expected  toin-tensify.</p>|2019-04-01  22:52:19.489707
http://arxiv.org/abs/1903.12554|Linked  Open  Data  Validity  --  A  Technical  Report  from  ISWS  2018.  (arXiv:1903.12554v1  [cs.DB])|<p>Linked  Open  Data  (LOD)  is  the  publicly  available  RDF  data  in  the  Web.  EachLOD  entity  is  identfied  by  a  URI  and  accessible  via  HTTP.  LOD  encodesglobalscale  knowledge  potentially  available  to  any  human  as  well  as  artificialintelligence  that  may  want  to  benefit  from  it  as  background  knowledge  forsupporting  their  tasks.  LOD  has  emerged  as  the  backbone  of  applications  indiverse  fields  such  as  Natural  Language  Processing,  Information  Retrieval,Computer  Vision,  Speech  Recognition,  and  many  more.  Nevertheless,  regardless  ofthe  specific  tasks  that  LOD-based  tools  aim  to  address,  the  reuse  of  suchknowledge  may  be  challenging  for  diverse  reasons,  e.g.  semantic  heterogeneity,provenance,  and  data  quality.  As  aptly  stated  by  Heath  et  al.  Linked  Data  mightbe  outdated,  imprecise,  or  simply  wrong":  there  arouses  a  necessity  toinvestigate  the  problem  of  linked  data  validity.  This  work  reports  acollaborative  effort  performed  by  nine  teams  of  students,  guided  by  an  equalnumber  of  senior  researchers,  attending  the  International  Semantic  Web  ResearchSchool  (ISWS  2018)  towards  addressing  such  investigation  from  differentperspectives  coupled  with  different  approaches  to  tackle  the  issue.</p>|2019-04-01  22:52:19.489740
http://arxiv.org/abs/1903.12556|Capacity  of  Quantum  Private  Information  Retrieval  with  Collusion  of  All  But  One  of  Servers.  (arXiv:1903.12556v1  [quant-ph])|<p>Quantum  private  information  retrieval  (QPIR)  is  the  problem  to  retrieve  oneof  $\mathsf{f}$  classical  files  by  downloading  quantum  systems  fromnon-communicating  $\mathsf{n}$  servers  each  of  which  contains  the  copy  of$\mathsf{f}$  files,  while  the  identity  of  the  retrieving  file  is  unknown  toeach  server.  As  an  extension,  we  consider  the  colluded  QPIR  that  the  identityof  the  retrieving  file  is  secret  even  if  any  $\mathsf{n}-1$  servers  collude,and  derive  the  QPIR  capacity  for  this  problem  which  is  defined  as  the  maximumrate  of  the  retrieving  file  size  over  the  download  size.  For  an  even  number$\mathsf{n}$  of  servers,  we  show  that  the  capacity  of  the  colluded  QPIR  is$2/\mathsf{n}$,  when  we  assume  that  there  are  preexisting  entanglements  amongthe  servers  and  require  that  no  information  of  the  non-retrieving  files  isretrieved.  We  construct  a  colluded  QPIR  protocol  of  rate$\lceil\mathsf{n}/2\rceil^{-1}$  and  prove  that  the  capacity  is  upper  bounded  by$2/\mathsf{n}$.  The  colluded  QPIR  capacity  is  strictly  higher  than  theclassical  counterpart.</p>|2019-04-01  22:52:19.489770
http://arxiv.org/abs/1903.12561|Second  Rethinking  of  Network  Pruning  in  the  Adversarial  Setting.  (arXiv:1903.12561v1  [cs.CV])|<p>It  is  well  known  that  deep  neural  networks  (DNNs)  are  vulnerable  toadversarial  attacks,  which  are  implemented  by  adding  crafted  perturbations  ontobenign  examples.  Min-max  robust  optimization  based  adversarial  training  canprovide  a  notion  of  security  against  adversarial  attacks.  However,  adversarialrobustness  requires  a  significantly  larger  capacity  of  the  network  than  thatfor  the  natural  training  with  only  benign  examples.  This  paper  proposes  aframework  of  concurrent  adversarial  training  and  weight  pruning  that  enablesmodel  compression  while  still  preserving  the  adversarial  robustness  andessentially  tackles  the  dilemma  of  adversarial  training.  Furthermore,  this  workstudies  two  hypotheses  about  weight  pruning  in  the  conventional  network  pruningsetting  and  finds  that  weight  pruning  is  essential  for  reducing  the  networkmodel  size  in  the  adversarial  setting,  i.e.,  training  a  small  model  fromscratch  even  with  inherited  initialization  from  the  large  model  cannot  achieveboth  adversarial  robustness  and  model  compression.</p>|2019-04-01  22:52:19.489801
http://arxiv.org/abs/1903.12564|Infinite  Brain  MR  Images:  PGGAN-based  Data  Augmentation  for  Tumor  Detection.  (arXiv:1903.12564v1  [cs.CV])|<p>Due  to  the  lack  of  available  annotated  medical  images,  accuratecomputer-assisted  diagnosis  requires  intensive  Data  Augmentation  (DA)techniques,  such  as  geometric/intensity  transformations  of  original  images;however,  those  transformed  images  intrinsically  have  a  similar  distribution  tothe  original  ones,  leading  to  limited  performance  improvement.  To  fill  the  datalack  in  the  real  image  distribution,  we  synthesize  brain  contrast-enhancedMagnetic  Resonance  (MR)  images---realistic  but  completely  different  from  theoriginal  ones---using  Generative  Adversarial  Networks  (GANs).  This  studyexploits  Progressive  Growing  of  GANs  (PGGANs),  a  multi-stage  generativetraining  method,  to  generate  original-sized  256  X  256  MR  images  forConvolutional  Neural  Network-based  brain  tumor  detection,  which  is  challengingvia  conventional  GANs;  difficulties  arise  due  to  unstable  GAN  training  withhigh  resolution  and  a  variety  of  tumors  in  size,  location,  shape,  and  contrast.Our  preliminary  results  show  that  this  novel  PGGAN-based  DA  method  can  achievepromising  performance  improvement,  when  combined  with  classical  DA,  in  tumordetection  and  also  in  other  medical  imaging  tasks.</p>|2019-04-01  22:52:19.489831
http://arxiv.org/abs/1903.12570|Sparse  graphs  are  near-bipartite.  (arXiv:1903.12570v1  [math.CO])|<p>A  multigraph  $G$  is  near-bipartite  if  $V(G)$  can  be  partitioned  as  $I,F$  suchthat  $I$  is  an  independent  set  and  $F$  induces  a  forest.  We  prove  that  amultigraph  $G$  is  near-bipartite  when  $3 |W |-2 |E(G[W]) |\ge  -1$  for  every$W\subseteq  V(G)$,  and  $G$  contains  no  $K_4$  and  no  Moser  spindle.  We  provethat  a  simple  graph  $G$  is  near-bipartite  when  $8 |W |-5 |E(G[W]) |\ge  -4$  forevery  $W\subseteq  V(G)$,  and  $G$  contains  no  subgraph  from  some  finite  family$\mathcal{H}$.  We  also  construct  infinite  families  to  show  that  both  resultsare  best  possible  in  a  very  sharp  sense.</p>|2019-04-01  22:52:19.489862
http://arxiv.org/abs/1903.12571|CNN-based  Prostate  Zonal  Segmentation  on  T2-weighted  MR  Images:  A  Cross-dataset  Study.  (arXiv:1903.12571v1  [cs.CV])|<p>Prostate  cancer  is  the  most  common  cancer  among  US  men.  However,  prostateimaging  is  still  challenging  despite  the  advances  in  multi-parametric  MagneticResonance  Imaging  (MRI),  which  provides  both  morphologic  and  functionalinformation  pertaining  to  the  pathological  regions.  Along  with  whole  prostategland  segmentation,  distinguishing  between  the  Central  Gland  (CG)  andPeripheral  Zone  (PZ)  can  guide  towards  differential  diagnosis,  since  thefrequency  and  severity  of  tumors  differ  in  these  regions;  however,  theirboundary  is  often  weak  and  fuzzy.  This  work  presents  a  preliminary  study  onDeep  Learning  to  automatically  delineate  the  CG  and  PZ,  aiming  at  evaluatingthe  generalization  ability  of  Convolutional  Neural  Networks  (CNNs)  on  twomulti-centric  MRI  prostate  datasets.  Especially,  we  compared  three  CNN-basedarchitectures:  SegNet,  U-Net,  and  pix2pix.  In  such  a  context,  the  segmentationperformances  achieved  with/without  pre-training  were  compared  in  4-foldcross-validation.  In  general,  U-Net  outperforms  the  other  methods,  especiallywhen  training  and  testing  are  performed  on  multiple  datasets.</p>|2019-04-01  22:52:19.489894
http://arxiv.org/abs/1903.12575|Invariance-Preserving  Localized  Activation  Functions  for  Graph  Neural  Networks.  (arXiv:1903.12575v1  [eess.SP])|<p>Graph  signals  are  signals  with  an  irregular  structure  that  can  be  describedby  a  graph.  Graph  neural  networks  (GNNs)  are  information  processingarchitectures  tailored  to  these  graph  signals  and  made  of  stacked  layers  thatcompose  graph  convolutional  filters  with  nonlinear  activation  functions.  Graphconvolutions  endow  GNNs  with  invariance  to  permutations  of  the  graph  nodes'labels.  In  this  paper,  we  consider  the  design  of  trainable  nonlinear  activationfunctions  that  take  into  consideration  the  structure  of  the  graph.  This  isaccomplished  by  using  graph  median  filters  and  graph  max  filters,  which  mimiclinear  graph  convolutions  and  are  shown  to  retain  the  permutation  invariance  ofGNNs.  We  also  discuss  modifications  to  the  backpropagation  algorithm  necessaryto  train  local  activation  functions.  The  advantages  of  localized  activationfunction  architectures  are  demonstrated  in  three  numerical  experiments:  sourcelocalization  on  synthetic  graphs,  authorship  attribution  of  19th  century  novelsand  prediction  of  movie  ratings.  In  all  cases,  localized  activation  functionsare  shown  to  improve  model  capacity.</p>|2019-04-01  22:52:19.489925
http://arxiv.org/abs/1903.12576|Practical  Synthesis  of  Reactive  Systems  from  LTL  Specifications  via  Parity  Games.  (arXiv:1903.12576v1  [cs.LO])|<p>The  synthesis  -  the  automatic  construction  -  of  reactive  systems  from  lineartemporal  logic  (LTL)  specifications  has  recently  seen  a  revival  of  the  classicautomata-theoretic  approach  based  on  parity-tree-automata,  which  outperformedother  synthesis  approaches  in  the  last  synthesis  competition  (Syntcomp2018).  Wedescribe  a  complete  synthesis  procedure  that  is  based  on  the  translation  of  LTLto  deterministic  parity  automata  and  the  emptiness  check  of  the  correspondingtree  automata.</p><p>The  described  approach  is  (1)  structured,  meaning  that  the  states  used  in  theconstruction  have  a  structure,  which  is  also  (partly)  preserved  in  thesynthesis  result,  performs  a  (2)  forward  exploration  and  thus  often  onlyconstructs  a  small  subset  of  the  reachable  states,  and  is  (3)  incremental  inthe  sense  that  it  reuses  results  from  previous  unsuccessful  solution  attempts.We  further  explore  the  impact  of  different  guiding  heuristics  that  determinewhere  to  expand  the  on-the-fly  built  arena  and  present  several  mechanisms  forextracting  an  implementation  (Mealy  machine  or  circuit).  Furthermore,  severaldata  structures  used  in  the  implementation  can  be  encoded  symbolically  reducingtime  and  memory  consumption.  We  compare  the  proposed  techniques  on  theSyntcomp2017  benchmark  set.</p>|2019-04-01  22:52:19.489956
http://arxiv.org/abs/1903.12577|Learning  Relational  Representations  with  Auto-encoding  Logic  Programs.  (arXiv:1903.12577v1  [cs.LG])|<p>Deep  learning  methods  capable  of  handling  relational  data  have  proliferatedover  the  last  years.  In  contrast  to  traditional  relational  learning  methodsthat  leverage  first-order  logic  for  representing  such  data,  these  deep  learningmethods  aim  at  re-representing  symbolic  relational  data  in  Euclidean  spaces.They  offer  better  scalability,  but  can  only  numerically  approximate  relationalstructures  and  are  less  flexible  in  terms  of  reasoning  tasks  supported.  Thispaper  introduces  a  novel  framework  for  relational  representation  learning  thatcombines  the  best  of  both  worlds.  This  framework,  inspired  by  the  auto-encodingprinciple,  uses  first-order  logic  as  a  data  representation  language,  and  themapping  between  the  original  and  latent  representation  is  done  by  means  oflogic  programs  instead  of  neural  networks.  We  show  how  learning  can  be  cast  asa  constraint  optimisation  problem  for  which  existing  solvers  can  be  used.  Theuse  of  logic  as  a  representation  language  makes  the  proposed  framework  moreaccurate  (as  the  representation  is  exact,  rather  than  approximate),  moreflexible,  and  more  interpretable  than  deep  learning  methods.  We  experimentallyshow  that  these  latent  representations  are  indeed  beneficial  in  relationallearning  tasks.</p>|2019-04-01  22:52:19.489987
http://arxiv.org/abs/1903.12579|Predicting  complex  user  behavior  from  CDR  based  social  networks.  (arXiv:1903.12579v1  [cs.SI])|<p>Call  Detail  Record  (CDR)  datasets  provide  enough  information  about  personalinteractions  to  support  building  and  analyzing  detailed  empirical  socialnetworks.  We  take  one  such  dataset  and  describe  the  various  ways  of  using  it  tocreate  a  true  social  network  in  spite  of  the  highly  noisy  data  source.  We  usethe  resulting  network  to  predict  each  individual's  likelihood  to  default  onpayments  for  the  network  services,  a  complex  behavior  that  involves  acombination  of  social,  economic,  and  legal  considerations.  We  use  a  largenumber  of  features  extracted  from  the  network  to  build  a  model  for  predictingwhich  users  will  default.  By  analyzing  the  relative  contributions  of  features,we  choose  their  best  performing  subsets  ranging  in  size  from  small  to  medium.Features  based  on  the  number  of  close  ties  maintained  by  a  user  performedbetter  than  those  derived  from  user's  geographical  location.  The  papercontributions  include  systematic  impact  analysis  that  the  number  of  callscutoff  has  on  the  properties  of  the  network  derived  from  CDR,  and  a  methodologyfor  building  complex  behavior  models  by  creating  very  large  sets  of  diversefeatures  and  systematically  choosing  those  which  perform  best  for  the  finalmodel.</p>|2019-04-01  22:52:19.490038
http://arxiv.org/abs/1903.12581|CroP:  Color  Constancy  Benchmark  Dataset  Generator.  (arXiv:1903.12581v1  [cs.CV])|<p>Implementing  color  constancy  as  a  pre-processing  step  in  contemporary  digitalcameras  is  of  significant  importance  as  it  removes  the  influence  of  sceneillumination  on  object  colors.  Several  benchmark  color  constancy  datasets  havebeen  created  for  the  purpose  of  developing  and  testing  new  color  constancymethods.  However,  they  all  have  numerous  drawbacks  including  a  small  number  ofimages,  erroneously  extracted  ground-truth  illuminations,  long  histories  ofmisuses,  violations  of  their  stated  assumptions,  etc.  To  overcome  such  andsimilar  problems,  in  this  paper  a  color  constancy  benchmark  dataset  generatoris  proposed.  For  a  given  camera  sensor  it  enables  generation  of  any  number  ofrealistic  raw  images  taken  in  a  subset  of  the  real  world,  namely  images  ofprinted  photographs.  Datasets  with  such  images  share  many  positive  featureswith  other  existing  real-world  datasets,  while  some  of  the  negative  featuresare  completely  eliminated.  The  generated  images  can  be  successfully  used  totrain  methods  that  afterward  achieve  high  accuracy  on  real-world  datasets.  Thisopens  the  way  for  creating  large  enough  datasets  for  advanced  deep  learningtechniques.  Experimental  results  are  presented  and  discussed.  The  source  codeis  available  at  <a  href="http://www.fer.unizg.hr/ipg/resources/color_constancy/.">this  http  URL</a></p>|2019-04-01  22:52:19.490073
http://arxiv.org/abs/1903.12582|Methodology  for  Designing  Decision  Support  Systems  for  Visualising  and  Mitigating  Supply  Chain  Cyber  Risk  from  IoT  Technologies.  (arXiv:1903.12582v1  [cs.OH])|<p>This  paper  proposes  a  methodology  for  designing  decision  support  systems  forvisualising  and  mitigating  the  Internet  of  Things  cyber  risks.  Digitaltechnologies  present  new  cyber  risk  in  the  supply  chain  which  are  often  notvisible  to  companies  participating  in  the  supply  chains.  This  studyinvestigates  how  the  Internet  of  Things  cyber  risks  can  be  visualised  andmitigated  in  the  process  of  designing  business  and  supply  chain  strategies.  Theemerging  DSS  methodology  present  new  findings  on  how  digital  technologiesaffect  business  and  supply  chain  systems.  Through  epistemological  analysis,  thearticle  derives  with  a  decision  support  system  for  visualising  supply  chaincyber  risk  from  Internet  of  Things  digital  technologies.  Such  methods  do  notexist  at  present  and  this  represents  the  first  attempt  to  devise  a  decisionsupport  system  that  would  enable  practitioners  to  develop  a  step  by  stepprocess  for  visualising,  assessing  and  mitigating  the  emerging  cyber  risk  fromIoT  technologies  on  shared  infrastructure  in  legacy  supply  chain  systems.</p>|2019-04-01  22:52:19.490104
http://arxiv.org/abs/1903.12584|The  False  Positive  Control  Lasso.  (arXiv:1903.12584v1  [stat.ML])|<p>In  high  dimensional  settings  where  a  small  number  of  regressors  are  expectedto  be  important,  the  Lasso  estimator  can  be  used  to  obtain  a  sparse  solutionvector  with  the  expectation  that  most  of  the  non-zero  coefficients  areassociated  with  true  signals.  While  several  approaches  have  been  developed  tocontrol  the  inclusion  of  false  predictors  with  the  Lasso,  these  approaches  arelimited  by  relying  on  asymptotic  theory,  having  to  empirically  estimate  termsbased  on  theoretical  quantities,  assuming  a  continuous  response  class  withGaussian  noise  and  design  matrices,  or  high  computation  costs.  In  this  paper  weshow  how:  (1)  an  existing  model  (the  SQRT-Lasso)  can  be  recast  as  a  method  ofcontrolling  the  number  of  expected  false  positives,  (2)  how  a  similar  estimatorcan  used  for  all  other  generalized  linear  model  classes,  and  (3)  this  approachcan  be  fit  with  existing  fast  Lasso  optimization  solvers.  Our  justification  forfalse  positive  control  using  randomly  weighted  self-normalized  sum  theory  is  toour  knowledge  novel.  Moreover,  our  estimator's  properties  hold  in  finitesamples  up  to  some  approximation  error  which  we  find  in  practical  settings  tobe  negligible  under  a  strict  mutual  incoherence  condition.</p>|2019-04-01  22:52:19.490135
http://arxiv.org/abs/1903.12589|Coordinated  Beam  Selection  in  Millimeter  Wave  Multi-User  MIMO  Using  Out-of-Band  Information.  (arXiv:1903.12589v1  [eess.SP])|<p>Using  out-of-band  (OOB)  side-information  has  recently  been  shown  toaccelerate  beam  selection  in  single-user  millimeter  wave  (mmWave)  massive  MIMOcommunications.  In  this  paper,  we  propose  a  novel  OOB-aided  beam  selectionframework  for  a  mmWave  uplink  multi-user  system.  In  particular,  we  exploitspatial  information  extracted  from  lower  (sub-6  GHz)  bands  in  order  to  assistwith  an  inter-user  coordination  scheme  at  mmWave  bands.  To  enforcecoordination,  we  propose  an  exchange  protocol  exploiting  device-to-devicecommunications,  where  low-rate  beam-related  information  is  exchanged  betweenthe  mobile  terminals.  The  decentralized  coordination  mechanism  allows  thesuppression  of  the  so-called  co-beam  interference  which  would  otherwise  lead  toirreducible  interference  at  the  base  station  side,  thereby  triggeringsubstantial  spectral  efficiency  gains.</p>|2019-04-01  22:52:19.490166
http://arxiv.org/abs/1903.12600|A  proof  of  convergence  of  multi-class  logistic  regression  network.  (arXiv:1903.12600v1  [stat.ML])|<p>This  paper  revisits  the  special  type  of  a  neural  network  known  under  twonames.  In  the  statistics  and  machine  learning  community  it  is  known  as  amulti-class  logistic  regression  neural  network.  In  the  neural  networkcommunity,  it  is  simply  the  soft-max  layer.  The  importance  is  underscored  byits  role  in  deep  learning:  as  the  last  layer,  whose  autput  is  actually  theclassification  of  the  input  patterns,  such  as  images.  Our  exposition  focuses  onmathematically  rigorous  derivation  of  the  key  equation  expressing  the  gradient.The  fringe  benefit  of  our  approach  is  a  fully  vectorized  expression,  which  is  abasis  of  an  efficient  implementation.  The  second  result  of  this  paper  is  thepositivity  of  the  second  derivative  of  the  cross-entropy  loss  function  asfunction  of  the  weights.  This  result  proves  that  optimization  methods  based  onconvexity  may  be  used  to  train  this  network.  As  a  corollary,  we  demonstratethat  no  $L^2$-regularizer  is  needed  to  guarantee  convergence  of  gradientdescent.</p>|2019-04-01  22:52:19.490197
http://arxiv.org/abs/1903.12605|Stable,  Concurrent  Controller  Composition  for  Multi-Objective  Robotic  Tasks.  (arXiv:1903.12605v1  [cs.SY])|<p>Robotic  systems  often  need  to  consider  multiple  tasks  concurrently.  Thischallenge  calls  for  control  synthesis  algorithms  that  are  capable  of  fulfillingmultiple  control  specifications  simultaneously  while  maintaining  the  stabilityof  the  overall  system.  In  this  paper,  we  decompose  complex,  multi-objectivetasks  into  subtasks,  where  individual  subtask  controllers  are  designedindependently  and  then  combined  to  generate  the  overall  control  policy.  Inparticular,  we  adopt  Riemannian  Motion  Policies  (RMPs),  a  recently  proposedcontroller  structure  in  robotics,  and,  RMPflow,  its  associated  computationalframework  for  combining  RMP  controllers.  We  re-establish  and  extend  thestability  results  of  RMPflow  through  a  rigorous  Control  Lyapunov  Function  (CLF)treatment.  We  then  show  that  RMPflow  can  stably  combine  individually  designedsubtask  controllers  that  satisfy  certain  CLF  constraints.  This  new  insightleads  to  an  efficient  CLF-based  computational  framework  to  generate  stablecontrollers  that  consider  all  the  subtasks  simultaneously.  Compared  with  theoriginal  usage  of  RMPflow,  our  framework  provides  users  the  flexibility  toincorporate  design  heuristics  through  nominal  controllers  for  the  subtasks.  Wevalidate  the  proposed  computational  framework  through  numerical  simulation  androbotic  implementation.</p>|2019-04-01  22:52:19.490228
http://arxiv.org/abs/1903.12616|Activity  Classification  Using  Smartphone  Gyroscope  and  Accelerometer  Data.  (arXiv:1903.12616v1  [cs.HC])|<p>Activities,  such  as  walking  and  sitting,  are  commonly  used  in  biomedicalsettings  either  as  an  outcome  or  covariate  of  interest.  Researchers  havetraditionally  relied  on  surveys  to  quantify  activity  levels  of  subjects  in  bothresearch  and  clinical  settings,  but  surveys  are  not  objective  in  nature  andhave  many  known  limitations,  such  as  recall  bias.  Smartphones  provide  anopportunity  for  unobtrusive  objective  measurement  of  various  activities  innaturalistic  settings,  but  their  data  tends  to  be  noisy  and  needs  to  beanalyzed  with  care.  We  explored  the  potential  of  smartphone  accelerometer  andgyroscope  data  to  distinguish  between  five  different  types  of  activity:walking,  sitting,  standing,  ascending  stairs,  and  descending  stairs.  Weconducted  a  study  in  which  four  participants  followed  a  study  protocol  andperformed  a  sequence  of  various  activities  with  one  phone  in  their  front  pocketand  another  phone  in  their  back  pocket.  The  subjects  were  filmed  throughout,and  the  obtained  footage  was  annotated  to  establish  ground  truth  activity.  Weapplied  the  so-called  movelet  method  to  classify  their  activity.  Our  resultsdemonstrate  the  promise  of  smartphones  for  activity  detection  in  naturalisticsettings,  but  they  also  highlight  common  challenges  in  this  field  of  research.</p>|2019-04-01  22:52:19.490262
http://arxiv.org/abs/1903.12617|Some  Experimental  Results  of  Relieving  Discomfort  in  Virtual  Reality  by  Disturbing  Feedback  Loop  in  Human  Brain.  (arXiv:1903.12617v1  [cs.HC])|<p>Recently,  great  progress  has  been  made  in  virtual  reality(VR)  research  andapplication.  However,  virtual  reality  faces  a  big  problem  since  its  appearance,i.e.  discomfort  (nausea,  stomach  awareness,  etc).  Discomfort  can  be  relieved  byincreasing  hardware  (sensor,  cpu  and  display)  speed.  But  this  will  increasecost.  This  paper  gives  another  low  cost  solution.  The  phenomenon  ofcybersickness  is  explained  with  the  control  theory:  discomfort  arises  iffeedback  scene  differs  from  expectation,  so  it  can  be  relieved  by  disturbingfeedback  loop  in  human  brain.  A  hardware  platform  is  build  to  test  thisexplanation.  The  VR  display  on  a  Samsung  S6  is  blurred  while  head  movement  isdetected.  The  effect  is  evaluated  by  comparing  responses  to  the  SimulatedSickness  Questionnaire  (SSQ)  between  a  control  and  experimental  condition.Experimental  results  show  that  the  new  method  can  ease  discomfort  remarkablywith  little  extra  cost.  As  a  result,  VR  may  be  used  more  widely  in  teaching(like  foreign  language,  medicine).  It's  also  reasonable  to  expect  likewisemerits  in  other  VR  applications.</p>|2019-04-01  22:52:19.490292
http://arxiv.org/abs/1903.12620|Alternating  Weak  Automata  from  Universal  Trees.  (arXiv:1903.12620v1  [cs.FL])|<p>An  improved  translation  from  alternating  parity  automata  on  infinite  words  toalternating  weak  automata  is  given.  The  blow-up  of  the  number  of  states  isrelated  to  the  size  of  the  smallest  universal  ordered  trees  and  hence  it  isquasi-polynomial,  and  only  polynomial  if  the  asymptotic  number  of  priorities  islogarithmic  in  the  number  of  states.</p><p>This  is  an  exponential  improvement  on  the  translation  of  Kupferman  and  Vardi(2001)  and  a  quasi-polynomial  improvement  on  the  translation  of  Boker  andLehtinen  (2018).  Any  slightly  better  such  translation  would  (if---like  allpresently  known  such  translations---it  is  efficiently  constructive)  lead  toalgorithms  for  solving  parity  games  that  are  asymptotically  faster  in  the  worstcase  than  the  current  state  of  the  art  (Calude,  Jain,  Khoussainov,  Li,  andStephan,  2017;  Jurdzi\'nski  and  Lazi\'c,  2017;  and  Fearnley,  Jain,  Schewe,Stephan,  and  Wojtczak,  2017),  and  hence  it  would  yield  a  significantbreakthrough.</p>|2019-04-01  22:52:19.490323
http://arxiv.org/abs/1903.12626|Integrating  Semantic  Knowledge  to  Tackle  Zero-shot  Text  Classification.  (arXiv:1903.12626v1  [cs.CL])|<p>Insufficient  or  even  unavailable  training  data  of  emerging  classes  is  a  bigchallenge  of  many  classification  tasks,  including  text  classification.Recognising  text  documents  of  classes  that  have  never  been  seen  in  the  learningstage,  so-called  zero-shot  text  classification,  is  therefore  difficult  and  onlylimited  previous  works  tackled  this  problem.  In  this  paper,  we  propose  atwo-phase  framework  together  with  data  augmentation  and  feature  augmentation  tosolve  this  problem.  Four  kinds  of  semantic  knowledge  (word  embeddings,  classdescriptions,  class  hierarchy,  and  a  general  knowledge  graph)  are  incorporatedinto  the  proposed  framework  to  deal  with  instances  of  unseen  classeseffectively.  Experimental  results  show  that  each  and  the  combination  of  the  twophases  achieve  the  best  overall  accuracy  compared  with  baselines  and  recentapproaches  in  classifying  real-world  texts  under  the  zero-shot  scenario.</p>|2019-04-01  22:52:19.490354
http://arxiv.org/abs/1903.12641|Connected  max  cut  is  polynomial  for  graphs  without  $K_5\backslash  e$  as  a  minor.  (arXiv:1903.12641v1  [cs.DS])|<p>Given  a  graph  $G=(V,  E)$,  a  connected  cut  $\delta  (U)$  is  the  set  of  edges  ofE  linking  all  vertices  of  U  to  all  vertices  of  $V\backslash  U$  such  that  theinduced  subgraphs  $G[U]$  and  $G[V\backslash  U]$  are  connected.  Given  a  positiveweight  function  $w$  defined  on  $E$,  the  connected  maximum  cut  problem  (CMAXCUT)  is  to  find  a  connected  cut  $\Omega$  such  that  $w(\Omega)$  is  maximum  amongall  connected  cuts.  CMAX  CUT  is  NP-hard  even  for  planar  graphs.  In  this  paper,we  prove  that  CMAX  CUT  is  polynomial  for  graphs  without  $K_5\backslash  e$  as  aminor.  We  deduce  a  quadratic  time  algorithm  for  the  minimum  cut  problem  in  thesame  class  of  graphs  without  computing  the  maximum  flow.</p>|2019-04-01  22:52:19.490385
http://arxiv.org/abs/1903.12644|Optimising  maintenance:  What  are  the  expectations  for  Cyber  Physical  Systems.  (arXiv:1903.12644v1  [eess.SP])|<p>The  need  for  maintenance  is  based  on  the  wear  of  components  of  machinery.  Ifthis  need  can  be  defined  reliably  beforehand  so  that  no  unpredicted  failurestake  place  then  the  maintenance  actions  can  be  carried  out  economically  withmini-mum  disturbances  to  production.  There  are  two  basic  challenges  in  solvingthe  above.  First  understanding  the  development  of  wear  and  failures,  and  secondmanaging  the  measurement  and  diagnosis  of  such  parameters  that  can  reveal  thedevelopment  of  wear.  In  principle  the  development  of  wear  and  failures  can  bepredicted  through  monitoring  time,  load  or  wear  as  such.  Moni-toring  time  isnot  very  efficient,  as  there  are  only  limited  numbers  of  components  that  sufferfrom  aging  which  as  such  is  the  result  of  chemical  wear  i.e.  changes  in  thematerial.  In  most  cases  the  loading  of  components  influences  their  wear.  Inprinciple  the  loading  can  be  stable  or  varying  in  nature.  Of  these  two  casesthe  varying  load  case  is  much  more  challenging  than  the  stable  one.  Themonitoring  of  wear  can  be  done  either  directly  e.g.  optical  methods  orindirectly  e.g.  vibration.  Monitoring  actual  wear  is  naturally  the  mostreliable  approach,  but  it  often  means  that  additional  investments  are  needed.The  paper  discusses  how  the  monitoring  of  wear  and  need  for  maintenance  can  bedone  based  on  the  use  of  Cyber  Physical  Systems.</p>|2019-04-01  22:52:19.490416
http://arxiv.org/abs/1903.12648|Incremental  Learning  with  Unlabeled  Data  in  the  Wild.  (arXiv:1903.12648v1  [cs.CV])|<p>Deep  neural  networks  are  known  to  suffer  from  catastrophic  forgetting  inclass-incremental  learning,  where  the  performance  on  previous  tasks  drasticallydegrades  when  learning  a  new  task.  To  alleviate  this  effect,  we  propose  toleverage  a  continuous  and  large  stream  of  unlabeled  data  in  the  wild.  Inparticular,  to  leverage  such  transient  external  data  effectively,  we  design  anovel  class-incremental  learning  scheme  with  (a)  a  new  distillation  loss,termed  global  distillation,  (b)  a  learning  strategy  to  avoid  overfitting  to  themost  recent  task,  and  (c)  a  sampling  strategy  for  the  desired  external  data.Our  experimental  results  on  various  datasets,  including  CIFAR  and  ImageNet,demonstrate  the  superiority  of  the  proposed  methods  over  prior  methods,particularly  when  a  stream  of  unlabeled  data  is  accessible:  we  achieve  up  to9.3%  of  relative  performance  improvement  compared  to  the  state-of-the-artmethod.</p>|2019-04-01  22:52:19.490470
http://arxiv.org/abs/1903.12650|Yet  Another  Accelerated  SGD:  ResNet-50  Training  on  ImageNet  in  74.7  seconds.  (arXiv:1903.12650v1  [cs.LG])|<p>There  has  been  a  strong  demand  for  algorithms  that  can  execute  machinelearning  as  faster  as  possible  and  the  speed  of  deep  learning  has  acceleratedby  30  times  only  in  the  past  two  years.  Distributed  deep  learning  using  thelarge  mini-batch  is  a  key  technology  to  address  the  demand  and  is  a  greatchallenge  as  it  is  difficult  to  achieve  high  scalability  on  large  clusterswithout  compromising  accuracy.  In  this  paper,  we  introduce  optimization  methodswhich  we  applied  to  this  challenge.  We  achieved  the  training  time  of  74.7seconds  using  2,048  GPUs  on  ABCI  cluster  applying  these  methods.  The  trainingthroughput  is  over  1.73  million  images/sec  and  the  top-1  validation  accuracy  is75.08%.</p>|2019-04-01  22:52:19.490504
http://arxiv.org/abs/1903.12653|Fooling  the  Parallel  Or  Tester  with  Probability  $8/27$.  (arXiv:1903.12653v1  [cs.LO])|<p>It  is  well-known  that  the  higher-order  language  PCF  is  not  fully  abstract:there  is  a  program  -  the  so-called  parallel  or  tester,  meant  to  test  whetherits  input  behaves  as  a  parallel  or  -  which  never  terminates  on  any  input,operationally,  but  is  denotationally  non-trivial.  We  explore  a  probabilisticvariant  of  PCF,  and  ask  whether  the  parallel  or  tester  exhibits  a  similarbehavior  there.  The  answer  is  no:  operationally,  one  can  feed  the  parallel  ortester  an  input  that  will  fool  it  into  thinking  it  is  a  parallel  or.  We  showthat  the  largest  probability  of  success  of  such  would-be  parallel  ors  isexactly  $8/27$.  The  bound  is  reached  by  a  very  simple  probabilistic  program.The  difficult  part  is  to  show  that  that  bound  cannot  be  exceeded.</p>|2019-04-01  22:52:19.490536
http://arxiv.org/abs/cs/0601132|A  Study  on  the  Global  Convergence  Time  Complexity  of  Estimation  of  Distribution  Algorithms.  (arXiv:cs/0601132v2  [cs.AI]  UPDATED)|<p>The  Estimation  of  Distribution  Algorithm  is  a  new  class  of  population  basedsearch  methods  in  that  a  probabilistic  model  of  individuals  is  estimated  basedon  the  high  quality  individuals  and  used  to  generate  the  new  individuals.  Inthis  paper  we  compute  1)  some  upper  bounds  on  the  number  of  iterations  requiredfor  global  convergence  of  EDA  2)  the  exact  number  of  iterations  needed  for  EDAto  converge  to  global  optima.</p>|2019-04-01  22:52:19.490566
http://arxiv.org/abs/1505.02847|Minimal  conditions  for  parametric  continuity  of  a  utility  representation.  (arXiv:1505.02847v2  [cs.GT]  UPDATED)|<p>Dependence  on  the  parameter  is  continuous  when  perturbations  of  the  parameterpreserves  strict  preference  for  one  alternative  over  another.  We  characterisethis  property  via  a  utility  function  over  alternatives  that  dependscontinuously  on  the  parameter.  The  class  of  parameter  spaces  where  such  arepresentation  is  guaranteed  to  exist  is  also  identified.  When  the  parameter  isthe  type  or  belief  of  a  player,  these  results  have  implications  for  Bayesianand  psychological  games.  When  alternatives  are  discrete,  the  representation  isjointly  continuous  and  an  extension  of  Berge's  theorem  of  the  maximum  yields  acontinuous  value  function.  We  apply  this  result  to  generalise  a  standardconsumer  choice  problem  where  parameters  are  price-wealth  vectors.  When  theparameter  space  is  lexicographically  ordered,  a  novel  application  toreference-dependent  preferences  is  possible.</p>|2019-04-01  22:52:19.490597
http://arxiv.org/abs/1610.01234|Ensemble  Validation:  Selectivity  has  a  Price,  but  Variety  is  Free.  (arXiv:1610.01234v3  [stat.ML]  UPDATED)|<p>Suppose  some  classifiers  are  selected  from  a  set  of  hypothesis  classifiers  toform  an  equally-weighted  ensemble  that  selects  a  member  classifier  at  randomfor  each  input  example.  Then  the  ensemble  has  an  error  bound  consisting  of  theaverage  error  bound  for  the  member  classifiers,  a  term  for  selectivity  thatvaries  from  zero  (if  all  hypothesis  classifiers  are  selected)  to  a  standarduniform  error  bound  (if  only  a  single  classifier  is  selected),  and  smallconstants.  There  is  no  penalty  for  using  a  richer  hypothesis  set  if  the  samefraction  of  the  hypothesis  classifiers  are  selected  for  the  ensemble.</p>|2019-04-01  22:52:19.490627
http://arxiv.org/abs/1704.00229|Dense  point  sets  with  many  halving  lines.  (arXiv:1704.00229v2  [math.CO]  UPDATED)|<p>A  planar  point  set  of  $n$  points  is  called  {\em  $\gamma$-dense}  if  the  ratioof  the  largest  and  smallest  distances  among  the  points  is  at  most$\gamma\sqrt{n}$.  We  construct  a  dense  set  of  $n$  points  in  the  plane  with$ne^{\Omega\left({\sqrt{\log  n}}\right)}$  halving  lines.  This  improves  thebound  $\Omega(n\log  n)$  of  Edelsbrunner,  Valtr  and  Welzl  from  1997.</p><p>Our  construction  can  be  generalized  to  higher  dimensions,  for  any  $d$  weconstruct  a  dense  point  set  of  $n$  points  in  $\mathbb{R}^d$  with$n^{d-1}e^{\Omega\left({\sqrt{\log  n}}\right)}$  halving  hyperplanes.  Our  lowerbounds  are  asymptotically  the  same  as  the  best  known  lower  bounds  for  generalpoint  sets.</p>|2019-04-01  22:52:19.490657
http://arxiv.org/abs/1706.09606|Theoretical  Performance  Analysis  of  Vehicular  Broadcast  Communications  at  Intersection  and  their  Optimization.  (arXiv:1706.09606v3  [cs.PF]  UPDATED)|<p>In  this  paper,  we  propose  an  optimization  method  for  the  broadcast  rate  invehicle-to-vehicle  (V2V)  broadcast  communications  at  an  intersection  on  thebasis  of  theoretical  analysis.  We  consider  a  model  in  which  locations  ofvehicles  are  modeled  separately  as  queuing  and  running  segments  and  derive  keyperformance  metrics  of  V2V  broadcast  communications  via  a  stochastic  geometryapproach.  Since  these  theoretical  expressions  are  mathematically  intractable,we  developed  closed-form  approximate  formulae  for  them.  Using  them,  we  optimizethe  broadcast  rate  such  that  the  mean  number  of  successful  receivers  per  unittime  is  maximized.  Because  of  the  closed  form  approximation,  the  optimal  ratecan  be  used  as  a  guideline  for  a  real-time  control-method,  which  is  notachieved  through  time-consuming  simulations.  We  evaluated  our  method  throughnumerical  examples  and  demonstrated  the  effectiveness  of  our  method.</p>|2019-04-01  22:52:19.490692
http://arxiv.org/abs/1711.07230|Optimism-Based  Adaptive  Regulation  of  Linear-Quadratic  Systems.  (arXiv:1711.07230v3  [cs.SY]  UPDATED)|<p>The  main  challenge  for  adaptive  regulation  of  linear-quadratic  systems  is  thetrade-off  between  identification  and  control.  An  adaptive  policy  needs  toaddress  both  the  estimation  of  unknown  dynamics  parameters  (exploration),  aswell  as  the  regulation  of  the  underlying  system  (exploitation).  To  this  end,optimism-based  methods  which  bias  the  identification  in  favor  of  optimisticapproximations  of  the  true  parameter  are  employed  in  the  literature.  A  numberof  asymptotic  results  have  been  established,  but  their  finite  time  counterpartsare  few,  with  important  restrictions.</p><p>This  study  establishes  results  for  the  worst-case  regret  of  optimism-basedadaptive  policies.  The  presented  high  probability  upper  bounds  are  optimal  upto  logarithmic  factors.  The  non-asymptotic  analysis  of  this  work  requires  verymild  assumptions;  (i)  stabilizability  of  the  system's  dynamics,  and  (ii)limiting  the  degree  of  heaviness  of  the  noise  distribution.  To  establish  suchbounds,  certain  novel  techniques  are  developed  to  comprehensively  address  theprobabilistic  behavior  of  dependent  random  matrices  with  heavy-taileddistributions.</p>|2019-04-01  22:52:19.490723
http://arxiv.org/abs/1712.02719|Incremental  Learning  in  Deep  Convolutional  Neural  Networks  Using  Partial  Network  Sharing.  (arXiv:1712.02719v3  [cs.CV]  UPDATED)|<p>Deep  convolutional  neural  network  (DCNN)  based  supervised  learning  is  awidely  practiced  approach  for  large-scale  image  classification.  However,retraining  these  large  networks  to  accommodate  new,  previously  unseen  datademands  high  computational  time  and  energy  requirements.  Also,  previously  seentraining  samples  may  not  be  available  at  the  time  of  retraining.  We  propose  anefficient  training  methodology  and  incrementally  growing  DCNN  to  allow  newclasses  to  be  learned  while  sharing  part  of  the  base  network.  Our  proposedmethodology  is  inspired  by  transfer  learning  techniques,  although  it  does  notforget  previously  learned  classes.  An  updated  network  for  learning  new  set  ofclasses  is  formed  using  previously  learned  convolutional  layers  (shared  frominitial  part  of  base  network)  with  addition  of  few  newly  added  convolutionalkernels  included  in  the  later  layers  of  the  network.  We  employed  a`clone-and-branch'  technique  which  allows  the  network  to  learn  new  tasks  oneafter  another  without  any  performance  loss  in  old  tasks.  We  evaluated  theproposed  scheme  on  several  recognition  applications.  The  classificationaccuracy  achieved  by  our  approach  is  comparable  to  the  regular  incrementallearning  approach  (where  networks  are  updated  with  new  training  samples  only,without  any  network  sharing),  while  achieving  energy  efficiency,  reduction  instorage  requirements,  memory  access  and  training  time.</p>|2019-04-01  22:52:19.490754
http://arxiv.org/abs/1712.04054|Information  Dissemination  Speed  in  Delay  Tolerant  Urban  Vehicular  Networks  in  a  Hyperfractal  Setting.  (arXiv:1712.04054v2  [cs.NI]  UPDATED)|<p>This  paper  studies  the  fundamental  communication  properties  of  urban  vehiclenetworks  by  exploiting  the  self-similarity  and  hierarchical  organization  ofmodern  cities.  We  use  an  innovative  model  called  "hyperfractal"  that  capturesthe  self-similarities  of  both  the  traffic  and  vehicle  locations  but  avoids  theextremes  of  regularity  and  randomness.  We  use  analytical  tools  to  derivetheoretical  upper  and  lower  bounds  for  the  information  propagation  speed  in  anurban  delay  tolerant  network  (i.e.,  a  network  that  is  disconnected  at  all  time,and  thus  uses  a  store-carry-and-forward  routing  model).  We  prove  that  theaverage  broadcast  time  behaves  as  $n^{1-\delta}$  times  a  slowly  varyingfunction,  where  $\delta$  depends  on  the  precise  fractal  dimension.</p><p>Furthermore,  we  show  that  the  broadcast  speedup  is  due  in  part  to  aninteresting  self-similar  phenomenon,  that  we  denote  as  {\em  informationteleportation}.  This  phenomenon  arises  as  a  consequence  of  the  topology  of  thevehicle  traffic,  and  triggers  an  acceleration  of  the  broadcast  time.  We  showthat  our  model  fits  real  cities  where  open  traffic  data  sets  are  available.  Wepresent  simulations  confirming  the  validity  of  the  bounds  in  multiple  realisticsettings,  including  scenarios  with  variable  speed,  using  both  QualNet  and  adiscrete-event  simulator  in  Matlab.</p>|2019-04-01  22:52:19.490785
http://arxiv.org/abs/1801.10365|Synchronized  Detection  and  Recovery  of  Steganographic  Messages  with  Adversarial  Learning.  (arXiv:1801.10365v3  [cs.CV]  UPDATED)|<p>In  this  work,  we  mainly  study  the  mechanism  of  learning  the  steganographicalgorithm  as  well  as  combining  the  learning  process  with  adversarial  learningto  learn  a  good  steganographic  algorithm.  To  handle  the  problem  of  embeddingsecret  messages  into  the  specific  medium,  we  design  a  novel  adversarial  modulesto  learn  the  steganographic  algorithm,  and  simultaneously  train  three  modulescalled  generator,  discriminator  and  steganalyzer.  Different  from  existingmethods,  the  three  modules  are  formalized  as  a  game  to  communicate  with  eachother.  In  the  game,  the  generator  and  discriminator  attempt  to  communicate  witheach  other  using  secret  messages  hidden  in  an  image.  While  the  steganalyzerattempts  to  analyze  whether  there  is  a  transmission  of  confidentialinformation.  We  show  that  through  unsupervised  adversarial  training,  theadversarial  model  can  produce  robust  steganographic  solutions,  which  act  likean  encryption.  Furthermore,  we  propose  to  utilize  supervised  adversarialtraining  method  to  train  a  robust  steganalyzer,  which  is  utilized  todiscriminate  whether  an  image  contains  secret  information.  Numerous  experimentsare  conducted  on  publicly  available  dataset  to  demonstrate  the  effectiveness  ofthe  proposed  method.</p>|2019-04-01  22:52:19.490816
http://arxiv.org/abs/1802.01751|Near-Optimal  Coresets  of  Kernel  Density  Estimates.  (arXiv:1802.01751v4  [cs.LG]  UPDATED)|<p>We  construct  near-optimal  coresets  for  kernel  density  estimates  for  points  in$\mathbb{R}^d$  when  the  kernel  is  positive  definite.  Specifically  we  show  apolynomial  time  construction  for  a  coreset  of  size  $O(\sqrt{d}/\varepsilon\cdot\sqrt{\log  1/\varepsilon}  )$,  and  we  show  a  near-matching  lower  bound  of  size$\Omega(\min\{\sqrt{d}/\varepsilon,  1/\varepsilon^2\})$.  When  $d\geq1/\varepsilon^2$,  it  is  known  that  the  size  of  coreset  can  be$O(1/\varepsilon^2)$.  The  upper  bound  is  a  polynomial-in-$(1/\varepsilon)$improvement  when  $d  \in  [3,1/\varepsilon^2)$  and  the  lower  bound  is  the  firstknown  lower  bound  to  depend  on  $d$  for  this  problem.  Moreover,  the  upper  boundrestriction  that  the  kernel  is  positive  definite  is  significant  in  that  itapplies  to  a  wide-variety  of  kernels,  specifically  those  most  important  formachine  learning.  This  includes  kernels  for  information  distances  and  the  sinckernel  which  can  be  negative.</p>|2019-04-01  22:52:19.490846
http://arxiv.org/abs/1802.02607|Learning  from  Past  Mistakes:  Improving  Automatic  Speech  Recognition  Output  via  Noisy-Clean  Phrase  Context  Modeling.  (arXiv:1802.02607v2  [cs.CL]  UPDATED)|<p>Automatic  speech  recognition  (ASR)  systems  often  make  unrecoverable  errorsdue  to  subsystem  pruning  (acoustic,  language  and  pronunciation  models);  forexample  pruning  words  due  to  acoustics  using  short-term  context,  prior  torescoring  with  long-term  context  based  on  linguistics.  In  this  work  we  modelASR  as  a  phrase-based  noisy  transformation  channel  and  propose  an  errorcorrection  system  that  can  learn  from  the  aggregate  errors  of  all  theindependent  modules  constituting  the  ASR  and  attempt  to  invert  those.  Theproposed  system  can  exploit  long-term  context  using  a  neural  network  languagemodel  and  can  better  choose  between  existing  ASR  output  possibilities  as  wellas  re-introduce  previously  pruned  or  unseen  (out-of-vocabulary)  phrases.  Itprovides  corrections  under  poorly  performing  ASR  conditions  without  degradingany  accurate  transcriptions;  such  corrections  are  greater  on  top  ofout-of-domain  and  mismatched  data  ASR.  Our  system  consistently  providesimprovements  over  the  baseline  ASR,  even  when  baseline  is  further  optimizedthrough  recurrent  neural  network  language  model  rescoring.  This  demonstratesthat  any  ASR  improvements  can  be  exploited  independently  and  that  our  proposedsystem  can  potentially  still  provide  benefits  on  highly  optimized  ASR.  Finally,we  present  an  extensive  analysis  of  the  type  of  errors  corrected  by  our  system.</p>|2019-04-01  22:52:19.490877
http://arxiv.org/abs/1802.04364|Junction  Tree  Variational  Autoencoder  for  Molecular  Graph  Generation.  (arXiv:1802.04364v4  [cs.LG]  UPDATED)|<p>We  seek  to  automate  the  design  of  molecules  based  on  specific  chemicalproperties.  In  computational  terms,  this  task  involves  continuous  embedding  andgeneration  of  molecular  graphs.  Our  primary  contribution  is  the  directrealization  of  molecular  graphs,  a  task  previously  approached  by  generatinglinear  SMILES  strings  instead  of  graphs.  Our  junction  tree  variationalautoencoder  generates  molecular  graphs  in  two  phases,  by  first  generating  atree-structured  scaffold  over  chemical  substructures,  and  then  combining  theminto  a  molecule  with  a  graph  message  passing  network.  This  approach  allows  usto  incrementally  expand  molecules  while  maintaining  chemical  validity  at  everystep.  We  evaluate  our  model  on  multiple  tasks  ranging  from  molecular  generationto  optimization.  Across  these  tasks,  our  model  outperforms  previousstate-of-the-art  baselines  by  a  significant  margin.</p>|2019-04-01  22:52:19.490907
http://arxiv.org/abs/1803.10681|Motion  Guided  LIDAR-camera  Self-calibration  and  Accelerated  Depth  Upsampling.  (arXiv:1803.10681v2  [cs.CV]  UPDATED)|<p>In  this  work  we  describe  a  novel  motion  guided  method  for  targetlessself-calibration  of  a  LiDAR  and  camera  and  use  the  re-projection  of  LiDARpoints  onto  the  image  reference  frame  for  real-time  depth  upsampling.  Thecalibration  parameters  are  estimated  by  optimizing  an  objective  function  thatpenalizes  distances  between  2D  and  re-projected  3D  motion  vectors  obtained  fromtime-synchronized  image  and  point  cloud  sequences.  For  upsampling,  we  propose  asimple,  yet  effective  and  time  efficient  formulation  that  minimizes  depthgradients  subject  to  an  equality  constraint  involving  the  LiDAR  measurements.We  test  our  algorithms  on  real  data  from  urban  environments  and  demonstratethat  our  two  methods  are  effective  and  suitable  to  mobile  robotics  andautonomous  vehicle  applications  imposing  real-time  requirements.</p>|2019-04-01  22:52:19.490939
http://arxiv.org/abs/1804.03295|MmWave  MU-MIMO  for  Aerial  Networks.  (arXiv:1804.03295v5  [eess.SP]  UPDATED)|<p>Millimeter  wave  offers  high  bandwidth  for  air-to-air  (A2A)  communication.  Inthis  paper,  we  evaluate  the  rate  performance  of  a  multiuser  MIMO  (MU-MIMO)configuration  where  several  aircraft  communicate  with  a  central  hub.  Weconsider  a  hybrid  subarray  architecture,  single  path  channels,  and  realisticatmospheric  attenuation  effects.  We  propose  a  mathematical  framework  for  theanalysis  of  millimeter  wave  (mmWave)  MU-MIMO  networks.  Via  Monte  Carlosimulation,  we  demonstrate  that  mmWave  is  a  promising  technology  for  deliveringgigabit  connectivity  in  next-generation  aerial  networks.</p>|2019-04-01  22:52:19.490969
http://arxiv.org/abs/1804.10445|Adaptive  Transmission  in  Cellular  Networks:  Fixed-Rate  Codes  with  Power  Control  vs  Physical  Layer  Rateless  Codes.  (arXiv:1804.10445v2  [cs.IT]  UPDATED)|<p>Adaptive  transmission  schemes  are  a  crucial  aspect  of  the  radio  design  forfuture  wireless  networks.  The  paper  studies  the  performance  of  two  classes  ofadaptive  transmission  schemes  in  a  cellular  downlink.  One  class  is  based  onphysical  layer  rateless  codes  with  constant  transmit  power  and  the  other  usesfixed-rate  codes  in  conjunction  with  power  adaptation.  Using  a  simplestochastic  geometry  model  for  the  cellular  downlink,  the  focus  is  to  comparethe  adaptivity  of  fixed-rate  codes  with  power  adaptation  to  that  of  physicallayer  rateless  codes  only.  The  performance  of  both  rateless  and  fixed-ratecoded  adaptive  transmission  schemes  are  compared  by  evaluating  the  typical  usersuccess  probability  and  rate  achievable  with  the  two  schemes.  Based  on  both  thetheoretical  analysis  and  simulation  results,  it  is  clearly  shown  thatfixed-rate  codes  require  power  control  to  maintain  good  performance  whereasphysical  layer  rateless  codes  with  constant  power  can  still  provide  robustperformance.</p>|2019-04-01  22:52:19.491000
http://arxiv.org/abs/1805.05086|Unsupervised  Intuitive  Physics  from  Visual  Observations.  (arXiv:1805.05086v2  [cs.CV]  UPDATED)|<p>While  learning  models  of  intuitive  physics  is  an  increasingly  active  area  ofresearch,  current  approaches  still  fall  short  of  natural  intelligences  in  oneimportant  regard:  they  require  external  supervision,  such  as  explicit  access  tophysical  states,  at  training  and  sometimes  even  at  test  times.  Some  authorshave  relaxed  such  requirements  by  supplementing  the  model  with  an  handcraftedphysical  simulator.  Still,  the  resulting  methods  are  unable  to  automaticallylearn  new  complex  environments  and  to  understand  physical  interactions  withinthem.  In  this  work,  we  demonstrated  for  the  first  time  learning  such  predictorsdirectly  from  raw  visual  observations  and  without  relying  on  simulators.  We  doso  in  two  steps:  first,  we  learn  to  track  mechanically-salient  objects  invideos  using  causality  and  equivariance,  two  unsupervised  learning  principlesthat  do  not  require  auto-encoding.  Second,  we  demonstrate  that  the  extractedpositions  are  sufficient  to  successfully  train  visual  motion  predictors  thatcan  take  the  underlying  environment  into  account.  We  validate  our  predictors  onsynthetic  datasets;  then,  we  introduce  a  new  dataset,  ROLL4REAL,  consisting  ofreal  objects  rolling  on  complex  terrains  (pool  table,  elliptical  bowl,  andrandom  height-field).  We  show  that  in  all  such  cases  it  is  possible  to  learnreliable  extrapolators  of  the  object  trajectories  from  raw  videos  alone,without  any  form  of  external  supervision  and  with  no  more  prior  knowledge  thanthe  choice  of  a  convolutional  neural  network  architecture.</p>|2019-04-01  22:52:19.491051
http://arxiv.org/abs/1805.11519|Face  Recognition  in  Low  Quality  Images:  A  Survey.  (arXiv:1805.11519v3  [cs.CV]  UPDATED)|<p>Low-resolution  face  recognition  (LRFR)  has  received  increasing  attention  overthe  past  few  years.  Its  applications  lie  widely  in  the  real-world  environmentwhen  high-resolution  or  high-quality  images  are  hard  to  capture.  One  of  thebiggest  demands  for  LRFR  technologies  is  video  surveillance.  As  the  the  numberof  surveillance  cameras  in  the  city  increases,  the  videos  that  captured  willneed  to  be  processed  automatically.  However,  those  videos  or  images  are  usuallycaptured  with  large  standoffs,  arbitrary  illumination  condition,  and  diverseangles  of  view.  Faces  in  these  images  are  generally  small  in  size.  Severalstudies  addressed  this  problem  employed  techniques  like  super  resolution,deblurring,  or  learning  a  relationship  between  different  resolution  domains.  Inthis  paper,  we  provide  a  comprehensive  review  of  approaches  to  low-resolutionface  recognition  in  the  past  five  years.  First,  a  general  problem  definition  isgiven.  Later,  systematically  analysis  of  the  works  on  this  topic  is  presentedby  catogory.  In  addition  to  describing  the  methods,  we  also  focus  on  datasetsand  experiment  settings.  We  further  address  the  related  works  on  unconstrainedlow-resolution  face  recognition  and  compare  them  with  the  result  that  usesynthetic  low-resolution  data.  Finally,  we  summarized  the  general  limitationsand  speculate  a  priorities  for  the  future  effort.</p>|2019-04-01  22:52:19.491086
http://arxiv.org/abs/1805.11529|On  Low-Resolution  Face  Recognition  in  the  Wild:  Comparisons  and  New  Techniques.  (arXiv:1805.11529v2  [cs.CV]  UPDATED)|<p>Although  face  recognition  systems  have  achieved  impressive  performance  inrecent  years,  the  low-resolution  face  recognition  (LRFR)  task  remainschallenging,  especially  when  the  LR  faces  are  captured  under  non-idealconditions,  as  is  common  in  surveillance-based  applications.  Faces  captured  insuch  conditions  are  often  contaminated  by  blur,  nonuniform  lighting,  andnonfrontal  face  pose.  In  this  paper,  we  analyze  face  recognition  techniquesusing  data  captured  under  low-quality  conditions  in  the  wild.  We  provide  acomprehensive  analysis  of  experimental  results  for  two  of  the  most  importantapplications  in  real  surveillance  applications,  and  demonstrate  practicalapproaches  to  handle  both  cases  that  show  promising  performance.  The  followingthree  contributions  are  made:  {\em  (i)}  we  conduct  experiments  to  evaluatesuper-resolution  methods  for  low-resolution  face  recognition;  {\em  (ii)}  westudy  face  re-identification  on  various  public  face  datasets  including  realsurveillance  and  low-resolution  subsets  of  large-scale  datasets,  present  abaseline  result  for  several  deep  learning  based  approaches,  and  improve  them  byintroducing  a  GAN  pre-training  approach  and  fully  convolutional  architecture;and  {\em  (iii)}  we  explore  low-resolution  face  identification  by  employing  astate-of-the-art  supervised  discriminative  learning  approach.  Evaluations  areconducted  on  challenging  portions  of  the  SCFace  and  UCCSface  datasets.</p>|2019-04-01  22:52:19.491118
http://arxiv.org/abs/1806.01825|The  Effect  of  Planning  Shape  on  Dyna-style  Planning  in  High-dimensional  State  Spaces.  (arXiv:1806.01825v3  [cs.AI]  UPDATED)|<p>Dyna  is  a  fundamental  approach  to  model-based  reinforcement  learning  (MBRL)that  interleaves  planning,  acting,  and  learning  in  an  online  setting.  In  themost  typical  application  of  Dyna,  the  dynamics  model  is  used  to  generateone-step  transitions  from  selected  start  states  from  the  agent's  history,  whichare  used  to  update  the  agent's  value  function  or  policy  as  if  they  were  realexperiences.  In  this  work,  one-step  Dyna  was  applied  to  several  games  from  theArcade  Learning  Environment  (ALE).  We  found  that  the  model-based  updatesoffered  surprisingly  little  benefit  over  simply  performing  more  updates  withthe  agent's  existing  experience,  even  when  using  a  perfect  model.  Wehypothesize  that  to  get  the  most  from  planning,  the  model  must  be  used  togenerate  unfamiliar  experience.  To  test  this,  we  experimented  with  the  "shape"of  planning  in  multiple  different  concrete  instantiations  of  Dyna,  performingfewer,  longer  rollouts,  rather  than  many  short  rollouts.  We  found  that  planningshape  has  a  profound  impact  on  the  efficacy  of  Dyna  for  both  perfect  andlearned  models.  In  addition  to  these  findings  regarding  Dyna  in  general,  ourresults  represent,  to  our  knowledge,  the  first  time  that  a  learned  dynamicsmodel  has  been  successfully  used  for  planning  in  the  ALE,  suggesting  that  Dynamay  be  a  viable  approach  to  MBRL  in  the  ALE  and  other  high-dimensionalproblems.</p>|2019-04-01  22:52:19.491149
http://arxiv.org/abs/1806.07307|Estimation  from  Non-Linear  Observations  via  Convex  Programming  with  Application  to  Bilinear  Regression.  (arXiv:1806.07307v2  [stat.ML]  UPDATED)|<p>We  propose  a  computationally  efficient  estimator,  formulated  as  a  convexprogram,  for  a  broad  class  of  non-linear  regression  problems  that  involvedifference  of  convex  (DC)  non-linearities.  The  proposed  method  can  be  viewed  asa  significant  extension  of  the  "anchored  regression"  method  formulated  andanalyzed  in  [10]  for  regression  with  convex  non-linearities.  Our  mainassumption,  in  addition  to  other  mild  statistical  and  computationalassumptions,  is  availability  of  a  certain  approximation  oracle  for  the  averageof  the  gradients  of  the  observation  functions  at  a  ground  truth.  Under  thisassumption  and  using  a  PAC-Bayesian  analysis  we  show  that  the  proposedestimator  produces  an  accurate  estimate  with  high  probability.  As  a  concreteexample,  we  study  the  proposed  framework  in  the  bilinear  regression  problemwith  Gaussian  factors  and  quantify  a  sufficient  sample  complexity  for  exactrecovery.  Furthermore,  we  describe  a  computationally  tractable  scheme  thatprovably  produces  the  required  approximation  oracle  in  the  considered  bilinearregression  problem.</p>|2019-04-01  22:52:19.491179
http://arxiv.org/abs/1806.11306|Excavate  Condition-invariant  Space  by  Intrinsic  Encoder.  (arXiv:1806.11306v4  [cs.CV]  UPDATED)|<p>As  the  human,  we  can  recognize  the  places  across  a  wide  range  of  changingenvironmental  conditions  such  as  those  caused  by  weathers,  seasons,  andday-night  cycles.  We  excavate  and  memorize  the  stable  semantic  structure  ofdifferent  places  and  scenes.  For  example,  we  can  recognize  tree  whether  thebare  tree  in  winter  or  lush  tree  in  summer.  Therefore,  the  intrinsic  featuresthat  are  corresponding  to  specific  semantic  contents  and  condition-invariant  ofappearance  changes  can  be  employed  to  improve  the  performance  of  long-termplace  recognition  significantly.</p><p>In  this  paper,  we  propose  a  novel  intrinsic  encoder  that  excavates  thecondition-invariant  latent  space  of  different  places  under  drastic  appearancechanges.  Our  method  excavates  the  space  of  intrinsic  structure  and  semanticinformation  by  proposed  self-supervised  encoder  loss.  Different  from  previouslearning  based  place  recognition  methods  that  need  paired  training  data  of  eachplace  with  appearance  changes,  we  employ  the  weakly-supervised  strategy  toutilize  unpaired  set-based  training  data  of  different  environmental  conditions.</p><p>We  conduct  comprehensive  experiments  and  show  that  our  semi-supervisedintrinsic  encoder  achieves  remarkable  performance  for  place  recognition  underdrastic  appearance  changes.  The  proposed  intrinsic  encoder  outperforms  thestate-of-the-art  image-level  place  recognition  methods  on  standard  benchmarkNordland.</p>|2019-04-01  22:52:19.491210
http://arxiv.org/abs/1807.01697|Benchmarking  Neural  Network  Robustness  to  Common  Corruptions  and  Surface  Variations.  (arXiv:1807.01697v4  [cs.LG]  UPDATED)|<p>In  this  paper  we  establish  rigorous  benchmarks  for  image  classifierrobustness.  Our  first  benchmark,  ImageNet-C,  standardizes  and  expands  thecorruption  robustness  topic,  while  showing  which  classifiers  are  preferable  insafety-critical  applications.  Unlike  recent  robustness  research,  this  benchmarkevaluates  performance  on  commonplace  corruptions  not  worst-case  adversarialcorruptions.  We  find  that  there  are  negligible  changes  in  relative  corruptionrobustness  from  AlexNet  to  ResNet  classifiers,  and  we  discover  ways  to  enhancecorruption  robustness.  Then  we  propose  a  new  dataset  called  Icons-50  whichopens  research  on  a  new  kind  of  robustness,  surface  variation  robustness.  Withthis  dataset  we  evaluate  the  frailty  of  classifiers  on  new  styles  of  knownobjects  and  unexpected  instances  of  known  classes.  We  also  demonstrate  twomethods  that  improve  surface  variation  robustness.  Together  our  benchmarks  mayaid  future  work  toward  networks  that  learn  fundamental  class  structure  and  alsorobustly  generalize.</p>|2019-04-01  22:52:19.491240
http://arxiv.org/abs/1807.02631|Some  Insights  on  Synthesizing  Optimal  Linear  Quadratic  Controller  Using  Krotov's  Sufficiency  Conditions.  (arXiv:1807.02631v2  [math.OC]  UPDATED)|<p>This  paper  revisits  the  problem  of  optimal  control  law  design  for  linearsystems  using  the  global  optimal  control  framework  introduced  by  Vadim  Krotov.Krotov's  approach  is  based  on  the  idea  of  total  decomposition  of  the  originaloptimal  control  problem  (OCP)  with  respect  to  time,  by  an  $ad$  $hoc$  choice  ofthe  so-called  Krotov's  function  or  solving  function,  thereby  providingsufficient  conditions  for  the  existence  of  global  solution  based  on  anotheroptimization  problem,  which  is  completely  equivalent  to  the  original  OCP.  It  iswell  known  that  the  solution  of  this  equivalent  optimization  problem  isobtained  using  an  iterative  method.  In  this  paper,  we  propose  suitable  Krotov'sfunctions  for  linear  quadratic  OCP  and  subsequently,  show  that  by  imposingconvexity  condition  on  this  equivalent  optimization  problem,  there  is  no  needto  compute  an  iterative  solution.  We  also  give  some  key  insights  into  thesolution  procedure  of  the  linear  quadratic  OCP  using  the  proposed  methodologyin  contrast  to  the  celebrated  Calculus  of  Variations  (CoV)  andHamilton-Jacobi-Bellman  (HJB)  equation  based  approach.</p>|2019-04-01  22:52:19.491270
http://arxiv.org/abs/1807.07560|Compositional  GAN:  Learning  Image-Conditional  Binary  Composition.  (arXiv:1807.07560v3  [cs.CV]  UPDATED)|<p>Generative  Adversarial  Networks  (GANs)  can  produce  images  of  remarkablecomplexity  and  realism  but  are  generally  structured  to  sample  from  a  singlelatent  source  ignoring  the  explicit  spatial  interaction  between  multipleentities  that  could  be  present  in  a  scene.  Capturing  such  complex  interactionsbetween  different  objects  in  the  world,  including  their  relative  scaling,spatial  layout,  occlusion,  or  viewpoint  transformation  is  a  challengingproblem.  In  this  work,  we  propose  a  novel  self-consistentComposition-by-Decomposition  (CoDe)  network  to  compose  a  pair  of  objects.  Givenobject  images  from  two  distinct  distributions,  our  model  can  generate  arealistic  composite  image  from  their  joint  distribution  following  the  textureand  shape  of  the  input  objects.  We  evaluate  our  approach  through  qualitativeexperiments  and  user  evaluations.  Our  results  indicate  that  the  learned  modelcaptures  potential  interactions  between  the  two  object  domains,  and  generatesrealistic  composed  scenes  at  test  time.</p>|2019-04-01  22:52:19.491301
http://arxiv.org/abs/1807.08284|Predicting  breast  tumor  proliferation  from  whole-slide  images:  the  TUPAC16  challenge.  (arXiv:1807.08284v2  [cs.CV]  UPDATED)|<p>Tumor  proliferation  is  an  important  biomarker  indicative  of  the  prognosis  ofbreast  cancer  patients.  Assessment  of  tumor  proliferation  in  a  clinical  settingis  highly  subjective  and  labor-intensive  task.  Previous  efforts  to  automatetumor  proliferation  assessment  by  image  analysis  only  focused  on  mitosisdetection  in  predefined  tumor  regions.  However,  in  a  real-world  scenario,automatic  mitosis  detection  should  be  performed  in  whole-slide  images  (WSIs)and  an  automatic  method  should  be  able  to  produce  a  tumor  proliferation  scoregiven  a  WSI  as  input.  To  address  this,  we  organized  the  TUmor  ProliferationAssessment  Challenge  2016  (TUPAC16)  on  prediction  of  tumor  proliferation  scoresfrom  WSIs.  The  challenge  dataset  consisted  of  500  training  and  321  testingbreast  cancer  histopathology  WSIs.  In  order  to  ensure  fair  and  independentevaluation,  only  the  ground  truth  for  the  training  dataset  was  provided  to  thechallenge  participants.  The  first  task  of  the  challenge  was  to  predict  mitoticscores,  i.e.,  to  reproduce  the  manual  method  of  assessing  tumor  proliferationby  a  pathologist.  The  second  task  was  to  predict  the  gene  expression  basedPAM50  proliferation  scores  from  the  WSI.  The  best  performing  automatic  methodfor  the  first  task  achieved  a  quadratic-weighted  Cohen's  kappa  score  of$\kappa$  =  0.567,  95%  CI  [0.464,  0.671]  between  the  predicted  scores  and  theground  truth.  For  the  second  task,  the  predictions  of  the  top  method  had  aSpearman's  correlation  coefficient  of  r  =  0.617,  95%  CI  [0.581  0.651]  with  theground  truth.  This  was  the  first  study  that  investigated  tumor  proliferationassessment  from  WSIs.  The  achieved  results  are  promising  given  the  difficultyof  the  tasks  and  weakly-labelled  nature  of  the  ground  truth.  However,  furtherresearch  is  needed  to  improve  the  practical  utility  of  image  analysis  methodsfor  this  task.</p>|2019-04-01  22:52:19.491332
http://arxiv.org/abs/1809.02223|Character-Aware  Decoder  for  Translation  into  Morphologically  Rich  Languages.  (arXiv:1809.02223v4  [cs.CL]  UPDATED)|<p>Neural  machine  translation  (NMT)  systems  operate  primarily  on  words  (orsubwords),  ignoring  lower-level  patterns  of  morphology.  We  present  acharacter-aware  decoder  designed  to  capture  such  patterns  when  translating  intomorphologically  rich  languages.  We  achieve  character-awareness  by  augmentingboth  the  softmax  and  embedding  layers  of  an  attention-based  encoder-decodermodel  with  convolutional  neural  networks  that  operate  on  the  spelling  of  aword.  To  investigate  performance  on  a  wide  variety  of  morphological  phenomena,we  translate  English  into  $14$  typologically  diverse  target  languages  using  theTED  multi-target  dataset.  In  this  low-resource  setting,  the  character-awaredecoder  provides  consistent  improvements  with  BLEU  score  gains  of  up  to$+3.05$.  In  addition,  we  analyze  the  relationship  between  the  gains  obtainedand  properties  of  the  target  language  and  find  evidence  that  our  model  doesindeed  exploit  morphological  patterns.</p>|2019-04-01  22:52:19.491363
http://arxiv.org/abs/1809.05929|Solving  for  multi-class:  a  survey  and  synthesis.  (arXiv:1809.05929v4  [stat.ML]  UPDATED)|<p>We  review  common  methods  of  solving  for  multi-class  from  binary  andgeneralize  them  to  a  common  framework.  Since  conditional  probabilties  areuseful  both  for  quantifying  the  accuracy  of  an  estimate  and  for  calibrationpurposes,  these  are  a  required  part  of  the  solution.  There  is  some  indicationthat  the  best  solution  for  multi-class  classification  is  dependent  on  theparticular  dataset.  As  such,  we  are  especially  interested  in  data-drivensolution  design,  whether  based  on  a  priori  considerations  or  empiricalexamination  of  the  data.  Numerical  results  indicate  that  while  aone-size-fits-all  solution  consisting  of  one-versus-one  is  appropriate  for  mostdatasets,  a  minority  will  benefit  from  a  more  customized  approach.  Thetechniques  discussed  in  this  paper  allow  for  a  large  variety  of  multi-classconfigurations  and  solution  methods  to  be  explored  so  as  to  optimizeclassification  accuracy,  accuracy  of  conditional  probabilities  and  speed.</p>|2019-04-01  22:52:19.491417
http://arxiv.org/abs/1809.10243|Segmentation  of  Skin  Lesions  and  their  Attributes  Using  Multi-Scale  Convolutional  Neural  Networks  and  Domain  Specific  Augmentations.  (arXiv:1809.10243v3  [cs.CV]  UPDATED)|<p>Computer-aided  diagnosis  systems  for  classification  of  different  type  of  skinlesions  have  been  an  active  field  of  research  in  recent  decades.  It  has  beenshown  that  introducing  lesions  and  their  attributes  masks  into  lesionclassification  pipeline  can  greatly  improve  the  performance.  In  this  paper,  wepropose  a  framework  by  incorporating  transfer  learning  for  segmenting  lesionsand  their  attributes  based  on  the  convolutional  neural  networks.  The  proposedframework  is  based  on  the  encoder-decoder  architecture  which  utilizes  a  varietyof  pre-trained  networks  in  the  encoding  path  and  generates  the  prediction  mapby  combining  multi-scale  information  in  decoding  path  using  a  pyramid  poolingmanner.  To  address  the  lack  of  training  data  and  increase  the  proposed  modelgeneralization,  an  extensive  set  of  novel  domain-specific  augmentation  routineshave  been  applied  to  simulate  the  real  variations  in  dermoscopy  images.Finally,  by  performing  broad  experiments  on  three  different  data  sets  obtainedfrom  International  Skin  Imaging  Collaboration  archive  (ISIC2016,  ISIC2017,  andISIC2018  challenges  data  sets),  we  show  that  the  proposed  method  outperformsother  state-of-the-art  approaches  for  ISIC2016  and  ISIC2017  segmentation  taskand  achieved  the  first  rank  on  the  leader-board  of  ISIC2018  attribute  detectiontask.</p>|2019-04-01  22:52:19.491451
http://arxiv.org/abs/1810.04369|$\epsilon$-Nash  Equilibria  for  Major  Minor  LQG  Mean  Field  Games  with  Partial  Observations  of  All  Agents.  (arXiv:1810.04369v2  [math.OC]  UPDATED)|<p>The  partially  observed  major  minor  LQG  and  nonlinear  mean  field  game  (PO  MMLQG  MFG)  systems  where  it  is  assumed  the  major  agent's  state  is  partiallyobserved  by  each  minor  agent,  and  the  major  agent  completely  observes  its  ownstate  have  been  analysed  in  the  literature.  In  this  paper,  PO  MM  LQG  MFGproblems  with  general  information  patterns  are  studied  where  (i)  the  majoragent  has  partial  observations  of  its  own  state,  and  (ii)  each  minor  agent  haspartial  observations  of  its  own  state  and  the  major  agent's  state.  Theassumption  of  partial  observations  by  all  agents  leads  to  a  new  situationinvolving  the  recursive  estimation  by  each  minor  agent  of  the  major  agent'sestimate  of  its  own  state.  For  a  general  case  of  indefinite  LQG  MFG  systems,the  existence  of  $\epsilon$-Nash  equilibria  together  with  the  individualagents'  control  laws  yielding  the  equilibria  are  established  via  the  SeparationPrinciple.</p>|2019-04-01  22:52:19.491486
http://arxiv.org/abs/1810.09948|Comments  on  "Towards  Unambiguous  Edge  Bundling:  Investigating  Confluent  Drawings  for  Network  Visualization".  (arXiv:1810.09948v2  [cs.CG]  UPDATED)|<p>Bach  et  al.  [1]  recently  presented  an  algorithm  for  constructing  confluentdrawings,  by  leveraging  power  graph  decomposition  to  generate  an  auxiliaryrouting  graph.  We  identify  two  problems  with  their  method  and  offer  a  singlesolution  to  solve  both.  We  then  recognize  a  limitation  regarding  planarity,  andhelp  to  guide  future  research  by  introducing  a  new  classification  of'power-confluent'  drawing.</p>|2019-04-01  22:52:19.491518
http://arxiv.org/abs/1811.00656|Exposing  DeepFake  Videos  By  Detecting  Face  Warping  Artifacts.  (arXiv:1811.00656v2  [cs.CV]  UPDATED)|<p>In  this  work,  we  describe  a  new  deep  learning  based  method  that  caneffectively  distinguish  AI-generated  fake  videos  (referred  to  as  {\em  DeepFake}videos  hereafter)  from  real  videos.  Our  method  is  based  on  the  observationsthat  current  DeepFake  algorithm  can  only  generate  images  of  limitedresolutions,  which  need  to  be  further  warped  to  match  the  original  faces  in  thesource  video.  Such  transforms  leave  distinctive  artifacts  in  the  resultingDeepFake  videos,  and  we  show  that  they  can  be  effectively  captured  byconvolutional  neural  networks  (CNNs).  Compared  to  previous  methods  which  use  alarge  amount  of  real  and  DeepFake  generated  images  to  train  CNN  classifier,  ourmethod  does  not  need  DeepFake  generated  images  as  negative  training  examplessince  we  target  the  artifacts  in  affine  face  warping  as  the  distinctive  featureto  distinguish  real  and  fake  images.  The  advantages  of  our  method  are  two-fold:(1)  Such  artifacts  can  be  simulated  directly  using  simple  image  processingoperations  on  a  image  to  make  it  as  negative  example.  Since  training  a  DeepFakemodel  to  generate  negative  examples  is  time-consuming  and  resource-demanding,our  method  saves  a  plenty  of  time  and  resources  in  training  data  collection;(2)  Since  such  artifacts  are  general  existed  in  DeepFake  videos  from  differentsources,  our  method  is  more  robust  compared  to  others.  Our  method  is  evaluatedon  two  sets  of  DeepFake  video  datasets  for  its  effectiveness  in  practice.</p>|2019-04-01  22:52:19.491549
http://arxiv.org/abs/1811.03199|Confusion2Vec:  Towards  Enriching  Vector  Space  Word  Representations  with  Representational  Ambiguities.  (arXiv:1811.03199v2  [cs.CL]  UPDATED)|<p>Word  vector  representations  are  a  crucial  part  of  Natural  Language  Processing(NLP)  and  Human  Computer  Interaction.  In  this  paper,  we  propose  a  novel  wordvector  representation,  Confusion2Vec,  motivated  from  the  human  speechproduction  and  perception  that  encodes  representational  ambiguity.  Humansemploy  both  acoustic  similarity  cues  and  contextual  cues  to  decode  informationand  we  focus  on  a  model  that  incorporates  both  sources  of  information.  Therepresentational  ambiguity  of  acoustics,  which  manifests  itself  in  wordconfusions,  is  often  resolved  by  both  humans  and  machines  through  contextualcues.  A  range  of  representational  ambiguities  can  emerge  in  various  domainsfurther  to  acoustic  perception,  such  as  morphological  transformations,paraphrasing  for  NLP  tasks  like  machine  translation  etc.  In  this  work,  wepresent  a  case  study  in  application  to  Automatic  Speech  Recognition  (ASR),where  the  word  confusions  are  related  to  acoustic  similarity.  We  presentseveral  techniques  to  train  an  acoustic  perceptual  similarity  representationambiguity.  We  term  this  Confusion2Vec  and  learn  on  unsupervised-generated  datafrom  ASR  confusion  networks  or  lattice-like  structures.  Appropriate  evaluationsfor  the  Confusion2Vec  are  formulated  for  gauging  acoustic  similarity  inaddition  to  semantic-syntactic  and  word  similarity  evaluations.  TheConfusion2Vec  is  able  to  model  word  confusions  efficiently,  withoutcompromising  on  the  semantic-syntactic  word  relations,  thus  effectivelyenriching  the  word  vector  space  with  extra  task  relevant  ambiguity  information.We  provide  an  intuitive  exploration  of  the  2-dimensional  Confusion2Vec  spaceusing  Principal  Component  Analysis  of  the  embedding  and  relate  to  semantic,syntactic  and  acoustic  relationships.  The  potential  of  Confusion2Vec  in  theutilization  of  uncertainty  present  in  lattices  is  demonstrated  through  smallexamples  relating  to  ASR  error  correction.</p>|2019-04-01  22:52:19.491582
http://arxiv.org/abs/1811.03706|Maximizing  Diversity  of  Opinion  in  Social  Networks.  (arXiv:1811.03706v2  [math.OC]  UPDATED)|<p>We  study  the  problem  of  maximizing  opinion  diversity  in  a  social  network  thatincludes  opinion  leaders  with  binary  opposing  opinions.  The  members  of  thenetwork  who  are  not  leaders  form  their  opinions  using  the  French-DeGroot  modelof  opinion  dynamics.  To  quantify  the  diversity  of  such  a  system,  we  adapt  twodiversity  measures  from  ecology  to  our  setting,  the  Simpson  Diversity  Index  andthe  Shannon  Index.  Using  these  two  measures,  we  formalize  the  problem  of  how  toplace  a  single  leader  with  opinion  1,  given  a  network  with  a  leader  withopinion  0,  so  as  to  maximize  the  opinion  diversity.  We  give  analyticalsolutions  to  these  problems  for  paths,  cycles,  and  trees,  and  we  highlight  ourresults  through  a  numerical  example.</p>|2019-04-01  22:52:19.491612
http://arxiv.org/abs/1811.04918|Learning  and  Generalization  in  Overparameterized  Neural  Networks,  Going  Beyond  Two  Layers.  (arXiv:1811.04918v4  [cs.LG]  UPDATED)|<p>Neural  networks  have  great  success  in  many  machine  learning  applications,  butthe  fundamental  learning  theory  behind  them  remains  largely  unsolved.  Learningneural  networks  is  NP-hard,  but  in  practice,  simple  algorithms  like  stochasticgradient  descent  (SGD)  often  produce  good  solutions.  Moreover,  it  is  observedthat  overparameterization  (that  is,  designing  networks  whose  number  ofparameters  is  larger  than  statistically  needed  to  perfectly  fit  the  trainingdata)  improves  both  optimization  and  generalization,  appearing  to  contradicttraditional  learning  theory.</p><p>In  this  work,  we  prove  that  using  overparameterized  neural  networks  withrectified  linear  units,  one  can  (improperly)  learn  some  notable  hypothesisclasses,  including  two  and  three-layer  neural  networks  with  fewer  parametersand  smooth  activations.  Moreover,  the  learning  process  can  be  simply  done  bySGD  or  its  variants  in  polynomial  time  using  polynomially  many  samples.  We  alsoshow  that  for  a  fixed  sample  size,  the  population  risk  of  the  solution  found  bysome  SGD  variant  can  be  made  almost  independent  of  the  number  of  parameters  inthe  overparameterized  network.</p>|2019-04-01  22:52:19.491643
http://arxiv.org/abs/1811.07619|Adversarial  Soft-detection-based  Aggregation  Network  for  Image  Retrieval.  (arXiv:1811.07619v3  [cs.CV]  UPDATED)|<p>In  recent  year,  the  compact  representations  based  on  activations  ofConvolutional  Neural  Network  (CNN)  achieve  remarkable  performance  in  imageretrieval.  However,  retrieval  of  some  interested  object  that  only  takes  up  asmall  part  of  the  whole  image  is  still  a  challenging  problem.  Therefore,  it  issignificant  to  extract  the  discriminative  representations  that  contain  regionalinformation  of  the  pivotal  small  object.  In  this  paper,  we  propose  a  noveladversarial  soft-detection-based  aggregation  (ASDA)  method  free  from  boundingbox  annotations  for  image  retrieval,  based  on  adversarial  detector  and  softregion  proposal  layer.  Our  trainable  adversarial  detector  generates  semanticmaps  based  on  adversarial  erasing  strategy  to  preserve  more  discriminative  anddetailed  information.  Computed  based  on  semantic  maps  corresponding  to  variousdiscriminative  patterns  and  semantic  contents,  our  soft  region  proposal  isarbitrary  shape  rather  than  only  rectangle  and  it  reflects  the  significance  ofobjects.  The  aggregation  based  on  trainable  soft  region  proposal  highlightsdiscriminative  semantic  contents  and  suppresses  the  noise  of  background.</p><p>We  conduct  comprehensive  experiments  on  standard  image  retrieval  datasets.Our  weakly  supervised  ASDA  method  achieves  state-of-the-art  performance  on  mostdatasets.  The  results  demonstrate  that  the  proposed  ASDA  method  is  effectivefor  image  retrieval.</p>|2019-04-01  22:52:19.491674
http://arxiv.org/abs/1811.10719|Learning  View  Priors  for  Single-view  3D  Reconstruction.  (arXiv:1811.10719v2  [cs.CV]  UPDATED)|<p>There  is  some  ambiguity  in  the  3D  shape  of  an  object  when  the  number  ofobserved  views  is  small.  Because  of  this  ambiguity,  although  a  3D  objectreconstructor  can  be  trained  using  a  single  view  or  a  few  views  per  object,reconstructed  shapes  only  fit  the  observed  views  and  appear  incorrect  from  theunobserved  viewpoints.  To  reconstruct  shapes  that  look  reasonable  from  anyviewpoint,  we  propose  to  train  a  discriminator  that  learns  prior  knowledgeregarding  possible  views.  The  discriminator  is  trained  to  distinguish  thereconstructed  views  of  the  observed  viewpoints  from  those  of  the  unobservedviewpoints.  The  reconstructor  is  trained  to  correct  unobserved  views  by  foolingthe  discriminator.  Our  method  outperforms  current  state-of-the-art  methods  onboth  synthetic  and  natural  image  datasets;  this  validates  the  effectiveness  ofour  method.</p>|2019-04-01  22:52:19.491704
http://arxiv.org/abs/1811.11742|3D  human  pose  estimation  in  video  with  temporal  convolutions  and  semi-supervised  training.  (arXiv:1811.11742v2  [cs.CV]  UPDATED)|<p>In  this  work,  we  demonstrate  that  3D  poses  in  video  can  be  effectivelyestimated  with  a  fully  convolutional  model  based  on  dilated  temporalconvolutions  over  2D  keypoints.  We  also  introduce  back-projection,  a  simple  andeffective  semi-supervised  training  method  that  leverages  unlabeled  video  data.We  start  with  predicted  2D  keypoints  for  unlabeled  video,  then  estimate  3Dposes  and  finally  back-project  to  the  input  2D  keypoints.  In  the  supervisedsetting,  our  fully-convolutional  model  outperforms  the  previous  best  resultfrom  the  literature  by  6  mm  mean  per-joint  position  error  on  Human3.6M,corresponding  to  an  error  reduction  of  11%,  and  the  model  also  showssignificant  improvements  on  HumanEva-I.  Moreover,  experiments  withback-projection  show  that  it  comfortably  outperforms  previous  state-of-the-artresults  in  semi-supervised  settings  where  labeled  data  is  scarce.  Code  andmodels  are  available  at  https://github.com/facebookresearch/VideoPose3D</p>|2019-04-01  22:52:19.491734
http://arxiv.org/abs/1811.12197|Iterative  Residual  CNNs  for  Burst  Photography  Applications.  (arXiv:1811.12197v2  [cs.CV]  UPDATED)|<p>Modern  inexpensive  imaging  sensors  suffer  from  inherent  hardware  constraintswhich  often  result  in  captured  images  of  poor  quality.  Among  the  most  commonways  to  deal  with  such  limitations  is  to  rely  on  burst  photography,  whichnowadays  acts  as  the  backbone  of  all  modern  smartphone  imaging  applications.  Inthis  work,  we  focus  on  the  fact  that  every  frame  of  a  burst  sequence  can  beaccurately  described  by  a  forward  (physical)  model.  This  in  turn  allows  us  torestore  a  single  image  of  higher  quality  from  a  sequence  of  low  quality  imagesas  the  solution  of  an  optimization  problem.  Inspired  by  an  extension  of  thegradient  descent  method  that  can  handle  non-smooth  functions,  namely  theproximal  gradient  descent,  and  modern  deep  learning  techniques,  we  propose  aconvolutional  iterative  network  with  a  transparent  architecture.  Our  network,uses  a  burst  of  low  quality  image  frames  and  is  able  to  produce  an  output  ofhigher  image  quality  recovering  fine  details  which  are  not  distinguishable  inany  of  the  original  burst  frames.  We  focus  both  on  the  burst  photographypipeline  as  a  whole,  i.e.  burst  demosaicking  and  denoising,  as  well  as  on  thetraditional  Gaussian  denoising  task.  The  developed  method  demonstratesconsistent  state-of-the  art  performance  across  the  two  tasks  and  as  opposed  toother  recent  deep  learning  approaches  does  not  have  any  inherent  restrictionseither  to  the  number  of  frames  or  their  ordering.  Code  can  be  found  athttps://fkokkinos.github.io/deep_burst/</p>|2019-04-01  22:52:19.491765
http://arxiv.org/abs/1811.12784|The  GAN  that  Warped:  Semantic  Attribute  Editing  with  Unpaired  Data.  (arXiv:1811.12784v2  [cs.CV]  UPDATED)|<p>Deep  neural  networks  have  recently  been  used  to  edit  images  with  greatsuccess,  in  particular  for  faces.  However,  they  are  often  limited  to  only  beingable  to  work  at  a  restricted  range  of  resolutions.  Many  methods  are  so  flexiblethat  face  edits  can  often  result  in  an  unwanted  loss  of  identity.  This  workproposes  to  learn  how  to  perform  semantic  image  edits  through  the  applicationof  smooth  warp  fields.  Previous  approaches  that  attempted  to  use  warping  forsemantic  edits  required  paired  data,  i.e.  example  images  of  the  same  subjectwith  different  semantic  attributes.  In  contrast,  we  employ  recent  advances  inGenerative  Adversarial  Networks  that  allow  our  model  to  be  trained  withunpaired  data.  We  demonstrate  face  editing  at  very  high  resolutions  (4k  images)with  a  single  forward  pass  of  a  deep  network  at  a  lower  resolution.  We  alsoshow  that  our  edits  are  substantially  better  at  preserving  the  subject'sidentity.</p>|2019-04-01  22:52:19.491795
http://arxiv.org/abs/1812.00573|Towards  Visual  Feature  Translation.  (arXiv:1812.00573v2  [cs.CV]  UPDATED)|<p>Most  existing  visual  search  systems  are  deployed  based  upon  fixed  kinds  ofvisual  features,  which  prohibits  the  feature  reusing  across  different  systemsor  when  upgrading  systems  with  a  new  type  of  feature.  Such  a  setting  isobviously  inflexible  and  time/memory  consuming,  which  is  indeed  mendable  ifvisual  features  can  be  "translated"  across  systems.  In  this  paper,  we  make  thefirst  attempt  towards  visual  feature  translation  to  break  through  the  barrierof  using  features  across  different  visual  search  systems.  To  this  end,  wepropose  a  Hybrid  Auto-Encoder  (HAE)  to  translate  visual  features,  which  learnsa  mapping  by  minimizing  the  translation  and  reconstruction  errors.  Based  uponHAE,  an  Undirected  Affinity  Measurement  (UAM)  is  further  designed  to  quantifythe  affinity  among  different  types  of  visual  features.  Extensive  experimentshave  been  conducted  on  several  public  datasets  with  sixteen  different  types  ofwidely-used  features  in  visual  search  systems.  Quantitative  results  show  theencouraging  possibilities  of  feature  translation.  For  the  first  time,  theaffinity  among  widely-used  features  like  SIFT  and  DELF  is  reported.</p>|2019-04-01  22:52:19.491826
http://arxiv.org/abs/1812.01946|Unsupervised  Generation  of  Optical  Flow  Datasets.  (arXiv:1812.01946v3  [cs.CV]  UPDATED)|<p>Dense  optical  flow  ground  truths  of  non-rigid  motion  for  real-world  imagesare  not  available  due  to  the  non-intuitive  annotation.  Aiming  at  trainingoptical  flow  deep  networks,  we  present  an  unsupervised  algorithm  to  generateoptical  flow  ground  truth  from  real-world  videos.  The  algorithm  extracts  andmatches  objects  of  interest  from  pairs  of  images  in  videos  to  find  initialconstraints,  and  applies  as-rigid-as-possible  deformation  over  the  objects  ofinterest  to  obtain  dense  flow  fields.  The  ground  truth  correctness  is  enforcedby  warping  the  objects  in  the  first  frames  using  the  flow  fields.  We  apply  thealgorithm  on  the  DAVIS  dataset  to  obtain  optical  flow  ground  truths  fornon-rigid  movement  of  real-world  objects,  using  either  ground  truth  orpredicted  segmentation.  We  discuss  several  methods  to  increase  the  optical  flowvariations  in  the  dataset.  Extensive  experimental  results  show  that  training  onnon-rigid  real  motion  is  beneficial  compared  to  training  on  rigid  syntheticdata.  Moreover,  we  show  that  our  pipeline  generates  training  data  suitable  totrain  successfully  FlowNet-S,  PWC-Net,  and  LiteFlowNet  deep  networks.</p>|2019-04-01  22:52:19.491857
http://arxiv.org/abs/1812.02849|A  Survey  of  Unsupervised  Deep  Domain  Adaptation.  (arXiv:1812.02849v2  [cs.LG]  UPDATED)|<p>Deep  learning  has  produced  state-of-the-art  results  for  a  variety  of  tasks.While  such  approaches  for  supervised  learning  have  performed  well,  they  assumethat  training  and  testing  data  are  drawn  from  the  same  distribution,  which  maynot  always  be  the  case.  As  a  complement  to  this  challenge,  unsupervised  domainadaptation  can  handle  situations  where  a  network  is  trained  on  labeled  datafrom  a  source  domain  and  unlabeled  data  from  a  related  but  different  targetdomain  with  the  goal  of  performing  well  at  test-time  on  the  target  domain.  Manyunsupervised  deep  domain  adaptation  approaches  have  thus  been  developed.  Thissurvey  will  compare  these  approaches  by  examining  alternative  methods,  theunique  and  common  elements,  results,  and  theoretical  insights.  We  follow  thiswith  a  look  at  application  areas  and  open  research  directions.</p>|2019-04-01  22:52:19.491888
http://arxiv.org/abs/1812.03952|A  Scalable  Thermal  Reservoir  Simulator  for  Giant  Models  on  Parallel  Computers.  (arXiv:1812.03952v8  [cs.CE]  UPDATED)|<p>This  paper  introduces  the  model,  numerical  methods,  algorithms  and  parallelimplementation  of  a  thermal  reservoir  simulator  that  designed  for  numericalsimulations  of  thermal  reservoir  with  multiple  components  in  three  dimensionaldomain  using  distributed-memory  parallel  computers.  Its  full  mathematical  modelis  introduced  with  correlations  for  important  properties  and  well  modeling.Various  well  constraints,  such  as  fixed  bottom  hole  pressure,  fixed  oil,  water,gas  and  liquid  rates,  constant  heat  transfer  model,  convective  heat  transfermodel,  heater  model  (temperature  control,  rate  control,  dual  rate/temperaturecontrol),  and  subcool  (steam  trap),  are  introduced  in  details,  including  theirmathematical  models  and  methods.  Efficient  numerical  methods  and  parallelcomputing  technologies  are  presented.  The  simulator  is  designed  for  giantmodels  with  billions  or  even  trillions  of  grid  blocks  using  hundreds  ofthousands  of  CPUs.  Numerical  experiments  show  that  our  results  match  commercialsimulators,  which  confirms  the  correctness  of  our  methods  and  implementations.SAGD  simulation  with  15106  well  pairs  is  also  presented  to  study  theeffectiveness  of  our  numerical  methods.  Scalability  testings  demonstrate  thatour  simulator  can  handle  giant  models  with  over  200  billion  grid  blocks  using98,000  CPU  cores  and  the  simulator  has  good  scalability.</p>|2019-04-01  22:52:19.491920
http://arxiv.org/abs/1812.04948|A  Style-Based  Generator  Architecture  for  Generative  Adversarial  Networks.  (arXiv:1812.04948v3  [cs.NE]  UPDATED)|<p>We  propose  an  alternative  generator  architecture  for  generative  adversarialnetworks,  borrowing  from  style  transfer  literature.  The  new  architecture  leadsto  an  automatically  learned,  unsupervised  separation  of  high-level  attributes(e.g.,  pose  and  identity  when  trained  on  human  faces)  and  stochastic  variationin  the  generated  images  (e.g.,  freckles,  hair),  and  it  enables  intuitive,scale-specific  control  of  the  synthesis.  The  new  generator  improves  thestate-of-the-art  in  terms  of  traditional  distribution  quality  metrics,  leads  todemonstrably  better  interpolation  properties,  and  also  better  disentangles  thelatent  factors  of  variation.  To  quantify  interpolation  quality  anddisentanglement,  we  propose  two  new,  automated  methods  that  are  applicable  toany  generator  architecture.  Finally,  we  introduce  a  new,  highly  varied  andhigh-quality  dataset  of  human  faces.</p>|2019-04-01  22:52:19.491950
http://arxiv.org/abs/1812.06570|Defense-VAE:  A  Fast  and  Accurate  Defense  against  Adversarial  Attacks.  (arXiv:1812.06570v2  [cs.CV]  UPDATED)|<p>Deep  neural  networks  (DNNs)  have  been  enormously  successful  across  a  varietyof  prediction  tasks.  However,  recent  research  shows  that  DNNs  are  particularlyvulnerable  to  adversarial  attacks,  which  poses  a  serous  threat  to  theirapplications  in  security-sensitive  systems.  In  this  paper,  we  propose  a  simpleyet  effective  defense  algorithm  Defense-VAE  that  uses  variational  autoencoder(VAE)  to  purge  adversarial  perturbations  from  contaminated  images.  The  proposedmethod  is  generic  and  can  defend  white-box  and  black-box  attacks  without  theneed  of  retraining  the  original  CNN  classifiers,  and  can  further  strengthen  thedefense  by  retraining  CNN  or  end-to-end  finetuning  the  whole  pipeline.  Inaddition,  the  proposed  method  is  very  efficient  compared  to  theoptimization-based  alternatives,  such  as  Defense-GAN,  since  no  iterativeoptimization  is  needed  for  online  prediction.  Extensive  experiments  on  MNIST,Fashion-MNIST,  CelebA  and  CIFAR-10  demonstrate  the  superior  defense  accuracy  ofDefense-VAE  compared  to  Defense-GAN,  while  being  50x  faster  than  the  latter.This  makes  Defense-VAE  widely  deployable  in  real-time  security-sensitivesystems.  We  plan  to  open  source  our  implementation  to  facilitate  the  researchin  this  area.</p>|2019-04-01  22:52:19.491980
http://arxiv.org/abs/1812.09638|AEPecker:  L0  Adversarial  Examples  are  not  Strong  Enough.  (arXiv:1812.09638v2  [cs.CR]  UPDATED)|<p>Despite  the  great  achievements  made  by  neural  networks  on  tasks  such  as  imageclassification,  they  are  brittle  and  vulnerable  to  adversarial  examples  (AEs).By  adding  adversarial  noise  to  input  images,  adversarial  examples  can  becrafted  to  mislead  neural  network  based  image  classifiers.  One  type  of  AEattack  in  particular,  known  as  an  L0  AE,  has  been  used  in  several  notablereal-world  incidents.  Our  observation  is  that,  while  L0  corruptions  modify  asfew  pixels  as  possible,  they  tend  to  cause  large-amplitude  perturbations  to  themodified  pixels.  We  consider  this  to  be  an  inherent  limitation  of  L0  AEs  whichcan  be  exploited.  To  show  the  weakness  of  L0  AEs,  we  thwart  samples  of  theseattacks  by  both  detecting  and  rectifying  them.  The  main  novelty  of  the  proposeddetector  is  that  we  convert  the  AE  detection  problem  into  an  image  comparisonproblem  by  exploiting  the  inherent  characteristics  of  L0  AEs.  More  concretely,given  an  image  I,  it  is  pre-processed  to  obtain  another  image  I'.  We  use  aSiamese  network  which  is  known  to  be  effective  in  comparison,  to  take  I  and  I'as  the  input  pair.  A  well  trained  Siamese  network  can  automatically  capture  thediscrepancy  between  I  and  I'  to  detect  L0  noises.  In  addition,  thestraightforward  pre-processor  based  on  heuristics  can  be  deployed  as  aneffective  defense,  having  a  high  probability  of  removing  the  adversarialinfluence  of  L0  perturbations.  The  proposed  technique  shows  not  only  a  highaccuracy  but  also  a  resilience  to  the  adaptive  adversary,  which  outperformsother  state-of-the-art  methods.  We  accordingly  argue  that  L0  attacks  are  notstrong  enough.</p>|2019-04-01  22:52:19.492031
http://arxiv.org/abs/1812.11448|Removing  Malicious  Nodes  from  Networks.  (arXiv:1812.11448v6  [cs.SI]  UPDATED)|<p>A  fundamental  challenge  in  networked  systems  is  detection  and  removal  ofsuspected  malicious  nodes.  In  reality,  detection  is  always  imperfect,  and  thedecision  about  which  potentially  malicious  nodes  to  remove  must  trade  off  falsepositives  (erroneously  removing  benign  nodes)  and  false  negatives  (mistakenlyfailing  to  remove  malicious  nodes).  However,  in  network  settings  thisconventional  tradeoff  must  now  account  for  node  connectivity.  In  particular,malicious  nodes  may  exert  malicious  influence,  so  that  mistakenly  leaving  someof  these  in  the  network  may  cause  damage  to  spread.  On  the  other  hand,  removingbenign  nodes  causes  direct  harm  to  these,  and  indirect  harm  to  their  benignneighbors  who  would  wish  to  communicate  with  them.</p><p>We  formalize  the  problem  of  removing  potentially  malicious  nodes  from  anetwork  under  uncertainty  through  an  objective  that  takes  connectivity  intoaccount.  We  show  that  optimally  solving  the  resulting  problem  is  NP-Hard.  Wethen  propose  a  tractable  solution  approach  based  on  a  convex  relaxation  of  theobjective.  Finally,  we  experimentally  demonstrate  that  our  approachsignificantly  outperforms  both  a  simple  baseline  that  ignores  networkstructure,  as  well  as  a  state-of-the-art  approach  for  a  related  problem,  onboth  synthetic  and  real-world  datasets.</p>|2019-04-01  22:52:19.492067
http://arxiv.org/abs/1812.11631|Actor  Conditioned  Attention  Maps  for  Video  Action  Detection.  (arXiv:1812.11631v2  [cs.CV]  UPDATED)|<p>While  observing  complex  events  with  multiple  actors,  humans  do  not  assesseach  actor  separately,  but  infer  from  the  context.  The  surrounding  contextprovides  essential  information  for  understanding  actions.  To  this  end,  wepropose  to  replace  region  of  interest(RoI)  pooling  with  an  attention  module,which  ranks  each  spatio-temporal  region's  relevance  to  a  detected  actor  insteadof  cropping.  We  refer  to  these  as  Actor-Conditioned  Attention  Maps  (ACAM),which  weight  the  features  extracted  from  the  entire  scene.  The  resultingactor-conditioned  features  focus  the  model  on  regions  that  are  relevant  to  theconditioned  actor.  For  actor  localization,  we  leverage  pre-trained  objectdetectors,  which  generalize  better.  The  proposed  model  is  efficient  and  ouraction  detection  pipeline  achieves  near  real-time  performance.  Experimentalresults  on  AVA  2.1  and  JHMDB  demonstrate  the  effectiveness  of  attention  maps,with  improvements  of  5  mAP  on  AVA  and  4  mAP  on  JHMDB.</p>|2019-04-01  22:52:19.492098
http://arxiv.org/abs/1812.11771|Predicting  Group  Cohesiveness  in  Images.  (arXiv:1812.11771v3  [cs.CV]  UPDATED)|<p>Cohesiveness  of  a  group  is  an  essential  indicator  of  emotional  state,structure  and  success  of  a  group  of  people.  We  study  the  factors  that  influencethe  perception  of  group-level  cohesion  and  propose  methods  for  estimating  thehuman-perceived  cohesion  to  the  group  cohesiveness  scale.  In  order  to  identifythe  visual  cues  (attributes)  for  cohesion,  we  conducted  a  user  survey.  Imageanalysis  is  performed  at  a  group-level  via  a  multi-task  convolutional  neuralnetwork.  For  analyzing  the  contribution  of  facial  expressions  of  the  groupmembers  for  predicting  Group  Cohesion  Score  (GCS),  capsule  network  is  explored.We  add  GCS  on  the  Group  Affect  database  and  propose  the  `GAF-Cohesiondatabase'.  The  proposed  model  performs  well  on  the  database  and  is  able  toachieve  near  human-level  performance  in  predicting  group's  cohesion  score.  Itis  interesting  to  note  that  group  cohesion  as  an  attribute,  when  jointlytrained  for  group-level  emotion  prediction,  helps  in  increasing  the  performancefor  the  later  task.  This  suggests  that  group-level  emotion  and  cohesion  arecorrelated.</p>|2019-04-01  22:52:19.492128
http://arxiv.org/abs/1901.00224|Ancient  Painting  to  Natural  Image:  A  New  Solution  for  Painting  Processing.  (arXiv:1901.00224v2  [cs.CV]  UPDATED)|<p>Collecting  a  large-scale  and  well-annotated  dataset  for  image  processing  hasbecome  a  common  practice  in  computer  vision.  However,  in  the  ancient  paintingarea,  this  task  is  not  practical  as  the  number  of  paintings  is  limited  andtheir  style  is  greatly  diverse.  We,  therefore,  propose  a  novel  solution  for  theproblems  that  come  with  ancient  painting  processing.  This  is  to  use  domaintransfer  to  convert  ancient  paintings  to  photo-realistic  natural  images.  Bydoing  so,  the  ancient  painting  processing  problems  become  natural  imageprocessing  problems  and  models  trained  on  natural  images  can  be  directlyapplied  to  the  transferred  paintings.  Specifically,  we  focus  on  Chinese  ancientflower,  bird  and  landscape  paintings  in  this  work.  A  novel  Domain  StyleTransfer  Network  (DSTN)  is  proposed  to  transfer  ancient  paintings  to  naturalimages  which  employ  a  compound  loss  to  ensure  that  the  transferred  paintingsstill  maintain  the  color  composition  and  content  of  the  input  paintings.  Theexperiment  results  show  that  the  transferred  paintings  generated  by  the  DSTNhave  a  better  performance  in  both  the  human  perceptual  test  and  other  imageprocessing  tasks  than  other  state-of-art  methods,  indicating  the  authenticityof  the  transferred  paintings  and  the  superiority  of  the  proposed  method.</p>|2019-04-01  22:52:19.492158
http://arxiv.org/abs/1901.04713|Global-to-local  Memory  Pointer  Networks  for  Task-Oriented  Dialogue.  (arXiv:1901.04713v2  [cs.CL]  UPDATED)|<p>End-to-end  task-oriented  dialogue  is  challenging  since  knowledge  bases  areusually  large,  dynamic  and  hard  to  incorporate  into  a  learning  framework.  Wepropose  the  global-to-local  memory  pointer  (GLMP)  networks  to  address  thisissue.  In  our  model,  a  global  memory  encoder  and  a  local  memory  decoder  areproposed  to  share  external  knowledge.  The  encoder  encodes  dialogue  history,modifies  global  contextual  representation,  and  generates  a  global  memorypointer.  The  decoder  first  generates  a  sketch  response  with  unfilled  slots.Next,  it  passes  the  global  memory  pointer  to  filter  the  external  knowledge  forrelevant  information,  then  instantiates  the  slots  via  the  local  memorypointers.  We  empirically  show  that  our  model  can  improve  copy  accuracy  andmitigate  the  common  out-of-vocabulary  problem.  As  a  result,  GLMP  is  able  toimprove  over  the  previous  state-of-the-art  models  in  both  simulated  bAbIDialogue  dataset  and  human-human  Stanford  Multi-domain  Dialogue  dataset  onautomatic  and  human  evaluation.</p>|2019-04-01  22:52:19.492214
http://arxiv.org/abs/1901.07879|Physical  reservoir  computing  built  by  spintronic  devices  for  temporal  information  processing.  (arXiv:1901.07879v2  [cs.ET]  UPDATED)|<p>Spintronic  nanodevices  have  ultrafast  nonlinear  dynamic  and  recurrencebehaviors  on  a  nanosecond  scale  that  promises  to  enable  spintronic  reservoircomputing  (RC)  system.  Here  two  physical  RC  systems  based  on  a  single  magneticskyrmion  memristor  (MSM)  and  24  spin-torque  nano-oscillators  (STNOs)  wereproposed  and  modeled  to  process  image  classification  task  and  nonlinear  dynamicsystem  prediction,  respectively.  Based  on  our  micromagnetic  simulation  resultson  the  nonlinear  responses  of  MSM  and  STNO  with  current  pulses  stimulation,  thehandwritten  digits  recognition  task  domesticates  that  an  RC  system  using  onesingle  MSM  has  the  outstanding  performance  on  image  classification.  Inaddition,  the  complex  unknown  nonlinear  dynamic  problems  can  also  be  wellsolved  by  a  physical  RC  system  consisted  of  24  STNOs  confirmed  in  asecond-order  nonlinear  dynamic  system  and  NARMA10  tasks.  The  capability  of  bothhigh  accuracy  and  fast  information  processing  promises  to  enable  one  type  ofbrain-like  chip  based  on  spintronics  for  various  artificial  intelligence  tasks.</p>|2019-04-01  22:52:19.492249
http://arxiv.org/abs/1901.09109|DADAM:  A  Consensus-based  Distributed  Adaptive  Gradient  Method  for  Online  Optimization.  (arXiv:1901.09109v4  [cs.LG]  UPDATED)|<p>Adaptive  gradient-based  optimization  methods  such  as  \textsc{Adagrad},\textsc{Rmsprop},  and  \textsc{Adam}  are  widely  used  in  solving  large-scalemachine  learning  problems  including  deep  learning.  A  number  of  schemes  havebeen  proposed  in  the  literature  aiming  at  parallelizing  them,  based  oncommunications  of  peripheral  nodes  with  a  central  node,  but  incur  highcommunications  cost.  To  address  this  issue,  we  develop  a  novel  consensus-baseddistributed  adaptive  moment  estimation  method  (\textsc{Dadam})  for  onlineoptimization  over  a  decentralized  network  that  enables  data  parallelization,  aswell  as  decentralized  computation.  The  method  is  particularly  useful,  since  itcan  accommodate  settings  where  access  to  local  data  is  allowed.  Further,  asestablished  theoretically  in  this  work,  it  can  outperform  centralized  adaptivealgorithms,  for  certain  classes  of  loss  functions  used  in  applications.  Weanalyze  the  convergence  properties  of  the  proposed  algorithm  and  provide  adynamic  regret  bound  on  the  convergence  rate  of  adaptive  moment  estimationmethods  in  both  stochastic  and  deterministic  settings.  Empirical  resultsdemonstrate  that  \textsc{Dadam}  works  also  well  in  practice  and  comparesfavorably  to  competing  online  optimization  methods.</p>|2019-04-01  22:52:19.492283
http://arxiv.org/abs/1902.03368|Skin  Lesion  Analysis  Toward  Melanoma  Detection  2018:  A  Challenge  Hosted  by  the  International  Skin  Imaging  Collaboration  (ISIC).  (arXiv:1902.03368v2  [cs.CV]  UPDATED)|<p>This  work  summarizes  the  results  of  the  largest  skin  image  analysis  challengein  the  world,  hosted  by  the  International  Skin  Imaging  Collaboration  (ISIC),  aglobal  partnership  that  has  organized  the  world's  largest  public  repository  ofdermoscopic  images  of  skin.  The  challenge  was  hosted  in  2018  at  the  MedicalImage  Computing  and  Computer  Assisted  Intervention  (MICCAI)  conference  inGranada,  Spain.  The  dataset  included  over  12,500  images  across  3  tasks.  900users  registered  for  data  download,  115  submitted  to  the  lesion  segmentationtask,  25  submitted  to  the  lesion  attribute  detection  task,  and  159  submitted  tothe  disease  classification  task.  Novel  evaluation  protocols  were  established,including  a  new  test  for  segmentation  algorithm  performance,  and  a  test  foralgorithm  ability  to  generalize.  Results  show  that  top  segmentation  algorithmsstill  fail  on  over  10%  of  images  on  average,  and  algorithms  with  equalperformance  on  test  data  can  have  different  abilities  to  generalize.  This  is  animportant  consideration  for  agencies  regulating  the  growing  set  of  machinelearning  tools  in  the  healthcare  domain,  and  sets  a  new  standard  for  futurepublic  challenges  in  healthcare.</p>|2019-04-01  22:52:19.492315
http://arxiv.org/abs/1902.05679|ProxSARAH:  An  Efficient  Algorithmic  Framework  for  Stochastic  Composite  Nonconvex  Optimization.  (arXiv:1902.05679v2  [math.OC]  UPDATED)|<p>We  propose  a  new  stochastic  first-order  algorithmic  framework  to  solvestochastic  composite  nonconvex  optimization  problems  that  covers  bothfinite-sum  and  expectation  settings.  Our  algorithms  rely  on  the  SARAH  estimatorintroduced  in  (Nguyen  et  al,  2017)  and  consist  of  two  steps:  a  proximalgradient  and  an  averaging  step  making  them  different  from  existing  nonconvexproximal-type  algorithms.  The  algorithms  only  require  an  average  smoothnessassumption  of  the  nonconvex  objective  term  and  additional  bounded  varianceassumption  if  applied  to  expectation  problems.  They  work  with  both  constant  andadaptive  step-sizes,  while  allowing  single  sample  and  mini-batches.  In  allthese  cases,  we  prove  that  our  algorithms  can  achieve  the  best-known  complexitybounds.  One  key  step  of  our  methods  is  new  constant  and  adaptive  step-sizesthat  help  to  achieve  desired  complexity  bounds  while  improving  practicalperformance.  Our  constant  step-size  is  much  larger  than  existing  methodsincluding  proximal  SVRG  schemes  in  the  single  sample  case.  We  also  specify  thealgorithm  to  the  non-composite  case  that  covers  existing  state-of-the-arts  interms  of  complexity  bounds.  Our  update  also  allows  one  to  trade-off  betweenstep-sizes  and  mini-batch  sizes  to  improve  performance.  We  test  the  proposedalgorithms  on  two  composite  nonconvex  problems  and  neural  networks  usingseveral  well-known  datasets.</p>|2019-04-01  22:52:19.492346
http://arxiv.org/abs/1902.07836|ERSFQ  8-bit  Parallel  Binary  Shifter  for  Energy-Efficient  Superconducting  CPU.  (arXiv:1902.07836v2  [cs.AR]  UPDATED)|<p>We  have  designed  and  tested  a  parallel  8-bit  ERSFQ  binary  shifter  that  is  oneof  the  essential  circuits  in  the  design  of  the  energy-efficient  superconductingCPU.  The  binary  shifter  performs  a  bi-directional  SHIFT  instruction  of  an  8-bitargument.  It  consists  of  a  bi-direction  triple-port  shift  register  controlledby  two  (left  and  right)  shift  pulse  generators  asynchronously  generating  a  setnumber  of  shift  pulses.  At  first  clock  cycle,  an  8-bit  word  is  loaded  into  thebinary  shifter  and  a  3-bit  shift  argument  is  loaded  into  the  desiredshift-pulse  generator.  Next,  the  generator  produces  the  required  number  ofshift  SFQ  pulses  (from  0  to  7)  asynchronously,  with  a  repetition  rate  set  bythe  internal  generator  delay  of  ~  30  ps.  These  SFQ  pulses  are  applied  to  theleft  (positive)  or  the  right  (negative)  input  of  the  binary  shifter.  Finally,after  the  shift  operation  is  completed,  the  resulting  8-bit  word  goes  to  theparallel  output.  The  complete  8-bit  ERSFQ  binary  shifter,  consisting  of  820Josephson  junctions,  was  simulated  and  optimized  using  PSCAN2.  It  wasfabricated  in  MIT  Lincoln  Lab  10-kA/cm2  SFQ5ee  fabrication  process  with  ahigh-kinetic  inductance  layer.  We  have  successfully  tested  the  binary  shifterat  both  the  LSB-to-MSB  and  MSB-to-LSB  propagation  regimes  for  all  eight  shiftarguments.  A  single  shift  operation  on  a  single  input  word  demonstratedoperational  margins  of  +/-16%  of  the  dc  bias  current.  The  correct  functionalityof  the  8-bit  ERSFQ  binary  shifter  with  the  large,  exhaustive  data  pattern  wasobserved  within  +/-10%  margins  of  the  dc  bias  current.  In  this  paper,  wedescribe  the  design  and  present  the  test  results  for  the  ERSFQ  8-bit  parallelbinary  shifter.</p>|2019-04-01  22:52:19.492378
http://arxiv.org/abs/1902.07848|Gradient  Scheduling  with  Global  Momentum  for  Non-IID  Data  Distributed  Asynchronous  Training.  (arXiv:1902.07848v2  [cs.DC]  UPDATED)|<p>Distributed  asynchronous  offline  training  has  received  widespread  attentionin  recent  years  because  of  its  high  performance  on  large-scale  data  and  complexmodels.  As  data  are  processed  from  cloud-centric  positions  to  edge  locations,  abig  challenge  for  distributed  systems  is  how  to  handle  native  and  naturalnon-independent  and  identically  distributed  (non-IID)  data  for  training.Previous  asynchronous  training  methods  do  not  have  a  satisfying  performance  onnon-IID  data  because  it  would  result  in  that  the  training  process  fluctuatesgreatly  which  leads  to  an  abnormal  convergence.  We  propose  a  gradientscheduling  algorithm  with  global  momentum  (GSGM)  for  non-IID  data  distributedasynchronous  training.  Our  key  idea  is  to  schedule  the  gradients  contributed  bycomputing  nodes  based  on  a  white  list  so  that  each  training  node's  updatefrequency  remains  even.  Furthermore,  our  new  momentum  method  can  solve  thebiased  gradient  problem.  GSGM  can  make  model  converge  effectively,  and  maintainhigh  availability  eventually.  Experimental  results  show  that  for  non-IID  datatraining  under  the  same  experimental  conditions,  GSGM  on  popular  optimizationalgorithms  can  achieve  an  20%  increase  in  training  stability  with  a  slightimprovement  in  accuracy  on  Fashion-Mnist  and  CIFAR-10  datasets.  Meanwhile,  whenexpanding  distributed  scale  on  CIFAR-100  dataset  that  results  in  sparse  datadistribution,  GSGM  can  perform  an  37%  improvement  on  training  stability.Moreover,  only  GSGM  can  converge  well  when  the  number  of  computing  nodes  is  30,compared  to  the  state-of-the-art  distributed  asynchronous  algorithms.</p>|2019-04-01  22:52:19.492409
http://arxiv.org/abs/1902.09130|An  Attention  Enhanced  Graph  Convolutional  LSTM  Network  for  Skeleton-Based  Action  Recognition.  (arXiv:1902.09130v2  [cs.CV]  UPDATED)|<p>Skeleton-based  action  recognition  is  an  important  task  that  requires  theadequate  understanding  of  movement  characteristics  of  a  human  action  from  thegiven  skeleton  sequence.  Recent  studies  have  shown  that  exploring  spatial  andtemporal  features  of  the  skeleton  sequence  is  vital  for  this  task.Nevertheless,  how  to  effectively  extract  discriminative  spatial  and  temporalfeatures  is  still  a  challenging  problem.  In  this  paper,  we  propose  a  novelAttention  Enhanced  Graph  Convolutional  LSTM  Network  (AGC-LSTM)  for  human  actionrecognition  from  skeleton  data.  The  proposed  AGC-LSTM  can  not  only  capturediscriminative  features  in  spatial  configuration  and  temporal  dynamics  but  alsoexplore  the  co-occurrence  relationship  between  spatial  and  temporal  domains.  Wealso  present  a  temporal  hierarchical  architecture  to  increases  temporalreceptive  fields  of  the  top  AGC-LSTM  layer,  which  boosts  the  ability  to  learnthe  high-level  semantic  representation  and  significantly  reduces  thecomputation  cost.  Furthermore,  to  select  discriminative  spatial  information,the  attention  mechanism  is  employed  to  enhance  information  of  key  joints  ineach  AGC-LSTM  layer.  Experimental  results  on  two  datasets  are  provided:  NTURGB+D  dataset  and  Northwestern-UCLA  dataset.  The  comparison  results  demonstratethe  effectiveness  of  our  approach  and  show  that  our  approach  outperforms  thestate-of-the-art  methods  on  both  datasets.</p>|2019-04-01  22:52:19.492441
http://arxiv.org/abs/1902.09500|ERSFQ  8-bit  Parallel  Arithmetic  Logic  Unit.  (arXiv:1902.09500v2  [cs.AR]  UPDATED)|<p>We  have  designed  and  tested  a  parallel  8-bit  ERSFQ  arithmetic  logic  unit(ALU).  The  ALU  design  employs  wave-pipelined  instruction  execution  and  featuresmodular  bit-slice  architecture  that  is  easily  extendable  to  any  number  of  bitsand  adaptable  to  current  recycling.  A  carry  signal  synchronized  with  anasynchronous  instruction  propagation  provides  the  wave-pipeline  operation  ofthe  ALU.  The  ALU  instruction  set  consists  of  14  arithmetical  and  logicalinstructions.  It  has  been  designed  and  simulated  for  operation  up  to  a  10  GHzclock  rate  at  the  10-kA/cm2  fabrication  process.  The  ALU  is  embedded  into  ashift-register-based  high-frequency  testbed  with  on-chip  clock  generator  toallow  for  comprehensive  high  frequency  testing  for  all  possible  operands.  The8-bit  ERSFQ  ALU,  comprising  6840  Josephson  junctions,  has  been  fabricated  withMIT  Lincoln  Lab  10-kA/cm2  SFQ5ee  fabrication  process  featuring  eight  Nb  wiringlayers  and  a  high-kinetic  inductance  layer  needed  for  ERSFQ  technology.  Weevaluated  the  bias  margins  for  all  instructions  and  various  operands  at  bothlow  and  high  frequency  clock.  At  low  frequency,  clock  and  all  instructionpropagation  through  ALU  were  observed  with  bias  margins  of  +/-11%  and  +/-9%,respectively.  Also  at  low  speed,  the  ALU  exhibited  correct  functionality  forall  arithmetical  and  logical  instructions  with  +/-6%  bias  margins.  We  testedthe  8-bit  ALU  for  all  instructions  up  to  2.8  GHz  clock  frequency.</p>|2019-04-01  22:52:19.492471
http://arxiv.org/abs/1902.10505|Viable  Dependency  Parsing  as  Sequence  Labeling.  (arXiv:1902.10505v2  [cs.CL]  UPDATED)|<p>We  recast  dependency  parsing  as  a  sequence  labeling  problem,  exploringseveral  encodings  of  dependency  trees  as  labels.  While  dependency  parsing  bymeans  of  sequence  labeling  had  been  attempted  in  existing  work,  resultssuggested  that  the  technique  was  impractical.  We  show  instead  that  with  aconventional  BiLSTM-based  model  it  is  possible  to  obtain  fast  and  accurateparsers.  These  parsers  are  conceptually  simple,  not  needing  traditional  parsingalgorithms  or  auxiliary  structures.  However,  experiments  on  the  PTB  and  asample  of  UD  treebanks  show  that  they  provide  a  good  speed-accuracy  tradeoff,with  results  competitive  with  more  complex  approaches.</p>|2019-04-01  22:52:19.492502
http://arxiv.org/abs/1902.11191|A  Complexity  Dichotomy  for  Colourful  Components  Problems  on  $k$-caterpillars  and  Small-Degree  Planar  Graphs.  (arXiv:1902.11191v3  [cs.DM]  UPDATED)|<p>A  connected  component  of  a  vertex-coloured  graph  is  said  to  be  colourful  ifall  its  vertices  have  different  colours,  and  a  graph  is  colourful  if  all  itsconnected  components  are  colourful.  Given  a  vertex-coloured  graph,  theColourful  Components  problem  asks  whether  there  exist  at  most  $p$  edges  whoseremoval  makes  the  graph  colourful,  and  the  Colourful  Partition  problem  askswhether  there  exists  a  partition  of  the  vertex  set  with  at  most  $p$  parts  suchthat  each  part  induces  a  colourful  component.  We  study  the  problems  on$k$-caterpillars  (caterpillars  with  hairs  of  length  at  most  $k$)  and  explorethe  boundary  between  polynomial  and  NP-complete  cases.  It  is  known  that  theproblems  are  NP-complete  on  $2$-caterpillars  with  unbounded  maximum  degree.  Weprove  that  both  problems  remain  NP-complete  on  binary  $4$-caterpillars  and  onternary  $3$-caterpillars.  This  answers  an  open  question  regarding  thecomplexity  of  the  problems  on  trees  with  maximum  degree  at  most  $5$.  On  thepositive  side,  we  give  a  linear  time  algorithm  for  $1$-caterpillars  withunbounded  degree,  even  if  the  backbone  is  a  cycle,  which  outperforms  theprevious  best  complexity  on  paths  and  widens  the  class  of  graphs.  Finally,  weanswer  an  open  question  regarding  the  complexity  of  Colourful  Components  ongraphs  with  maximum  degree  at  most  $5$.  We  show  that  the  problem  is  NP-completeon  $5$-coloured  planar  graphs  with  maximum  degree  $4$,  and  on  $12$-colouredplanar  graphs  with  maximum  degree  $3$.  Since  the  problem  can  be  solved  inpolynomial-time  on  graphs  with  maximum  degree  $2$,  the  results  are  the  bestpossible  with  regard  to  the  maximum  degree.</p>|2019-04-01  22:52:19.492534
http://arxiv.org/abs/1903.00709|PartNet:  A  Recursive  Part  Decomposition  Network  for  Fine-grained  and  Hierarchical  Shape  Segmentation.  (arXiv:1903.00709v4  [cs.CV]  UPDATED)|<p>Deep  learning  approaches  to  3D  shape  segmentation  are  typically  formulated  asa  multi-class  labeling  problem.  Existing  models  are  trained  for  a  fixed  set  oflabels,  which  greatly  limits  their  flexibility  and  adaptivity.  We  opt  fortop-down  recursive  decomposition  and  develop  the  first  deep  learning  model  forhierarchical  segmentation  of  3D  shapes,  based  on  recursive  neural  networks.Starting  from  a  full  shape  represented  as  a  point  cloud,  our  model  performsrecursive  binary  decomposition,  where  the  decomposition  network  at  all  nodes  inthe  hierarchy  share  weights.  At  each  node,  a  node  classifier  is  trained  todetermine  the  type  (adjacency  or  symmetry)  and  stopping  criteria  of  itsdecomposition.  The  features  extracted  in  higher  level  nodes  are  recursivelypropagated  to  lower  level  ones.  Thus,  the  meaningful  decompositions  in  higherlevels  provide  strong  contextual  cues  constraining  the  segmentations  in  lowerlevels.  Meanwhile,  to  increase  the  segmentation  accuracy  at  each  node,  weenhance  the  recursive  contextual  feature  with  the  shape  feature  extracted  forthe  corresponding  part.  Our  method  segments  a  3D  shape  in  point  cloud  into  anunfixed  number  of  parts,  depending  on  the  shape  complexity,  showing  stronggenerality  and  flexibility.  It  achieves  the  state-of-the-art  performance,  bothfor  fine-grained  and  semantic  segmentation,  on  the  public  benchmark  and  a  newbenchmark  of  fine-grained  segmentation  proposed  in  this  work.  We  alsodemonstrate  its  application  for  fine-grained  part  refinements  in  image-to-shapereconstruction.</p>|2019-04-01  22:52:19.492565
http://arxiv.org/abs/1903.01698|Improving  Cross-Domain  Chinese  Word  Segmentation  with  Word  Embeddings.  (arXiv:1903.01698v3  [cs.CL]  UPDATED)|<p>Cross-domain  Chinese  Word  Segmentation  (CWS)  remains  a  challenge  despiterecent  progress  in  neural-based  CWS.  The  limited  amount  of  annotated  data  inthe  target  domain  has  been  the  key  obstacle  to  a  satisfactory  performance.  Inthis  paper,  we  propose  a  semi-supervised  word-based  approach  to  improvingcross-domain  CWS  given  a  baseline  segmenter.  Particularly,  our  model  onlydeploys  word  embeddings  trained  on  raw  text  in  the  target  domain,  discardingcomplex  hand-crafted  features  and  domain-specific  dictionaries.  Innovativesubsampling  and  negative  sampling  methods  are  proposed  to  derive  wordembeddings  optimized  for  CWS.  We  conduct  experiments  on  five  datasets  inspecial  domains,  covering  domains  in  novels,  medicine,  and  patent.  Results  showthat  our  model  can  obviously  improve  cross-domain  CWS,  especially  in  thesegmentation  of  domain-specific  noun  entities.  The  word  F-measure  increases  byover  3.0%  on  four  datasets,  outperforming  state-of-the-art  semi-supervised  andunsupervised  cross-domain  CWS  approaches  with  a  large  margin.  We  make  our  codeand  data  available  on  Github.</p>|2019-04-01  22:52:19.492595
http://arxiv.org/abs/1903.02728|Graphical  Contrastive  Losses  for  Scene  Graph  Generation.  (arXiv:1903.02728v3  [cs.CV]  UPDATED)|<p>Most  scene  graph  generators  use  a  two-stage  pipeline  to  detect  visualrelationships:  the  first  stage  detects  entities,  and  the  second  predicts  thepredicate  for  each  entity  pair  using  a  softmax  distribution.  We  find  that  suchpipelines,  trained  with  only  a  cross  entropy  loss  over  predicate  classes,suffer  from  two  common  errors.  The  first,  Entity  Instance  Confusion,  occurswhen  the  model  confuses  multiple  instances  of  the  same  type  of  entity  (e.g.multiple  cups).  The  second,  Proximal  Relationship  Ambiguity,  arises  whenmultiple  subject-predicate-object  triplets  appear  in  close  proximity  with  thesame  predicate,  and  the  model  struggles  to  infer  the  correct  subject-objectpairings  (e.g.  mis-pairing  musicians  and  their  instruments).  We  propose  a  setof  contrastive  loss  formulations  that  specifically  target  these  types  of  errorswithin  the  scene  graph  generation  problem,  collectively  termed  the  GraphicalContrastive  Losses.  These  losses  explicitly  force  the  model  to  disambiguaterelated  and  unrelated  instances  through  margin  constraints  specific  to  eachtype  of  confusion.  We  further  construct  a  relationship  detector,  called  RelDN,using  the  aforementioned  pipeline  to  demonstrate  the  efficacy  of  our  proposedlosses.  Our  model  outperforms  the  winning  method  of  the  OpenImages  RelationshipDetection  Challenge  by  4.7\%  (16.5\%  relative)  on  the  test  set.  We  also  showimproved  results  over  the  best  previous  methods  on  the  Visual  Genome  and  VisualRelationship  Detection  datasets.</p>|2019-04-01  22:52:19.492626
http://arxiv.org/abs/1903.06494|Content  Differences  in  Syntactic  and  Semantic  Representations.  (arXiv:1903.06494v4  [cs.CL]  UPDATED)|<p>Syntactic  analysis  plays  an  important  role  in  semantic  parsing,  but  thenature  of  this  role  remains  a  topic  of  ongoing  debate.  The  debate  has  beenconstrained  by  the  scarcity  of  empirical  comparative  studies  between  syntacticand  semantic  schemes,  which  hinders  the  development  of  parsing  methods  informedby  the  details  of  target  schemes  and  constructions.  We  target  this  gap,  andtake  Universal  Dependencies  (UD)  and  UCCA  as  a  test  case.  After  abstractingaway  from  differences  of  convention  or  formalism,  we  find  that  most  contentdivergences  can  be  ascribed  to:  (1)  UCCA's  distinction  between  a  Scene  and  anon-Scene;  (2)  UCCA's  distinction  between  primary  relations,  secondary  ones  andparticipants;  (3)  different  treatment  of  multi-word  expressions,  and  (4)different  treatment  of  inter-clause  linkage.  We  further  discuss  the  long  tailof  cases  where  the  two  schemes  take  markedly  different  approaches.  Finally,  weshow  that  the  proposed  comparison  methodology  can  be  used  for  fine-grainedevaluation  of  UCCA  parsing,  highlighting  both  challenges  and  potential  sourcesfor  improvement.  The  substantial  differences  between  the  schemes  suggest  thatsemantic  parsers  are  likely  to  benefit  downstream  text  understandingapplications  beyond  their  syntactic  counterparts.</p>|2019-04-01  22:52:19.492658
http://arxiv.org/abs/1903.08252|MP  net  as  Abstract  Model  of  Communication  for  Message-passing  Applications.  (arXiv:1903.08252v2  [cs.DC]  UPDATED)|<p>MP  net  is  a  formal  model  specifically  designed  for  the  field  of  parallelapplications  that  use  a  message  passing  interface.  The  main  idea  is  to  use  MPnet  as  a  comprehensible  way  of  presenting  the  actual  structure  of  communicationwithin  MPI  applications.  The  goal  is  to  provide  users  with  the  kind  of  feedbackthat  can  help  them  to  check  quickly  whether  or  not  the  actual  communicationwithin  their  application  corresponds  to  the  intended  one.  This  paper  introducesMP  net  that  focuses  on  the  communication  part  of  parallel  applications  andemphasizes  its  spatial  character,  which  is  rather  hidden  in  sequential(textual)  form.</p>|2019-04-01  22:52:19.492689
http://arxiv.org/abs/1903.08450|Decay-Function-Free  Time-Aware  Attention  to  Context  and  Speaker  Indicator  for  Spoken  Language  Understanding.  (arXiv:1903.08450v2  [cs.CL]  UPDATED)|<p>To  capture  salient  contextual  information  for  spoken  language  understanding(SLU)  of  a  dialogue,  we  propose  time-aware  models  that  automatically  learn  thelatent  time-decay  function  of  the  history  without  a  manual  time-decay  function.We  also  propose  a  method  to  identify  and  label  the  current  speaker  to  improvethe  SLU  accuracy.  In  experiments  on  the  benchmark  dataset  used  in  Dialog  StateTracking  Challenge  4,  the  proposed  models  achieved  significantly  higher  F1scores  than  the  state-of-the-art  contextual  models.  Finally,  we  analyze  theeffectiveness  of  the  introduced  models  in  detail.  The  analysis  demonstratesthat  the  proposed  methods  were  effective  to  improve  SLU  accuracy  individually.</p>|2019-04-01  22:52:19.492719
http://arxiv.org/abs/1903.09333|A  Type-coherent,  Expressive  Representation  as  an  Initial  Step  to  Language  Understanding.  (arXiv:1903.09333v2  [cs.CL]  UPDATED)|<p>A  growing  interest  in  tasks  involving  language  understanding  by  the  NLPcommunity  has  led  to  the  need  for  effective  semantic  parsing  and  inference.Modern  NLP  systems  use  semantic  representations  that  do  not  quite  fulfill  thenuanced  needs  for  language  understanding:  adequately  modeling  languagesemantics,  enabling  general  inferences,  and  being  accurately  recoverable.  Thisdocument  describes  underspecified  logical  forms  (ULF)  for  Episodic  Logic  (EL),which  is  an  initial  form  for  a  semantic  representation  that  balances  theseneeds.  ULFs  fully  resolve  the  semantic  type  structure  while  leaving  issues  suchas  quantifier  scope,  word  sense,  and  anaphora  unresolved;  they  provide  astarting  point  for  further  resolution  into  EL,  and  enable  certain  structuralinferences  without  further  resolution.  This  document  also  presents  preliminaryresults  of  creating  a  hand-annotated  corpus  of  ULFs  for  the  purpose  of  traininga  precise  ULF  parser,  showing  a  three-person  pairwise  interannotator  agreementof  0.88  on  confident  annotations.  We  hypothesize  that  a  divide-and-conquerapproach  to  semantic  parsing  starting  with  derivation  of  ULFs  will  lead  tosemantic  analyses  that  do  justice  to  subtle  aspects  of  linguistic  meaning,  andwill  enable  construction  of  more  accurate  semantic  parsers.</p>|2019-04-01  22:52:19.492750
http://arxiv.org/abs/1903.09465|Managing  Recurrent  Virtual  Network  Updates  in  Multi-Tenant  Datacenters:  A  System  Perspective.  (arXiv:1903.09465v3  [cs.CR]  UPDATED)|<p>With  the  advent  of  software-defined  networking,  network  configuration  throughprogrammable  interfaces  becomes  practical,  leading  to  various  on-demandopportunities  for  network  routing  update  in  multi-tenant  datacenters,  wheretenants  have  diverse  requirements  on  network  routings  such  as  short  latency,low  path  inflation,  large  bandwidth,  high  reliability,  etc.  Conventionalsolutions  that  rely  on  topology  search  coupled  with  an  objective  function  tofind  desired  routings  have  at  least  two  shortcomings:  (i)  they  run  intoscalability  issues  when  handling  consistent  and  frequent  routing  updates  and(ii)  they  restrict  the  flexibility  and  capability  to  satisfy  various  routingrequirements.  To  address  these  issues,  this  paper  proposes  a  novel  search  andoptimization  decoupled  design,  which  not  only  saves  considerable  topologysearch  costs  via  search  result  reuse,  but  also  avoids  possible  sub-optimalityin  greedy  routing  search  algorithms  by  making  decisions  based  on  the  globalview  of  all  possible  routings.  We  implement  a  prototype  of  our  proposed  system,OpReduce,  and  perform  extensive  evaluations  to  validate  its  design  goals.</p>|2019-04-01  22:52:19.492780
http://arxiv.org/abs/1903.09717|Instance  and  Output  Optimal  Parallel  Algorithms  for  Acyclic  Joins.  (arXiv:1903.09717v2  [cs.DB]  UPDATED)|<p>Massively  parallel  join  algorithms  have  received  much  attention  in  recentyears,  while  most  prior  work  has  focused  on  worst-optimal  algorithms.  However,the  worst-case  optimality  of  these  join  algorithms  relies  on  hard  instanceshaving  very  large  output  sizes,  which  rarely  appear  in  practice.  A  strongernotion  of  optimality  is  {\em  output-optimal},  which  requires  an  algorithm  to  beoptimal  within  the  class  of  all  instances  sharing  the  same  input  and  outputsize.  An  even  stronger  optimality  is  {\em  instance-optimal},  i.e.,  thealgorithm  is  optimal  on  every  single  instance,  but  this  may  not  always  beachievable.</p><p>In  the  traditional  RAM  model  of  computation,  the  classical  Yannakakisalgorithm  is  instance-optimal  on  any  acyclic  join.  But  in  the  massivelyparallel  computation  (MPC)  model,  the  situation  becomes  much  more  complicated.We  first  show  that  for  the  class  of  r-hierarchical  joins,  instance-optimalitycan  still  be  achieved  in  the  MPC  model.  Then,  we  give  a  new  MPC  algorithm  foran  arbitrary  acyclic  join  with  load  $O  ({\IN  \over  p}  +  {\sqrt{\IN  \cdot  \OUT}\over  p})$,  where  $\IN,\OUT$  are  the  input  and  output  sizes  of  the  join,  and$p$  is  the  number  of  servers  in  the  MPC  model.  This  improves  the  MPC  version  ofthe  Yannakakis  algorithm  by  an  $O  (\sqrt{\OUT  \over  \IN}  )$  factor.Furthermore,  we  show  that  this  is  output-optimal  when  $\OUT  =  O(p  \cdot  \IN)$,for  every  acyclic  but  non-r-hierarchical  join.  Finally,  we  give  the  firstoutput-sensitive  lower  bound  for  the  triangle  join  in  the  MPC  model,  showingthat  it  is  inherently  more  difficult  than  acyclic  joins.</p>|2019-04-01  22:52:19.492811
http://arxiv.org/abs/1903.09755|Trifocal  Relative  Pose  from  Lines  at  Points  and  its  Efficient  Solution.  (arXiv:1903.09755v2  [cs.CV]  UPDATED)|<p>We  present  a  new  minimal  problem  for  relative  pose  estimation  mixing  pointfeatures  with  lines  incident  at  points  observed  in  three  views  and  itsefficient  homotopy  continuation  solver.  We  demonstrate  the  generality  of  theapproach  by  analyzing  and  solving  an  additional  problem  with  mixed  point  andline  correspondences  in  three  views.  The  minimal  problems  includecorrespondences  of  (i)  three  points  and  one  line  and  (ii)  three  points  and  twolines  through  two  of  the  points  which  is  reported  and  analyzed  here  for  thefirst  time.  These  are  difficult  to  solve,  as  they  have  216  and  -  as  shown  here-  312  solutions,  but  cover  important  practical  situations  when  line  and  pointfeatures  appear  together,  e.g.,  in  urban  scenes  or  when  observing  curves.  Wedemonstrate  that  even  such  difficult  problems  can  be  solved  robustly  using  asuitable  homotopy  continuation  technique  and  we  provide  an  implementationoptimized  for  minimal  problems  that  can  be  integrated  into  engineeringapplications.  Our  simulated  and  real  experiments  demonstrate  our  solvers  in  thecamera  geometry  computation  task  in  structure  from  motion.  We  show  that  newsolvers  allow  for  reconstructing  challenging  scenes  where  the  standard  two-viewinitialization  of  structure  from  motion  fails.</p>|2019-04-01  22:52:19.492842
http://arxiv.org/abs/1903.10605|Q-Learning  for  Continuous  Actions  with  Cross-Entropy  Guided  Policies.  (arXiv:1903.10605v2  [cs.AI]  UPDATED)|<p>Off-Policy  reinforcement  learning  (RL)  is  an  important  class  of  methods  formany  problem  domains,  such  as  robotics,  where  the  cost  of  collecting  data  ishigh  and  on-policy  methods  are  consequently  intractable.  Standard  methods  forapplying  Q-learning  to  continuous-valued  action  domains  involve  iterativelysampling  the  Q-function  to  find  a  good  action  (e.g.  via  hill-climbing),  or  bylearning  a  policy  network  at  the  same  time  as  the  Q-function  (e.g.  DDPG).  Bothapproaches  make  tradeoffs  between  stability,  speed,  and  accuracy.  We  propose  anovel  approach,  called  Cross-Entropy  Guided  Policies,  or  CGP,  that  drawsinspiration  from  both  classes  of  techniques.  CGP  aims  to  combine  the  stabilityand  performance  of  iterative  sampling  policies  with  the  low  computational  costof  a  policy  network.  Our  approach  trains  the  Q-function  using  iterativesampling  with  the  Cross-Entropy  Method  (CEM),  while  training  a  policy  networkto  imitate  CEM's  sampling  behavior.  We  demonstrate  that  our  method  is  morestable  to  train  than  state  of  the  art  policy  network  methods,  while  preservingequivalent  inference  time  compute  costs,  and  achieving  competitive  total  rewardon  standard  benchmarks.</p>|2019-04-01  22:52:19.492872
http://arxiv.org/abs/1903.11242|An  Empirical  Study  on  Practicality  of  Specification  Mining  Algorithms  on  a  Real-world  Application.  (arXiv:1903.11242v2  [cs.SE]  UPDATED)|<p>Dynamic  model  inference  techniques  have  been  the  center  of  many  researchprojects  recently.  There  are  now  multiple  open  source  implementations  ofstate-of-the-art  algorithms,  which  provide  basic  abstraction  and  mergingcapabilities.  Most  of  these  tools  and  algorithms  have  been  developed  with  oneparticular  application  in  mind,  which  is  program  comprehension.  The  outputsmodels  can  abstract  away  the  details  of  the  program  and  represent  the  softwarebehavior  in  a  concise  and  easy  to  understand  form.  However,  one  applicationcontext  that  is  less  studied  is  using  such  inferred  models  for  debugging,  wherethe  behavior  to  abstract  is  a  faulty  behavior  (e.g.,  a  set  of  execution  tracesincluding  a  failed  test  case).  We  tried  to  apply  some  of  the  existing  modelinference  techniques  (implemented  in  a  promising  tool  called  MINT)  in  areal-world  industrial  context  to  support  program  comprehension  for  debugging.Our  initial  experiments  have  shown  many  limitations  both  in  terms  ofimplementation  as  well  as  the  algorithms.  The  paper  will  discuss  the  root  causeof  the  failures  and  proposes  ideas  for  future  improvement.</p>|2019-04-01  22:52:19.492904
http://arxiv.org/abs/1903.11249|W-Net:  Reinforced  U-Net  for  Density  Map  Estimation.  (arXiv:1903.11249v2  [cs.CV]  UPDATED)|<p>Crowd  management  is  of  paramount  importance  when  it  comes  to  preventingstampedes  and  saving  lives,  especially  in  a  countries  like  China  and  Indiawhere  the  combined  population  is  a  third  of  the  global  population.  Millions  ofpeople  convene  annually  all  around  the  nation  to  celebrate  a  myriad  of  eventsand  crowd  count  estimation  is  the  linchpin  of  the  crowd  management  system  thatcould  prevent  stampedes  and  save  lives.  We  present  a  network  for  crowd  countingwhich  reports  state  of  the  art  results  on  crowd  counting  benchmarks.  Ourcontributions  are,  first,  a  U-Net  inspired  model  which  affords  us  to  reportstate  of  the  art  results.  Second,  we  propose  an  independent  decodingReinforcement  branch  which  helps  the  network  converge  much  earlier  and  alsoenables  the  network  to  estimate  density  maps  with  high  Structural  SimilarityIndex  (SSIM).  Third,  we  discuss  the  drawbacks  of  the  contemporary  architecturesand  empirically  show  that  even  though  our  architecture  achieves  state  of  theart  results,  the  merit  may  be  due  to  the  encoder-decoder  pipeline  instead.Finally,  we  report  the  error  analysis  which  shows  that  the  contemporary  line  ofwork  is  at  saturation  and  leaves  certain  prominent  problems  unsolved.</p>|2019-04-01  22:52:19.492934
http://arxiv.org/abs/1903.11250|Auto-Embedding  Generative  Adversarial  Networks  for  High  Resolution  Image  Synthesis.  (arXiv:1903.11250v2  [cs.CV]  UPDATED)|<p>Generating  images  via  the  generative  adversarial  network  (GAN)  has  attractedmuch  attention  recently.  However,  most  of  the  existing  GAN-based  methods  canonly  produce  low-resolution  images  of  limited  quality.  Directly  generatinghigh-resolution  images  using  GANs  is  nontrivial,  and  often  produces  problematicimages  with  incomplete  objects.  To  address  this  issue,  we  develop  a  novel  GANcalled  Auto-Embedding  Generative  Adversarial  Network  (AEGAN),  whichsimultaneously  encodes  the  global  structure  features  and  captures  thefine-grained  details.  In  our  network,  we  use  an  autoencoder  to  learn  theintrinsic  high-level  structure  of  real  images  and  design  a  novel  denoisernetwork  to  provide  photo-realistic  details  for  the  generated  images.  In  theexperiments,  we  are  able  to  produce  512x512  images  of  promising  qualitydirectly  from  the  input  noise.  The  resultant  images  exhibit  better  perceptualphoto-realism,  i.e.,  with  sharper  structure  and  richer  details,  than  otherbaselines  on  several  datasets,  including  Oxford-102  Flowers,  Caltech-UCSD  Birds(CUB),  High-Quality  Large-scale  CelebFaces  Attributes  (CelebA-HQ),  Large-scaleScene  Understanding  (LSUN)  and  ImageNet.</p>|2019-04-01  22:52:19.492965
http://arxiv.org/abs/1903.11306|Linkage  Based  Face  Clustering  via  Graph  Convolution  Network.  (arXiv:1903.11306v2  [cs.CV]  UPDATED)|<p>In  this  paper,  we  present  an  accurate  and  scalable  approach  to  the  faceclustering  task.  We  aim  at  grouping  a  set  of  faces  by  their  potentialidentities.  We  formulate  this  task  as  a  link  prediction  problem:  a  link  existsbetween  two  faces  if  they  are  of  the  same  identity.  The  key  idea  is  that  wefind  the  local  context  in  the  feature  space  around  an  instance  (face)  containsrich  information  about  the  linkage  relationship  between  this  instance  and  itsneighbors.  By  constructing  sub-graphs  around  each  instance  as  input  data,  whichdepict  the  local  context,  we  utilize  the  graph  convolution  network  (GCN)  toperform  reasoning  and  infer  the  likelihood  of  linkage  between  pairs  in  thesub-graphs.  Experiments  show  that  our  method  is  more  robust  to  the  complexdistribution  of  faces  than  conventional  methods,  yielding  favorably  comparableresults  to  state-of-the-art  methods  on  standard  face  clustering  benchmarks,  andis  scalable  to  large  datasets.  Furthermore,  we  show  that  the  proposed  methoddoes  not  need  the  number  of  clusters  as  prior,  is  aware  of  noises  and  outliers,and  can  be  extended  to  a  multi-view  version  for  more  accurate  clusteringaccuracy.</p>|2019-04-01  22:52:19.492996
http://arxiv.org/abs/1903.11340|Multilevel  Text  Normalization  with  Sequence-to-Sequence  Networks  and  Multisource  Learning.  (arXiv:1903.11340v2  [cs.CL]  UPDATED)|<p>We  define  multilevel  text  normalization  as  sequence-to-sequence  processingthat  transforms  naturally  noisy  text  into  a  sequence  of  normalized  units  ofmeaning  (morphemes)  in  three  steps:  1)  writing  normalization,  2)  lemmatization,3)  canonical  segmentation.  These  steps  are  traditionally  considered  separateNLP  tasks,  with  diverse  solutions,  evaluation  schemes  and  data  sources.  Weexploit  the  fact  that  all  these  tasks  involve  sub-word  sequence-to-sequencetransformation  to  propose  a  systematic  solution  for  all  of  them  using  neuralencoder-decoder  technology.  The  specific  challenge  that  we  tackle  in  this  paperis  integrating  the  traditional  know-how  on  separate  tasks  into  the  neuralsequence-to-sequence  framework  to  improve  the  state  of  the  art.  We  address  thischallenge  by  enriching  the  general  framework  with  mechanisms  that  allowprocessing  the  information  on  multiple  levels  of  text  organization  (characters,morphemes,  words,  sentences)  in  combination  with  structural  information(multilevel  language  model,  part-of-speech)  and  heterogeneous  sources  (text,dictionaries).  We  show  that  our  solution  consistently  improves  on  the  currentmethods  in  all  three  steps.  In  addition,  we  analyze  the  performance  of  oursystem  to  show  the  specific  contribution  of  the  integrating  components  to  theoverall  improvement.</p>|2019-04-01  22:52:19.493076
http://arxiv.org/abs/1903.11771|A  Large-Scale  Multi-Length  Headline  Corpus  for  Improving  Length-Constrained  Headline  Generation  Model  Evaluation.  (arXiv:1903.11771v2  [cs.CL]  UPDATED)|<p>Browsing  news  articles  on  multiple  devices  is  now  possible.  The  lengths  ofnews  article  headlines  have  precise  upper  bounds,  dictated  by  the  size  of  thedisplay  of  the  relevant  device  or  interface.  Therefore,  controlling  the  lengthof  headlines  is  essential  when  applying  the  task  of  headline  generation  to  newsproduction.  However,  because  there  is  no  corpus  of  headlines  of  multiplelengths  for  a  given  article,  prior  researches  on  controlling  output  length  inheadline  generation  have  not  discussed  whether  the  evaluation  of  the  settingthat  uses  a  single  length  reference  can  evaluate  multiple  length  outputsappropriately.  In  this  paper,  we  introduce  two  corpora  (JNC  and  JAMUL)  toconfirm  the  validity  of  prior  experimental  settings  and  provide  for  the  nextstep  toward  the  goal  of  controlling  output  length  in  headline  generation.  TheJNC  provides  common  supervision  data  for  headline  generation.  The  JAMUL  is  alarge-scale  evaluation  dataset  for  headlines  of  three  different  lengthscomposed  by  professional  editors.  We  report  new  findings  on  these  corpora;  forexample,  while  the  longest  length  reference  summary  can  appropriately  evaluatethe  existing  methods  controlling  output  length,  the  methods  do  not  manage  theselection  of  words  according  to  length  constraint.</p>|2019-04-01  22:52:19.493112
http://arxiv.org/abs/1903.11783|A  dataset  for  resolving  referring  expressions  in  spoken  dialogue  via  contextual  query  rewrites  (CQR).  (arXiv:1903.11783v2  [cs.CL]  UPDATED)|<p>We  present  Contextual  Query  Rewrite  (CQR)  a  dataset  for  multi-domaintask-oriented  spoken  dialogue  systems  that  is  an  extension  of  the  Stanforddialog  corpus  (Eric  et  al.,  2017a).  While  previous  approaches  have  addressedthe  issue  of  diverse  schemas  by  learning  candidate  transformations  (Naik  etal.,  2018),  we  instead  model  the  reference  resolution  task  as  a  user  queryreformulation  task,  where  the  dialog  state  is  serialized  into  a  naturallanguage  query  that  can  be  executed  by  the  downstream  spoken  languageunderstanding  system.  In  this  paper,  we  describe  our  methodology  for  creatingthe  query  reformulation  extension  to  the  dialog  corpus,  and  present  an  initialset  of  experiments  to  establish  a  baseline  for  the  CQR  task.  We  have  releasedthe  corpus  to  the  public  [1]  to  support  further  research  in  this  area.</p>|2019-04-01  22:52:19.493144
http://arxiv.org/abs/1903.11787|Successive-Cancellation  Decoding  of  Linear  Source  Code.  (arXiv:1903.11787v2  [cs.IT]  UPDATED)|<p>This  paper  investigates  the  error  probability  of  several  decoding  methods  fora  source  code  with  decoder  side  information,  where  the  decoding  methods  are:  1)symbol-wise  maximum  a  posteriori  decoding,  2)  successive-cancellation  decoding,and  3)  stochastic  successive-cancellation  decoding.  The  proof  of  theeffectiveness  of  a  decoding  method  is  reduced  to  that  for  an  arbitrary  decodingmethod,  where  `effective'  means  that  the  error  probability  goes  to  zero  as  $n$goes  to  infinity.  Furthermore,  we  revisit  the  polar  source  code  showing  thatstochastic  successive-cancellation  decoding,  as  well  as  successive-cancellationdecoding,  is  effective  for  this  code.</p>|2019-04-01  22:52:19.493174
http://arxiv.org/abs/1903.11791|Hierarchical  Pooling  Structure  for  Weakly  Labeled  Sound  Event  Detection.  (arXiv:1903.11791v2  [cs.SD]  UPDATED)|<p>Sound  event  detection  with  weakly  labeled  data  is  considered  as  a  problem  ofmulti-instance  learning.  And  the  choice  of  pooling  function  is  the  key  tosolving  this  problem.  In  this  paper,  we  proposed  a  hierarchical  poolingstructure  to  improve  the  performance  of  weakly  labeled  sound  event  detectionsystem.  Proposed  pooling  structure  has  made  remarkable  improvements  on  threetypes  of  pooling  function  without  adding  any  parameters.  Moreover,  our  systemhas  achieved  competitive  performance  on  Task  4  of  Detection  and  Classificationof  Acoustic  Scenes  and  Events  (DCASE)  2017  Challenge  using  hierarchical  poolingstructure.</p>|2019-04-01  22:52:19.493204
http://arxiv.org/abs/1903.11863|On  Inertial  Navigation  and  Attitude  Initialization  in  Polar  Areas.  (arXiv:1903.11863v2  [cs.RO]  UPDATED)|<p>Inertial  navigation  and  attitude  initialization  in  polar  areas  become  a  hottopic  in  recent  years  in  the  navigation  community,  as  the  widely-usednavigation  mechanization  of  the  local  level  frame  encounters  the  inherentsingularity  when  the  latitude  approaches  90  degrees.  Great  endeavors  have  beendevoted  to  devising  novel  navigation  mechanizations  such  as  the  grid  ortransversal  frames.  This  paper  highlights  the  fact  that  the  common  Earth-framemechanization  is  sufficiently  good  to  well  handle  the  singularity  problem  inpolar  areas.  Simulation  results  are  reported  to  demonstrate  the  singularityproblem  and  the  effectiveness  of  the  Earth-frame  mechanization.</p>|2019-04-01  22:52:19.493235
http://arxiv.org/abs/1903.12033|Repeatable  and  Reproducible  Wireless  Networking  Experimentation  through  Trace-based  Simulation.  (arXiv:1903.12033v2  [cs.NI]  UPDATED)|<p>To  properly  validate  wireless  networking  solutions  we  depend  onexperimentation.  Simulation  very  often  produces  less  accurate  results  due  tothe  use  of  models  that  are  simplifications  of  the  real  phenomena  they  try  tomodel.  Networking  experimentation  may  offer  limited  repeatability  andreproducibility.  Being  influenced  by  external  random  phenomena  such  as  noise,interference,  and  multipath,  real  experiments  are  hardly  repeatable.  Inaddition,  they  are  difficult  to  reproduce  due  to  testbed  operationalconstraints  and  availability.  Without  repeatability  and  reproducibility,  thevalidation  of  the  networking  solution  under  evaluation  is  questionable.  In  thispaper,  we  show  how  the  Trace-based  Simulation  (TS)  approach  can  be  used  toaccurately  repeat  and  reproduce  real  experiments  and,  consequently,  introduce  aparadigm  shift  when  it  comes  to  the  evaluation  of  wireless  networkingsolutions.  We  present  an  extensive  evaluation  of  the  TS  approach  using  theFed4FIRE+  w-iLab.2  testbed.  The  results  show  that  it  is  possible  to  repeat  andreproduce  real  experiments  using  ns-3  trace-based  simulations  with  moreaccuracy  than  in  pure  simulation,  with  average  accuracy  gains  above  50%.</p>|2019-04-01  22:52:19.493300
http://arxiv.org/abs/1903.12063|Robust,  fast  and  accurate:  a  3-step  method  for  automatic  histological  image  registration.  (arXiv:1903.12063v2  [cs.CV]  UPDATED)|<p>We  present  a  3-step  registration  pipeline  for  differently  stainedhistological  serial  sections  that  consists  of  1)  a  robust  pre-alignment,  2)  aparametric  registration  computed  on  coarse  resolution  images,  and  3)  anaccurate  nonlinear  registration.  In  all  three  steps  the  NGF  distance  measure  isminimized  with  respect  to  an  increasingly  flexible  transformation.  We  apply  themethod  in  the  ANHIR  image  registration  challenge  and  evaluate  its  performanceon  the  training  data.  The  presented  method  is  robust  (error  reduction  in  99.6%of  the  cases),  fast  (runtime  4  seconds)  and  accurate  (median  relative  targetregistration  error  0.19%).</p>|2019-04-01  22:52:19.493332
http://arxiv.org/abs/1903.11672|MuSE-ing  on  the  Impact  of  Utterance  Ordering  On  Crowdsourced  Emotion  Annotations.  (arXiv:1903.11672v1  [cs.SD]  CROSS  LISTED)|<p>Emotion  recognition  algorithms  rely  on  data  annotated  with  high  qualitylabels.  However,  emotion  expression  and  perception  are  inherently  subjective.There  is  generally  not  a  single  annotation  that  can  be  unambiguously  declared"correct".  As  a  result,  annotations  are  colored  by  the  manner  in  which  theywere  collected.  In  this  paper,  we  conduct  crowdsourcing  experiments  toinvestigate  this  impact  on  both  the  annotations  themselves  and  on  theperformance  of  these  algorithms.  We  focus  on  one  critical  question:  the  effectof  context.  We  present  a  new  emotion  dataset,  Multimodal  Stressed  Emotion(MuSE),  and  annotate  the  dataset  using  two  conditions:  randomized,  in  whichannotators  are  presented  with  clips  in  random  order,  and  contextualized,  inwhich  annotators  are  presented  with  clips  in  order.  We  find  that  contextuallabeling  schemes  result  in  annotations  that  are  more  similar  to  a  speaker's  ownself-reported  labels  and  that  labels  generated  from  randomized  schemes  are  mosteasily  predictable  by  automated  systems.</p>|2019-04-01  22:52:19.493363
http://arxiv.org/abs/1903.11935|A  Stay-in-a-Set  Game  without  a  Stationary  Equilibrium.  (arXiv:1903.11935v1  [math.OC]  CROSS  LISTED)|<p>We  give  an  example  of  a  finite-state  two-player  turn-based  stochastic  gamewith  safety  objectives  for  both  players  which  has  no  stationary  Nashequilibrium.  This  answers  an  open  question  of  Secchi  and  Sudderth.</p>|2019-04-01  22:52:19.493394
