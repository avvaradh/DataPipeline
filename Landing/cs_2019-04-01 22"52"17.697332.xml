<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>cs updates on arXiv.org</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">Computer Science (cs) updates on the arXiv.org e-print archive</description>
<dc:language>en-us</dc:language>
<dc:date>2019-03-31T20:30:00-05:00</dc:date>
<dc:publisher>www-admin@arxiv.org</dc:publisher>
<dc:subject>Computer Science</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12178" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12204" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12206" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12211" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12212" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12216" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12220" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12221" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12225" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12226" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12235" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12238" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12239" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12247" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12248" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12254" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12255" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12258" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12259" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12260" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12261" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12262" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12264" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12266" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12269" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12270" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12271" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12272" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12282" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12286" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12287" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12289" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12290" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12294" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12296" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12297" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12301" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12302" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12303" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12305" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12307" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12311" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12312" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12314" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12316" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12318" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12322" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12325" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12328" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12329" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12330" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12331" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12337" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12340" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12344" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12347" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12348" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12349" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12351" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12354" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12355" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12356" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12359" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12360" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12363" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12366" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12368" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12370" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12371" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12384" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12385" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12386" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12388" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12389" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12392" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12394" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12395" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12398" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12399" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12400" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12402" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12411" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12416" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12417" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12422" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12424" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12427" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12431" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12432" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12436" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12449" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12451" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12452" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12453" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12457" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12458" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12466" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12467" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12468" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12469" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12470" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12472" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12473" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12476" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12480" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12482" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12483" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12487" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12489" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12493" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12495" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12497" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12505" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12508" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12509" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12510" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12514" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12516" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12517" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12519" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12520" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12525" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12527" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12529" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12530" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12536" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12542" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12546" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12549" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12551" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12552" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12553" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12554" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12556" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12561" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12564" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12570" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12571" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12575" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12576" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12577" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12579" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12581" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12582" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12584" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12589" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12600" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12605" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12616" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12617" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12620" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12626" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12641" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12644" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12648" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12650" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12653" />
  <rdf:li rdf:resource="http://arxiv.org/abs/cs/0601132" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1505.02847" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1610.01234" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1704.00229" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1706.09606" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1711.07230" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1712.02719" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1712.04054" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1801.10365" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1802.01751" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1802.02607" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1802.04364" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1803.10681" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1804.03295" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1804.10445" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.05086" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.11519" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1805.11529" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1806.01825" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1806.07307" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1806.11306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.01697" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.02631" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.07560" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1807.08284" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.02223" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.05929" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1809.10243" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.04369" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1810.09948" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.00656" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.03199" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.03706" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.04918" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.07619" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.10719" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.11742" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.12197" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1811.12784" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.00573" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.01946" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.02849" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.03952" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.04948" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.06570" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.09638" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.11448" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.11631" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1812.11771" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.00224" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.04713" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.07879" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1901.09109" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.03368" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.05679" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.07836" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.07848" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.09130" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.09500" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.10505" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1902.11191" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.00709" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.01698" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.02728" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.06494" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.08252" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.08450" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09333" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09465" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09717" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.09755" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.10605" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11242" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11249" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11250" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11306" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11340" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11771" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11783" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11787" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11791" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11863" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12033" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.12063" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11672" />
  <rdf:li rdf:resource="http://arxiv.org/abs/1903.11935" />
 </rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image>
<item rdf:about="http://arxiv.org/abs/1903.12178">
<title>Open-ended Evolution and a Mechanism of Novelties in Web Services. (arXiv:1903.12178v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1903.12178</link>
<description rdf:parseType="Literal">&lt;p&gt;Analogous to living ecosystems in nature, web services form an artificial
ecosystem consisting of many tags and their associated media, such as
photographs, movies, and web pages created by human users. Concerning
biological ecosystems, we regard tag as a species and human as a hidden
environmental resource. We subsequently analyze the evolution of the web
services, in particular social tagging systems, with respect to the
self-organization of new tags. The evolution of new combinations of tags is
analyzed as the open-ended evolution (OEE) index. The tag meaning is computed
by the types of associated tags; tags that vary their meanings temporally
exist. We argue that such tags are the examples of OEE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ikegami_T/0/1/0/all/0/1&quot;&gt;Takashi Ikegami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashimoto_Y/0/1/0/all/0/1&quot;&gt;Yasuhiro Hashimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oka_M/0/1/0/all/0/1&quot;&gt;Mizuki Oka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12204">
<title>Mutex-based Desanonymization of an Anonymous Read/Write Memory. (arXiv:1903.12204v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1903.12204</link>
<description rdf:parseType="Literal">&lt;p&gt;Anonymous shared memory is a memory in which processes use different names
for the same shared read/write register. As an example, a shared register named
$A$ by a process $p$ and a shared register named $B$ by another process $q$ can
correspond to the very same register $X$, and similarly for the names $B$ at
$p$ and $A$ at $q$ which can correspond to the same register $Y\neq X$. Hence,
there is a permanent disagreement on the register names among the processes.
This new notion of anonymity was recently introduced by G. Taubenfeld (PODC
2017), who presented several memory-anonymous algorithms and impossibility
results.
&lt;/p&gt;
&lt;p&gt;This paper introduces a new problem (new to our knowledge), that consists in
&quot;desanonymizing&quot; an anonymous shared memory. To this end, it presents an
algorithm that, starting with a shared memory made up of $m$ anonymous
read/write atomic registers (i.e., there is no a priori agreement on their
names), allows each process to compute a local addressing mapping, such that
all the processes agree on the names of each register. The proposed
construction is based on an underlying deadlock-free mutex algorithm for $n\geq
2$ processes (recently proposed in a paper co-authored by some of the authors
of this paper), and consequently inherits its necessary and sufficient
condition on the size $m$ of the anonymous memory, namely $m$ must belongs to
the set $M(n)=\{m:~$ such that $\forall~ \ell: 1&amp;lt;\ell \leq n:~
\gcd(\ell,m)=1\}\setminus \{1\}$. This algorithm, which is also symmetric in
the sense process identities can only be compared by equality, requires the
participation of all the processes; hence it can be part of the system
initialization. Last but not least, the proposed algorithm has a first-class
noteworthy property, namely, its simplicity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godard_E/0/1/0/all/0/1&quot;&gt;Emmanuel Godard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Imbs_D/0/1/0/all/0/1&quot;&gt;Damien Imbs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raynal_M/0/1/0/all/0/1&quot;&gt;Michel Raynal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taubenfeld_G/0/1/0/all/0/1&quot;&gt;Gadi Taubenfeld&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12206">
<title>Counting with Focus for Free. (arXiv:1903.12206v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12206</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper aims to count arbitrary objects in images. The leading counting
approaches start from point annotations per object from which they construct
density maps. Then, their training objective transforms input images to density
maps through deep convolutional networks. We posit that the point annotations
serve more supervision purposes than just constructing density maps. We
introduce ways to repurpose the points for free. First, we propose supervised
focus from segmentation, where points are converted into binary maps. The
binary maps are combined with a network branch and accompanying loss function
to focus on areas of interest. Second, we propose supervised focus from global
density, where the ratio of point annotations to image pixels is used in
another branch to regularize the overall density estimation. To assist both the
density estimation and the focus from segmentation, we also introduce an
improved kernel size estimator for the point annotations. Experiments on four
datasets show that all our contributions reduce the counting error, regardless
of the base network, resulting in state-of-the-art accuracy using only a single
network. Finally, we are the first to count on WIDER FACE, allowing us to show
the benefits of our approach in handling varying object scales and crowding
levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zenglin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mettes_P/0/1/0/all/0/1&quot;&gt;Pascal Mettes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1&quot;&gt;Cees G. M. Snoek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12211">
<title>Privacy of trajectory micro-data : a survey. (arXiv:1903.12211v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1903.12211</link>
<description rdf:parseType="Literal">&lt;p&gt;We survey the literature on the privacy of trajectory micro-data, i.e.,
spatiotemporal information about the mobility of individuals, whose collection
is becoming increasingly simple and frequent thanks to emerging information and
communication technologies. The focus of our review is on privacy-preserving
data publishing (PPDP), i.e., the publication of databases of trajectory
micro-data that preserve the privacy of the monitored individuals. We classify
and present the literature of attacks against trajectory micro-data, as well as
solutions proposed to date for protecting databases from such attacks. This
paper serves as an introductory reading on a critical subject in an era of
growing awareness about privacy risks connected to digital services, and
provides insights into open problems and future directions for research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiore_M/0/1/0/all/0/1&quot;&gt;Marco Fiore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsikouli_P/0/1/0/all/0/1&quot;&gt;Panagiota Katsikouli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zavou_E/0/1/0/all/0/1&quot;&gt;Elli Zavou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cunche_M/0/1/0/all/0/1&quot;&gt;Mathieu Cunche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fessant_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;oise Fessant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hello_D/0/1/0/all/0/1&quot;&gt;Dominique Le Hello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aivodji_U/0/1/0/all/0/1&quot;&gt;Ulrich Matchi Aivodji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olivier_B/0/1/0/all/0/1&quot;&gt;Baptiste Olivier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quertier_T/0/1/0/all/0/1&quot;&gt;Tony Quertier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanica_R/0/1/0/all/0/1&quot;&gt;Razvan Stanica&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12212">
<title>All about Structure: Adapting Structural Information across Domains for Boosting Semantic Segmentation. (arXiv:1903.12212v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12212</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we tackle the problem of unsupervised domain adaptation for the
task of semantic segmentation, where we attempt to transfer the knowledge
learned upon synthetic datasets with ground-truth labels to real-world images
without any annotation. With the hypothesis that the structural content of
images is the most informative and decisive factor to semantic segmentation and
can be readily shared across domains, we propose a Domain Invariant Structure
Extraction (DISE) framework to disentangle images into domain-invariant
structure and domain-specific texture representations, which can further
realize image-translation across domains and enable label transfer to improve
segmentation performance. Extensive experiments verify the effectiveness of our
proposed DISE model and demonstrate its superiority over several
state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_W/0/1/0/all/0/1&quot;&gt;Wei-Lun Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hui-Po Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1&quot;&gt;Wen-Hsiao Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiu_W/0/1/0/all/0/1&quot;&gt;Wei-Chen Chiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12216">
<title>Towards 6G Networks: Use Cases and Technologies. (arXiv:1903.12216v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1903.12216</link>
<description rdf:parseType="Literal">&lt;p&gt;As the digital world becomes increasingly intelligent, automated and
ubiquitous, the flow of data becomes ever more vital. Mobile wireless networks
are the data highways, and in a fully connected, intelligent digital world,
they will need to connect everything from people, vehicles, sensors, data,
cloud resources and even robotic agents. Fifth generation (5G) wireless
networks that are being released soon offer significant advances, but may be
unable to meet the full connectivity demands of emerging systems. This paper
envisions how 6G systems can be developed to address the needs of smart
networks of the future. The article considers several potential 6G use cases
and attempts to provide estimates on requirements to guide design. The demands
are daunting, but several promising technologies that can provide the basis for
6G systems are also surveyed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giordani_M/0/1/0/all/0/1&quot;&gt;Marco Giordani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polese_M/0/1/0/all/0/1&quot;&gt;Michele Polese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mezzavilla_M/0/1/0/all/0/1&quot;&gt;Marco Mezzavilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangan_S/0/1/0/all/0/1&quot;&gt;Sundeep Rangan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zorzi_M/0/1/0/all/0/1&quot;&gt;Michele Zorzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12220">
<title>The Algorithmic Automation Problem: Prediction, Triage, and Human Effort. (arXiv:1903.12220v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12220</link>
<description rdf:parseType="Literal">&lt;p&gt;In a wide array of areas, algorithms are matching and surpassing the
performance of human experts, leading to consideration of the roles of human
judgment and algorithmic prediction in these domains. The discussion around
these developments, however, has implicitly equated the specific task of
prediction with the general task of automation. We argue here that automation
is broader than just a comparison of human versus algorithmic performance on a
task; it also involves the decision of which instances of the task to give to
the algorithm in the first place. We develop a general framework that poses
this latter decision as an optimization problem, and we show how basic
heuristics for this optimization problem can lead to performance gains even on
heavily-studied applications of AI in medicine. Our framework also serves to
highlight how effective automation depends crucially on estimating both
algorithmic and human error on an instance-by-instance basis, and our results
show how improvements in these error estimation problems can yield significant
gains for automation as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghu_M/0/1/0/all/0/1&quot;&gt;Maithra Raghu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blumer_K/0/1/0/all/0/1&quot;&gt;Katy Blumer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corrado_G/0/1/0/all/0/1&quot;&gt;Greg Corrado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1&quot;&gt;Jon Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obermeyer_Z/0/1/0/all/0/1&quot;&gt;Ziad Obermeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mullainathan_S/0/1/0/all/0/1&quot;&gt;Sendhil Mullainathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12221">
<title>Mitigating Cold Starts in Serverless Platforms: A Pool-Based Approach. (arXiv:1903.12221v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1903.12221</link>
<description rdf:parseType="Literal">&lt;p&gt;Rapid adoption of the serverless (or Function-as-a-Service, FaaS) paradigm,
pioneered by Amazon with AWS Lambda and followed by numerous commercial
offerings and open source projects, introduces new challenges in designing the
cloud infrastructure, balancing between performance and cost. While instant
per-request elasticity that FaaS platforms typically offer application
developers makes it possible to achieve high performance of bursty workloads
without over-provisioning, such elasticity often involves extra latency
associated with on-demand provisioning of individual runtime containers that
serve the functions. This phenomenon is often called cold starts, as opposed to
the situation when a function is served by a pre-provisioned &quot;warm&quot; container,
ready to serve requests with close to zero overhead. Providers are constantly
working on techniques aimed at reducing cold starts. A common approach to
reduce cold starts is to maintain a pool of warm containers, in anticipation of
future requests. In this report, we address the cold start problem in
serverless architectures, specifically under the Knative Serving FaaS platform.
We describe our implementation leveraging a pool of function instances, and
evaluate the latency compared to the original implementation, resulting in a
85% reduction of P99 response time for a single instance pool.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1&quot;&gt;Ping-Min Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glikson_A/0/1/0/all/0/1&quot;&gt;Alex Glikson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12225">
<title>Arc-disjoint Strong Spanning Subdigraphs of Semicomplete Compositions. (arXiv:1903.12225v1 [cs.DM])</title>
<link>http://arxiv.org/abs/1903.12225</link>
<description rdf:parseType="Literal">&lt;p&gt;A strong arc decomposition of a digraph $D=(V,A)$ is a decomposition of its
arc set $A$ into two disjoint subsets $A_1$ and $A_2$ such that both of the
spanning subdigraphs $D_1=(V,A_1)$ and $D_2=(V,A_2)$ are strong. Let $T$ be a
digraph with $t$ vertices $u_1,\dots , u_t$ and let $H_1,\dots H_t$ be digraphs
such that $H_i$ has vertices $u_{i,j_i},\ 1\le j_i\le n_i.$ Then the
composition $Q=T[H_1,\dots , H_t]$ is a digraph with vertex set $\cup_{i=1}^t
V(H_i)=\{u_{i,j_i}\mid 1\le i\le t, 1\le j_i\le n_i\}$ and arc set \[
\left(\cup^t_{i=1}A(H_i) \right) \cup \left( \cup_{u_iu_p\in A(T)}
\{u_{ij_i}u_{pq_p} \mid 1\le j_i\le n_i, 1\le q_p\le n_p\} \right). \] We
obtain a characterization of digraph compositions $Q=T[H_1,\dots H_t]$ which
have a strong arc decomposition when $T$ is a semicomplete digraph and each
$H_i$ is an arbitrary digraph. Our characterization generalizes a
characterization by Bang-Jensen and Yeo (2003) of semicomplete digraphs with a
strong arc decomposition and solves an open problem by Sun, Gutin and Ai (2018)
on strong arc decompositions of digraph compositions $Q=T[H_1,\dots , H_t]$ in
which $T$ is semicomplete and each $H_i$ is arbitrary. Our proofs are
constructive and imply the existence of a polynomial algorithm for constructing
a \good{} decomposition of a digraph $Q=T[H_1,\dots , H_t]$, with $T$
semicomplete, whenever such a decomposition exists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bang_Jensen_J/0/1/0/all/0/1&quot;&gt;Joergen Bang-Jensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutin_G/0/1/0/all/0/1&quot;&gt;Gregory Gutin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeo_A/0/1/0/all/0/1&quot;&gt;Anders Yeo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12226">
<title>Co-evolving Tracing and Fault Injection with Box of Pain. (arXiv:1903.12226v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1903.12226</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed systems are hard to reason about largely because of uncertainty
about what may go wrong in a particular execution, and about whether the system
will mitigate those faults. Tools that perturb executions can help test whether
a system is robust to faults, while tools that observe executions can help
better understand their system-wide effects. We present Box of Pain, a tracer
and fault injector for unmodified distributed systems that addresses both
concerns by interposing at the system call level and dynamically reconstructing
the partial order of communication events based on causal relationships. Box of
Pain&apos;s lightweight approach to tracing and focus on simulating the effects of
partial failures on communication rather than the failures themselves sets it
apart from other tracing and fault injection systems. We present evidence of
the promise of Box of Pain and its approach to lightweight observation and
perturbation of distributed systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bittman_D/0/1/0/all/0/1&quot;&gt;Daniel Bittman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_E/0/1/0/all/0/1&quot;&gt;Ethan L. Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alvaro_P/0/1/0/all/0/1&quot;&gt;Peter Alvaro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12230">
<title>Learning to Transfer Examples for Partial Domain Adaptation. (arXiv:1903.12230v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12230</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain adaptation is critical for learning in new and unseen environments.
With domain adversarial training, deep networks can learn disentangled and
transferable features that effectively diminish the dataset shift between the
source and target domains for knowledge transfer. In the era of Big Data, the
ready availability of large-scale labeled datasets has stimulated wide interest
in partial domain adaptation (PDA), which transfers a recognizer from a labeled
large domain to an unlabeled small domain. It extends standard domain
adaptation to the scenario where target labels are only a subset of source
labels. Under the condition that target labels are unknown, the key challenge
of PDA is how to transfer relevant examples in the shared classes to promote
positive transfer, and ignore irrelevant ones in the specific classes to
mitigate negative transfer. In this work, we propose a unified approach to PDA,
Example Transfer Network (ETN), which jointly learns domain-invariant
representations across the source and target domains, and a progressive
weighting scheme that quantifies the transferability of source examples while
controlling their importance to the learning task in the target domain. A
thorough evaluation on several benchmark datasets shows that our approach
achieves state-of-the-art results for partial domain adaptation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1&quot;&gt;Zhangjie Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_K/0/1/0/all/0/1&quot;&gt;Kaichao You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1&quot;&gt;Mingsheng Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianmin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12235">
<title>Information Theoretic Feature Transformation Learning for Brain Interfaces. (arXiv:1903.12235v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12235</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: A variety of pattern analysis techniques for model training in
brain interfaces exploit neural feature dimensionality reduction based on
feature ranking and selection heuristics. In the light of broad evidence
demonstrating the potential sub-optimality of ranking based feature selection
by any criterion, we propose to extend this focus with an information theoretic
learning driven feature transformation concept. Methods: We present a maximum
mutual information linear transformation (MMI-LinT), and a nonlinear
transformation (MMI-NonLinT) framework derived by a general definition of the
feature transformation learning problem. Empirical assessments are performed
based on electroencephalographic (EEG) data recorded during a four class motor
imagery brain-computer interface (BCI) task. Exploiting state-of-the-art
methods for initial feature vector construction, we compare the proposed
approaches with conventional feature selection based dimensionality reduction
techniques which are widely used in brain interfaces. Furthermore, for the
multi-class problem, we present and exploit a hierarchical graphical model
based BCI decoding system. Results: Both binary and multi-class decoding
analyses demonstrate significantly better performances with the proposed
methods. Conclusion: Information theoretic feature transformations are capable
of tackling potential confounders of conventional approaches in various
settings. Significance: We argue that this concept provides significant
insights to extend the focus on feature selection heuristics to a broader
definition of feature transformation learning in brain interfaces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozdenizci_O/0/1/0/all/0/1&quot;&gt;Ozan Ozdenizci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erdogmus_D/0/1/0/all/0/1&quot;&gt;Deniz Erdogmus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12238">
<title>Modeling Acoustic-Prosodic Cues for Word Importance Prediction in Spoken Dialogues. (arXiv:1903.12238v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12238</link>
<description rdf:parseType="Literal">&lt;p&gt;Prosodic cues in conversational speech aid listeners in discerning a message.
We investigate whether acoustic cues in spoken dialogue can be used to identify
the importance of individual words to the meaning of a conversation turn.
Individuals who are Deaf and Hard of Hearing often rely on real-time captions
in live meetings. Word error rate, a traditional metric for evaluating
automatic speech recognition, fails to capture that some words are more
important for a system to transcribe correctly than others. We present and
evaluate neural architectures that use acoustic features for 3-class word
importance prediction. Our model performs competitively against
state-of-the-art text-based word-importance prediction models, and it
demonstrates particular benefits when operating on imperfect ASR output.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kafle_S/0/1/0/all/0/1&quot;&gt;Sushant Kafle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alm_C/0/1/0/all/0/1&quot;&gt;Cecilia O. Alm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huenerfauth_M/0/1/0/all/0/1&quot;&gt;Matt Huenerfauth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12239">
<title>SpaceNet MVOI: a Multi-View Overhead Imagery Dataset. (arXiv:1903.12239v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12239</link>
<description rdf:parseType="Literal">&lt;p&gt;Detection and segmentation of objects in overheard imagery is a challenging
task. The variable density, random orientation, small size, and
instance-to-instance heterogeneity of objects in overhead imagery calls for
approaches distinct from existing models designed for natural scene datasets.
Though new overhead imagery datasets are being developed, they almost
universally comprise a single view taken from directly overhead (&quot;at nadir&quot;),
failing to address one critical variable: look angle. By contrast, views vary
in real-world overhead imagery, particularly in dynamic scenarios such as
natural disasters where first looks are often over 40 degrees off-nadir. This
represents an important challenge to computer vision methods, as changing view
angle adds distortions, alters resolution, and changes lighting. At present,
the impact of these perturbations for algorithmic detection and segmentation of
objects is untested. To address this problem, we introduce the SpaceNet
Multi-View Overhead Imagery (MVOI) Dataset, an extension of the SpaceNet open
source remote sensing dataset. MVOI comprises 27 unique looks from a broad
range of viewing angles (-32 to 54 degrees). Each of these images cover the
same geography and are annotated with 126,747 building footprint labels,
enabling direct assessment of the impact of viewpoint perturbation on model
performance. We benchmark multiple leading segmentation and object detection
models on: (1) building detection, (2) generalization to unseen viewing angles
and resolutions, and (3) sensitivity of building footprint extraction to
changes in resolution. We find that segmentation and object detection models
struggle to identify buildings in off-nadir imagery and generalize poorly to
unseen views, presenting an important benchmark to explore the broadly relevant
challenge of detecting small, heterogeneous target objects in visually dynamic
contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weir_N/0/1/0/all/0/1&quot;&gt;Nicholas Weir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindenbaum_D/0/1/0/all/0/1&quot;&gt;David Lindenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastidas_A/0/1/0/all/0/1&quot;&gt;Alexei Bastidas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Etten_A/0/1/0/all/0/1&quot;&gt;Adam Van Etten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McPherson_S/0/1/0/all/0/1&quot;&gt;Sean McPherson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shermeyer_J/0/1/0/all/0/1&quot;&gt;Jacob Shermeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Varun Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hanlin Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12243">
<title>DEEP-FRI: Sampling outside the box improves soundness. (arXiv:1903.12243v1 [cs.CC])</title>
<link>http://arxiv.org/abs/1903.12243</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the quest for scalable and succinct zero knowledge arguments, we
revisit worst-case-to-average-case reductions for linear spaces, raised by
[Rothblum, Vadhan, Wigderson, STOC 2013]. We first show a sharp quantitative
form of a theorem which says that if an affine space $U$ is $\delta$-far in
relative Hamming distance from a linear code $V$ - this is the worst-case
assumption - then most elements of $U$ are almost $\delta$-far from $V$ - this
is the average case. This leads to an optimal analysis of the soundness of the
FRI protocol of [Ben-Sasson, et.al., eprint 2018] for proving proximity to
Reed-Solomon codes.
&lt;/p&gt;
&lt;p&gt;To further improve soundness, we sample outside the box. We suggest a new
protocol which asks a prover for values of a polynomial at points outside the
domain of evaluation of the Reed-Solomon code. We call this technique Domain
Extending for Eliminating Pretenders (DEEP).
&lt;/p&gt;
&lt;p&gt;We use the DEEP technique to devise two new protocols: (1) An Interactive
Oracle Proof of Proximity (IOPP) for RS codes, called DEEP-FRI. This soundness
of the protocol improves upon that of the FRI protocol while retaining linear
arithmetic proving complexity and logarithmic verifier arithmetic complexity.
(2) An Interactive Oracle Proof (IOP) for the Algebraic Linking IOP (ALI)
protocol used to construct zero knowledge scalable transparent arguments of
knowledge (ZK-STARKs) in [Ben-Sasson et al., eprint 2018]. The new protocol,
called DEEP-ALI, improves soundness of this crucial step from a small constant
$&amp;lt; 1/8$ to a constant arbitrarily close to $1$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ben_Sasson_E/0/1/0/all/0/1&quot;&gt;Eli Ben-Sasson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_L/0/1/0/all/0/1&quot;&gt;Lior Goldberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kopparty_S/0/1/0/all/0/1&quot;&gt;Swastik Kopparty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saraf_S/0/1/0/all/0/1&quot;&gt;Shubhangi Saraf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12247">
<title>iGen: Dynamic Interaction Inference for Configurable Software. (arXiv:1903.12247v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1903.12247</link>
<description rdf:parseType="Literal">&lt;p&gt;To develop, analyze, and evolve today&apos;s highly configurable software systems,
developers need deep knowledge of a system&apos;s configuration options, e.g., how
options need to be set to reach certain locations, what configurations to use
for testing, etc. Today, acquiring this detailed information requires manual
effort that is difficult, expensive, and error prone. In this paper, we propose
iGen, a novel, lightweight dynamic analysis technique that automatically
discovers a program&apos;s \emph{interactions}---expressive logical formulae that
give developers rich and detailed information about how a system&apos;s
configuration option settings map to particular code coverage. iGen employs an
iterative algorithm that runs a system under a small set of configurations,
capturing coverage data; processes the coverage data to infer potential
interactions; and then generates new configurations to further refine
interactions in the next iteration. We evaluated iGen on 29 programs spanning
five languages; the breadth of this study would be unachievable using prior
interaction inference tools. Our results show that iGen finds precise
interactions based on a very small fraction of the number of possible
configurations. Moreover, iGen&apos;s results confirm several earlier hypotheses
about typical interaction distributions and structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;ThanhVu Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koc_U/0/1/0/all/0/1&quot;&gt;Ugur Koc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;Javran Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_J/0/1/0/all/0/1&quot;&gt;Jeffrey S. Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porter_A/0/1/0/all/0/1&quot;&gt;Adam A. Porter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12248">
<title>Adversarial Approximate Inference for Speech to Electroglottograph Conversion. (arXiv:1903.12248v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1903.12248</link>
<description rdf:parseType="Literal">&lt;p&gt;Speech produced by human vocal apparatus conveys substantial non-semantic
information including the gender of the speaker, voice quality, affective
state, abnormalities in the vocal apparatus etc. Such information is attributed
to the properties of the voice source signal, which is usually estimated from
the speech signal. However, most of the source estimation techniques depend
heavily on the goodness of the model assumptions and are prone to noise. A
popular alternative is to indirectly obtain the source information through the
Electroglottographic (EGG) signal that measures the electrical admittance
around the vocal folds using a dedicated hardware. In this paper, we address
the problem of estimating the EGG signal directly from the speech signal,
devoid of any hardware. Sampling from the intractable conditional distribution
of the EGG signal given the speech signal is accomplished through optimization
of an evidence lower bound. This is constructed via minimization of the
KL-divergence between the true and the approximated posteriors of a latent
variable learned using a deep neural auto-encoder that serves an informative
prior which reconstructs the EGG signal. We demonstrate the efficacy of the
method to generate EGG signal by conducting several experiments on datasets
comprising multiple speakers, voice qualities, noise settings and speech
pathologies. The proposed method is evaluated on many benchmark metrics and is
found to agree with the gold standards while being better than the
state-of-the-art algorithms on a few tasks such as epoch extraction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+P%2E_P/0/1/0/all/0/1&quot;&gt;Prathosh A. P.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Srivastava_V/0/1/0/all/0/1&quot;&gt;Varun Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mishra_M/0/1/0/all/0/1&quot;&gt;Mayank Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12254">
<title>Proving Differential Privacy with Shadow Execution. (arXiv:1903.12254v1 [cs.PL])</title>
<link>http://arxiv.org/abs/1903.12254</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work on formal verification of differential privacy shows a trend
toward usability and expressiveness -- generating a correctness proof of
sophisticated algorithm while minimizing the annotation burden on programmers.
Sometimes, combining those two requires substantial changes to program logics:
one recent paper is able to verify Report Noisy Max automatically, but it
involves a complex verification system using customized program logics and
verifiers.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a new proof technique, called shadow execution, and
embed it into a language called ShadowDP. ShadowDP uses shadow execution to
generate proofs of differential privacy with very few programmer annotations
and without relying on customized logics and verifiers. In addition to
verifying Report Noisy Max, we show that it can verify a new variant of Sparse
Vector that reports the gap between some noisy query answers and the noisy
threshold. Moreover, ShadowDP reduces the complexity of verification: for all
of the algorithms we have evaluated, type checking and verification in total
takes at most 3 seconds, while prior work takes minutes on the same algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuxin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1&quot;&gt;Zeyu Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Guanhong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kifer_D/0/1/0/all/0/1&quot;&gt;Daniel Kifer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Danfeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12255">
<title>Improving Object Detection with Inverted Attention. (arXiv:1903.12255v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12255</link>
<description rdf:parseType="Literal">&lt;p&gt;Improving object detectors against occlusion, blur and noise is a critical
step to deploy detectors in real applications. Since it is not possible to
exhaust all image defects through data collection, many researchers seek to
generate hard samples in training. The generated hard samples are either images
or feature maps with coarse patches dropped out in the spatial dimensions.
Significant overheads are required in training the extra hard samples and/or
estimating drop-out patches using extra network branches. In this paper, we
improve object detectors using a highly efficient and fine-grain mechanism
called Inverted Attention (IA). Different from the original detector network
that only focuses on the dominant part of objects, the detector network with IA
iteratively inverts attention on feature maps and puts more attention on
complementary object parts, feature channels and even context. Our approach (1)
operates along both the spatial and channels dimensions of the feature maps;
(2) requires no extra training on hard samples, no extra network parameters for
attention estimation, and no testing overheads. Experiments show that our
approach consistently improved both two-stage and single-stage detectors on
benchmark databases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zeyi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_W/0/1/0/all/0/1&quot;&gt;Wei Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Dong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12258">
<title>Using Deep Learning Neural Networks and Candlestick Chart Representation to Predict Stock Market. (arXiv:1903.12258v1 [q-fin.GN])</title>
<link>http://arxiv.org/abs/1903.12258</link>
<description rdf:parseType="Literal">&lt;p&gt;Stock market prediction is still a challenging problem because there are many
factors effect to the stock market price such as company news and performance,
industry performance, investor sentiment, social media sentiment and economic
factors. This work explores the predictability in the stock market using Deep
Convolutional Network and candlestick charts. The outcome is utilized to design
a decision support framework that can be used by traders to provide suggested
indications of future stock price direction. We perform this work using various
types of neural networks like convolutional neural network, residual network
and visual geometry group network. From stock market historical data, we
converted it to candlestick charts. Finally, these candlestick charts will be
feed as input for training a Convolutional Neural Network model. This
Convolutional Neural Network model will help us to analyze the patterns inside
the candlestick chart and predict the future movements of stock market. The
effectiveness of our method is evaluated in stock market prediction with a
promising results 92.2% and 92.1% accuracy for Taiwan and Indonesian stock
market dataset respectively. The constructed model have been implemented as a
web-based system freely available at &lt;a href=&quot;http://140.138.155.216/deepcandle/&quot;&gt;this http URL&lt;/a&gt; for
predicting stock market using candlestick chart and deep learning neural
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Kusuma_R/0/1/0/all/0/1&quot;&gt;Rosdyana Mangir Irawan Kusuma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Ho_T/0/1/0/all/0/1&quot;&gt;Trang-Thi Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Kao_W/0/1/0/all/0/1&quot;&gt;Wei-Chun Kao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Ou_Y/0/1/0/all/0/1&quot;&gt;Yu-Yen Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Hua_K/0/1/0/all/0/1&quot;&gt;Kai-Lung Hua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12259">
<title>Efficient Use of Spectral Resources in Wireless Communication Using Training Data Optimization. (arXiv:1903.12259v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1903.12259</link>
<description rdf:parseType="Literal">&lt;p&gt;Wireless communication applications has acquired a vastly increasing range
over the past decade. This rapidly increasing demand implies limitations on
utilizing wireless resources. One of the most important resources in wireless
communication is frequency spectrum. This thesis provides different solutions
towards increasing the spectral efficiency. The first solution provided in this
thesis is to use a more accurate optimization metric: maximal acheivable rate
(compared to traditional metric: ergodic capacity) to optimize training data
size in wireless communication. Training data symbols are previously known
symbols to the receiver inserted in data packets which are used by receiver to
acquire channel state information (CSI). Optimizing training data size with
respect to our proposed tight optimization metric, we could achieve higher
rates especially for short packet and ultra reliable applications. Our second
proposed solution to increase spectral efficiency is to design a multifunction
communication and sensing platform utilizing a special training sequence
design. We proposed a platform where two training sequences are designed, one
for the base-station and the other for the user. By designing these two
training sequence such that they are uncorrelated to each other, the base
station will be able to distinguish between the two training sequence. Having
one of the sequences especially designed for radar purposes (by designing it
such that it has an impulse-like autocorrelation), the system will be able to
sense the environment, transmit and receive the communication data
simultaneously.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mousaei_M/0/1/0/all/0/1&quot;&gt;Mohammadreza Mousaei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12260">
<title>Digital Signal Processing Techniques for High-Speed Optical Communications Links. (arXiv:1903.12260v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1903.12260</link>
<description rdf:parseType="Literal">&lt;p&gt;The main topic of this thesis is the application of advanced Digital Signal
Processing (DSP) techniques to high data-rate optical links. This thesis is
divided in two parts: Direct-Detection systems, and Coherent systems. In the
first part, it is proposed a novel bi-directional architecture for &amp;lt;2km
Intra-DC link and a detailed analysis of self-coherent single-sideband
transmission for &amp;lt;80km dispersion-uncompensated Inter-DC link. The second part
instead focuses on Probabilistic Constellation Shaping techniques, and their
impact on long-haul optical communication links.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pilori_D/0/1/0/all/0/1&quot;&gt;Dario Pilori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12261">
<title>Benchmarking Neural Network Robustness to Common Corruptions and Perturbations. (arXiv:1903.12261v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12261</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we establish rigorous benchmarks for image classifier
robustness. Our first benchmark, ImageNet-C, standardizes and expands the
corruption robustness topic, while showing which classifiers are preferable in
safety-critical applications. Then we propose a new dataset called ImageNet-P
which enables researchers to benchmark a classifier&apos;s robustness to common
perturbations. Unlike recent robustness research, this benchmark evaluates
performance on common corruptions and perturbations not worst-case adversarial
perturbations. We find that there are negligible changes in relative corruption
robustness from AlexNet classifiers to ResNet classifiers. Afterward we
discover ways to enhance corruption and perturbation robustness. We even find
that a bypassed adversarial defense provides substantial common perturbation
robustness. Together our benchmarks may aid future work toward networks that
robustly generalize.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1&quot;&gt;Dan Hendrycks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dietterich_T/0/1/0/all/0/1&quot;&gt;Thomas Dietterich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12262">
<title>Towards Standardization of Data Licenses: The Montreal Data License. (arXiv:1903.12262v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1903.12262</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper provides a taxonomy for the licensing of data in the fields of
artificial intelligence and machine learning. The paper&apos;s goal is to build
towards a common framework for data licensing akin to the licensing of open
source software. Increased transparency and resolving conceptual ambiguities in
existing licensing language are two noted benefits of the approach proposed in
the paper. In parallel, such benefits may help foster fairer and more efficient
markets for data through bringing about clearer tools and concepts that better
define how data can be used in the fields of AI and ML. The paper&apos;s approach is
summarized in a new family of data license language - \textit{the Montreal Data
License (MDL)}. Alongside this new license, the authors and their collaborators
have developed a web-based tool to generate license language espousing the
taxonomies articulated in this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benjamin_M/0/1/0/all/0/1&quot;&gt;Misha Benjamin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagnon_P/0/1/0/all/0/1&quot;&gt;Paul Gagnon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rostamzadeh_N/0/1/0/all/0/1&quot;&gt;Negar Rostamzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1&quot;&gt;Chris Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shee_A/0/1/0/all/0/1&quot;&gt;Alex Shee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12264">
<title>Validation of a recommender system for prompting omitted foods in online dietary assessment surveys. (arXiv:1903.12264v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1903.12264</link>
<description rdf:parseType="Literal">&lt;p&gt;Recall assistance methods are among the key aspects that improve the accuracy
of online dietary assessment surveys. These methods still mainly rely on
experience of trained interviewers with nutritional background, but data driven
approaches could improve cost-efficiency and scalability of automated dietary
assessment. We evaluated the effectiveness of a recommender algorithm developed
for an online dietary assessment system called Intake24, that automates the
multiple-pass 24-hour recall method. The recommender builds a model of eating
behavior from recalls collected in past surveys. Based on foods they have
already selected, the model is used to remind respondents of associated foods
that they may have omitted to report. The performance of prompts generated by
the model was compared to that of prompts hand-coded by nutritionists in two
dietary studies. The results of our studies demonstrate that the recommender
system is able to capture a higher number of foods omitted by respondents of
online dietary surveys than prompts hand-coded by nutritionists. However, the
considerably lower precision of generated prompts indicates an opportunity for
further improvement of the system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osadchiy_T/0/1/0/all/0/1&quot;&gt;Timur Osadchiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poliakov_I/0/1/0/all/0/1&quot;&gt;Ivan Poliakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olivier_P/0/1/0/all/0/1&quot;&gt;Patrick Olivier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rowland_M/0/1/0/all/0/1&quot;&gt;Maisie Rowland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_E/0/1/0/all/0/1&quot;&gt;Emma Foster&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12266">
<title>Generative Adversarial Networks: recent developments. (arXiv:1903.12266v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12266</link>
<description rdf:parseType="Literal">&lt;p&gt;In traditional generative modeling, good data representation is very often a
base for a good machine learning model. It can be linked to good
representations encoding more explanatory factors that are hidden in the
original data. With the invention of Generative Adversarial Networks (GANs), a
subclass of generative models that are able to learn representations in an
unsupervised and semi-supervised fashion, we are now able to adversarially
learn good mappings from a simple prior distribution to a target data
distribution. This paper presents an overview of recent developments in GANs
with a focus on learning latent space representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamorski_M/0/1/0/all/0/1&quot;&gt;Maciej Zamorski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zdobylak_A/0/1/0/all/0/1&quot;&gt;Adrian Zdobylak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zieba_M/0/1/0/all/0/1&quot;&gt;Maciej Zi&amp;#x119;ba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swiatek_J/0/1/0/all/0/1&quot;&gt;Jerzy &amp;#x15a;wi&amp;#x105;tek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12269">
<title>Bit-Flip Attack: Crushing Neural Network withProgressive Bit Search. (arXiv:1903.12269v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12269</link>
<description rdf:parseType="Literal">&lt;p&gt;Several important security issues of Deep Neural Network (DNN) have been
raised recently associated with different applications and components. The most
widely investigated security concern of DNN is from its malicious input, a.k.a
adversarial example. Nevertheless, the security challenge of DNN&apos;s parameters
is not well explored yet. In this work, we are the first to propose a novel DNN
weight attack methodology called Bit-Flip Attack (BFA) which can crush a neural
network through maliciously flipping extremely small amount of bits within its
weight storage memory system (i.e., DRAM). The bit-flip operations could be
conducted through well-known Row-Hammer attack, while our main contribution is
to develop an algorithm to identify the most vulnerable bits of DNN weight
parameters (stored in memory as binary bits), that could maximize the accuracy
degradation with a minimum number of bit-flips. Our proposed BFA utilizes a
Progressive Bit Search (PBS) method which combines gradient ranking and
progressive search to identify the most vulnerable bit to be flipped. With the
aid of PBS, we can successfully attack a ResNet-18 fully malfunction (i.e.,
top-1 accuracy degrade from 69.8% to 0.1%) only through 13 bit-flips out of 93
million bits, while randomly flipping 100 bits merely degrades the accuracy by
less than 1%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rakin_A/0/1/0/all/0/1&quot;&gt;Adnan Siraj Rakin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhezhi He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1&quot;&gt;Deliang Fan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12270">
<title>Implementing Noise with Hash functions for Graphics Processing Units. (arXiv:1903.12270v1 [cs.GR])</title>
<link>http://arxiv.org/abs/1903.12270</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a modification to Perlin noise which use computable hash functions
instead of textures as lookup tables. We implemented the FNV1, Jenkins and
Murmur hashes on Shader Model 4.0 Graphics Processing Units for noise
generation. Modified versions of the FNV1 and Jenkins hashes provide very close
performance compared to a texture based Perlin noise implementation. Our noise
modification enables noise function evaluation without any texture fetches,
trading computational power for memory bandwidth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valdenegro_Toro_M/0/1/0/all/0/1&quot;&gt;Matias Valdenegro-Toro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pincheira_H/0/1/0/all/0/1&quot;&gt;Hector Pincheira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12271">
<title>In Search of Meaning: Lessons, Resources and Next Steps for Computational Analysis of Financial Discourse. (arXiv:1903.12271v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12271</link>
<description rdf:parseType="Literal">&lt;p&gt;We critically assess mainstream accounting and finance research applying
methods from computational linguistics (CL) to study financial discourse. We
also review common themes and innovations in the literature and assess the
incremental contributions of work applying CL methods over manual content
analysis. Key conclusions emerging from our analysis are: (a) accounting and
finance research is behind the curve in terms of CL methods generally and word
sense disambiguation in particular; (b) implementation issues mean the proposed
benefits of CL are often less pronounced than proponents suggest; (c)
structural issues limit practical relevance; and (d) CL methods and high
quality manual analysis represent complementary approaches to analyzing
financial discourse. We describe four CL tools that have yet to gain traction
in mainstream AF research but which we believe offer promising ways to enhance
the study of meaning in financial discourse. The four tools are named entity
recognition (NER), summarization, semantics and corpus linguistics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Haj_M/0/1/0/all/0/1&quot;&gt;Mahmoud El-Haj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rayson_P/0/1/0/all/0/1&quot;&gt;Paul Rayson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walker_M/0/1/0/all/0/1&quot;&gt;Martin Walker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Young_S/0/1/0/all/0/1&quot;&gt;Steven Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simaki_V/0/1/0/all/0/1&quot;&gt;Vasiliki Simaki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12272">
<title>Deep Convolutional Spiking Neural Networks for Image Classification. (arXiv:1903.12272v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1903.12272</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking neural networks are biologically plausible counterparts of the
artificial neural networks, artificial neural networks are usually trained with
stochastic gradient descent and spiking neural networks are trained with spike
timing dependant plasticity. Training deep convolutional neural networks is a
memory and power intensive job. Spiking networks could potentially help in
reducing the power usage. There is a large pool of tools for one to chose to
train artificial neural networks of any size, on the other hand all the
available tools to simulate spiking neural networks are geared towards
computational neuroscience applications and they are not suitable for real life
applications. In this work we focus on implementing a spiking CNN using
Tensorflow to examine behaviour of the network and empirically study the effect
of various parameters on learning capabilities and also study catastrophic
forgetting in the spiking CNN and weight initialization problem in R-STDP using
MNIST and N-MNIST data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaila_R/0/1/0/all/0/1&quot;&gt;Ruthvik Vaila&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiasson_J/0/1/0/all/0/1&quot;&gt;John Chiasson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_V/0/1/0/all/0/1&quot;&gt;Vishal Saxena&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12282">
<title>An Empirical Study of Obsolete Answers on Stack Overflow. (arXiv:1903.12282v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1903.12282</link>
<description rdf:parseType="Literal">&lt;p&gt;Stack Overflow accumulates an enormous amount of software engineering
knowledge. However, as time passes, certain knowledge in answers may become
obsolete. Such obsolete answers, if not identified or documented clearly, may
mislead answer seekers and cause unexpected problems (e.g., using an out-dated
security protocol). In this paper, we investigate how the knowledge in answers
becomes obsolete and identify the characteristics of such obsolete answers. We
find that: 1) More than half of the obsolete answers (58.4%) were probably
already obsolete when they were first posted. 2) When an obsolete answer is
observed, only a small proportion (20.5%) of such answers are ever updated. 3)
Answers to questions in certain tags (e.g., node.js, ajax, android, and
objective-c) are more likely to become obsolete. Our findings suggest that
Stack Overflow should develop mechanisms to encourage the whole community to
maintain answers (to avoid obsolete answers) and answer seekers are encouraged
to carefully go through all information (e.g., comments) in answer threads.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haoxiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shaowei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tse-Hsun/0/1/0/all/0/1&quot;&gt;Tse-Hsun&lt;/a&gt; (Peter) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen/0/1/0/all/0/1&quot;&gt;Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1&quot;&gt;Ying Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassan_A/0/1/0/all/0/1&quot;&gt;Ahmed E. Hassan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12286">
<title>Toroidal AutoEncoder. (arXiv:1903.12286v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1903.12286</link>
<description rdf:parseType="Literal">&lt;p&gt;Enforcing distributions of latent variables in neural networks is an active
subject. It is vital in all kinds of generative models, where we want to be
able to interpolate between points in the latent space, or sample from it.
Modern generative AutoEncoders (AE) like WAE, SWAE, CWAE add a regularizer to
the standard (deterministic) AE, which allows to enforce Gaussian distribution
in the latent space. Enforcing different distributions, especially
topologically nontrivial, might bring some new interesting possibilities, but
this subject seems unexplored so far.
&lt;/p&gt;
&lt;p&gt;This article proposes a new approach to enforce uniform distribution on
d-dimensional torus. We introduce a circular spring loss, which enforces
minibatch points to be equally spaced and satisfy cyclic boundary conditions.
&lt;/p&gt;
&lt;p&gt;As example of application we propose multiple-path morphing. Minimal distance
geodesic between two points in uniform distribution on latent space of angles
becomes a line, however, torus topology allows us to choose such lines in
alternative ways, going through different edges of $[-\pi,\pi]^d$.
&lt;/p&gt;
&lt;p&gt;Further applications to explore can be for example trying to learn real-life
topologically nontrivial spaces of features, like rotations to automatically
recognize 2D rotation of an object in picture by training on relative angles,
or even 3D rotations by additionally using spherical features - this way
morphing should be close to object rotation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mikulski_M/0/1/0/all/0/1&quot;&gt;Maciej Mikulski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duda_J/0/1/0/all/0/1&quot;&gt;Jaroslaw Duda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12287">
<title>PyTorch-BigGraph: A Large-scale Graph Embedding System. (arXiv:1903.12287v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12287</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph embedding methods produce unsupervised node features from graphs that
can then be used for a variety of machine learning tasks. Modern graphs,
particularly in industrial applications, contain billions of nodes and
trillions of edges, which exceeds the capability of existing embedding systems.
We present PyTorch-BigGraph (PBG), an embedding system that incorporates
several modifications to traditional multi-relation embedding systems that
allow it to scale to graphs with billions of nodes and trillions of edges. PBG
uses graph partitioning to train arbitrarily large embeddings on either a
single machine or in a distributed environment. We demonstrate comparable
performance with existing embedding systems on common benchmarks, while
allowing for scaling to arbitrarily large graphs and parallelization on
multiple machines. We train and evaluate embeddings on several large social
network graphs as well as the full Freebase dataset, which contains over 100
million nodes and 2 billion edges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1&quot;&gt;Adam Lerer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Ledell Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Jiajun Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacroix_T/0/1/0/all/0/1&quot;&gt;Timothee Lacroix&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wehrstedt_L/0/1/0/all/0/1&quot;&gt;Luca Wehrstedt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1&quot;&gt;Abhijit Bose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1&quot;&gt;Alex Peysakhovich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12289">
<title>Above the Nyquist Rate, Modulo Folding Does Not Hurt. (arXiv:1903.12289v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1903.12289</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of recovering a continuous-time bandlimited signal
from the discrete-time signal obtained from sampling it every $T_s$ seconds and
reducing the result modulo $\Delta$, for some $\Delta&amp;gt;0$. For $\Delta=\infty$
the celebrated Shannon-Nyquist sampling theorem guarantees that perfect
recovery is possible provided that the sampling rate $1/T_s$ exceeds the
so-called Nyquist rate. Recent work by Bhandari et al. has shown that for any
$\Delta&amp;gt;0$ perfect reconstruction is still possible if the sampling rate
exceeds the Nyquist rate by a factor of $\pi e$. In this letter we improve upon
this result and show that for finite energy signals, perfect recovery is
possible for any $\Delta&amp;gt;0$ and any sampling rate above the Nyquist rate. Thus,
modulo folding does not degrade the signal, provided that the sampling rate
exceeds the Nyquist rate. This claim is proved by establishing a connection
between the recovery problem of a discrete-time signal from its modulo reduced
version and the problem of predicting the next sample of a discrete-time signal
from its past, and leveraging the fact that for a bandlimited signal the
prediction error can be made arbitrarily small.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romanov_E/0/1/0/all/0/1&quot;&gt;Elad Romanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ordentlich_O/0/1/0/all/0/1&quot;&gt;Or Ordentlich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12290">
<title>Revisiting Local Descriptor based Image-to-Class Measure for Few-shot Learning. (arXiv:1903.12290v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12290</link>
<description rdf:parseType="Literal">&lt;p&gt;Few-shot learning in image classification aims to learn a classifier to
classify images when only few training examples are available for each class.
Recent work has achieved promising classification performance, where an
image-level feature based measure is usually used. In this paper, we argue that
a measure at such a level may not be effective enough in light of the scarcity
of examples in few-shot learning. Instead, we think a local descriptor based
image-to-class measure should be taken, inspired by its surprising success in
the heydays of local invariant features. Specifically, building upon the recent
episodic training mechanism, we propose a Deep Nearest Neighbor Neural Network
(DN4 in short) and train it in an end-to-end manner. Its key difference from
the literature is the replacement of the image-level feature based measure in
the final layer by a local descriptor based image-to-class measure. This
measure is conducted online via a $k$-nearest neighbor search over the deep
local descriptors of convolutional feature maps. The proposed DN4 not only
learns the optimal deep local descriptors for the image-to-class measure, but
also utilizes the higher efficiency of such a measure in the case of example
scarcity, thanks to the exchangeability of visual patterns across the images in
the same class. Our work leads to a simple, effective, and computationally
efficient framework for few-shot learning. Experimental study on benchmark
datasets consistently shows its superiority over the related state-of-the-art,
with the largest absolute improvement of $17\%$ over the next best. The source
code can be available from \UrlFont{https://github.com/WenbinLee/DN4.git}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenbin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jinglin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huo_J/0/1/0/all/0/1&quot;&gt;Jing Huo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1&quot;&gt;Jiebo Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12294">
<title>Multifaceted 4D Feature Segmentation and Extraction in Point and Field-based Datasets. (arXiv:1903.12294v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12294</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of large-scale multifaceted data is common in a wide variety of
scientific applications. In many cases, this multifaceted data takes the form
of a field-based (Eulerian) and point/trajectory-based (Lagrangian)
representation as each has a unique set of advantages in characterizing a
system of study. Furthermore, studying the increasing scale and complexity of
these multifaceted datasets is limited by perceptual ability and available
computational resources, necessitating sophisticated data reduction and feature
extraction techniques. In this work, we present a new 4D feature
segmentation/extraction scheme that can operate on both the field and
point/trajectory data types simultaneously. The resulting features are
time-varying data subsets that have both a field and point-based component, and
were extracted based on underlying patterns from both data types. This enables
researchers to better explore both the spatial and temporal interplay between
the two data representations and study underlying phenomena from new
perspectives. We parallelize our approach using GPU acceleration and apply it
to real world multifaceted datasets to illustrate the types of features that
can be extracted and explored.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sauer_F/0/1/0/all/0/1&quot;&gt;Franz Sauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1&quot;&gt;Kwan-Liu Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12296">
<title>Attention-Guided Generative Adversarial Networks for Unsupervised Image-to-Image Translation. (arXiv:1903.12296v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12296</link>
<description rdf:parseType="Literal">&lt;p&gt;The state-of-the-art approaches in Generative Adversarial Networks (GANs) are
able to learn a mapping function from one image domain to another with unpaired
image data. However, these methods often produce artifacts and can only be able
to convert low-level information, but fail to transfer high-level semantic part
of images. The reason is mainly that generators do not have the ability to
detect the most discriminative semantic part of images, which thus makes the
generated images with low-quality. To handle the limitation, in this paper we
propose a novel Attention-Guided Generative Adversarial Network (AGGAN), which
can detect the most discriminative semantic object and minimize changes of
unwanted part for semantic manipulation problems without using extra data and
models. The attention-guided generators in AGGAN are able to produce attention
masks via a built-in attention mechanism, and then fuse the input image with
the attention mask to obtain a target image with high-quality. Moreover, we
propose a novel attention-guided discriminator which only considers attended
regions. The proposed AGGAN is trained by an end-to-end fashion with an
adversarial loss, cycle-consistency loss, pixel loss and attention loss. Both
qualitative and quantitative results demonstrate that our approach is effective
to generate sharper and more accurate images than existing models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hao Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Dan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1&quot;&gt;Nicu Sebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1&quot;&gt;Yan Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12297">
<title>An analysis of the cost of hyper-parameter selection via split-sample validation, with applications to penalized regression. (arXiv:1903.12297v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1903.12297</link>
<description rdf:parseType="Literal">&lt;p&gt;In the regression setting, given a set of hyper-parameters, a
model-estimation procedure constructs a model from training data. The optimal
hyper-parameters that minimize generalization error of the model are usually
unknown. In practice they are often estimated using split-sample validation. Up
to now, there is an open question regarding how the generalization error of the
selected model grows with the number of hyper-parameters to be estimated. To
answer this question, we establish finite-sample oracle inequalities for
selection based on a single training/test split and based on cross-validation.
We show that if the model-estimation procedures are smoothly parameterized by
the hyper-parameters, the error incurred from tuning hyper-parameters shrinks
at nearly a parametric rate. Hence for semi- and non-parametric
model-estimation procedures with a fixed number of hyper-parameters, this
additional error is negligible. For parametric model-estimation procedures,
adding a hyper-parameter is roughly equivalent to adding a parameter to the
model itself. In addition, we specialize these ideas for penalized regression
problems with multiple penalty parameters. We establish that the fitted models
are Lipschitz in the penalty parameters and thus our oracle inequalities apply.
This result encourages development of regularization methods with many penalty
parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jean Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simon_N/0/1/0/all/0/1&quot;&gt;Noah Simon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12301">
<title>Dronecrypt - An Efficient Cryptographic Framework for Small Aerial Drones. (arXiv:1903.12301v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1903.12301</link>
<description rdf:parseType="Literal">&lt;p&gt;Aerial drones are becoming an integral part of application domains including
but not limited to, military operations, package delivery, construction,
monitoring and search/rescue operations. It is critical to ensure the cyber
security of networked aerial drone systems in these applications. Standard
cryptographic services can be deployed to provide basic security services;
however, they have been shown to be inefficient in terms of energy and time
consumption, especially for small aerial drones with resource-limited
processors. Therefore, there is a significant need for an efficient
cryptographic framework that can meet the requirements of small aerial drones.
&lt;/p&gt;
&lt;p&gt;We propose an improved cryptographic framework for small aerial drones, which
offers significant energy efficiency and speed advantages over standard
cryptographic techniques. (i) We create (to the best of our knowledge) the
first optimized public key infrastructure (PKI) based framework for small
aerial drones, which provides energy efficient techniques by harnessing special
precomputation methods and optimized elliptic curves. (ii) We also integrate
recent light-weight symmetric primitives into our PKI techniques to provide a
full-fledged cryptographic framework. (iii) We implemented standard
counterparts and our proposed techniques on an actual small aerial drone
(Crazyflie 2.0), and provided an in-depth energy analysis. Our experiments
showed that our improved cryptographic framework achieves up to 35x lower
energy consumption than its standard counterpart.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozmen_M/0/1/0/all/0/1&quot;&gt;Muslum Ozgur Ozmen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yavuz_A/0/1/0/all/0/1&quot;&gt;Attila A. Yavuz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12302">
<title>Amortized Object and Scene Perception for Long-term Robot Manipulation. (arXiv:1903.12302v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1903.12302</link>
<description rdf:parseType="Literal">&lt;p&gt;Mobile robots, performing long-term manipulation activities in human
environments, have to perceive a wide variety of objects possessing very
different visual characteristics and need to reliably keep track of these
throughout the execution of a task. In order to be efficient, robot perception
capabilities need to go beyond what is currently perceivable and should be able
to answer queries about both current and past scenes. In this paper we
investigate a perception system for long-term robot manipulation that keeps
track of the changing environment and builds a representation of the perceived
world. Specifically we introduce an amortized component that spreads perception
tasks throughout the execution cycle. The resulting query driven perception
system asynchronously integrates results from logged images into a symbolic and
numeric (what we call sub-symbolic) representation that forms the perceptual
belief state of the robot.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balint_Benczedi_F/0/1/0/all/0/1&quot;&gt;Ferenc Balint-Benczedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beetz_M/0/1/0/all/0/1&quot;&gt;Michael Beetz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12303">
<title>Nonlinear Moment Matching for the Simulation-Free Reduction of Structural Systems. (arXiv:1903.12303v1 [cs.CE])</title>
<link>http://arxiv.org/abs/1903.12303</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper transfers the concept of moment matching to nonlinear structural
systems and further provides a simulation-free reduction scheme for such
nonlinear second-order models. After first presenting the steady-state
interpretation of linear moment matching, we then extend this reduction concept
to the nonlinear second-order case based on Astolfi [2010]. Then, similar
simplifications as in Cruz Varona et al. [2019] are proposed to achieve a
simulation-free nonlinear moment matching algorithm. A discussion on the
simplifications and their limitations is presented, as well as a numerical
example which illustrates the efficiency of the algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varona_M/0/1/0/all/0/1&quot;&gt;Maria Cruz Varona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneucker_N/0/1/0/all/0/1&quot;&gt;Nico Schneucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lohmann_B/0/1/0/all/0/1&quot;&gt;Boris Lohmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12305">
<title>FrameNet: Learning Local Canonical Frames of 3D Surfaces from a Single RGB Image. (arXiv:1903.12305v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12305</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we introduce the novel problem of identifying dense canonical
3D coordinate frames from a single RGB image. We observe that each pixel in an
image corresponds to a surface in the underlying 3D geometry, where a canonical
frame can be identified as represented by three orthogonal axes, one along its
normal direction and two in its tangent plane. We propose an algorithm to
predict these axes from RGB. Our first insight is that canonical frames
computed automatically with recently introduced direction field synthesis
methods can provide training data for the task. Our second insight is that
networks designed for surface normal prediction provide better results when
trained jointly to predict canonical frames, and even better when trained to
also predict 2D projections of canonical frames. We conjecture this is because
projections of canonical tangent directions often align with local gradients in
images, and because those directions are tightly linked to 3D canonical frames
through projective geometry and orthogonality constraints. In our experiments,
we find that our method predicts 3D canonical frames that can be used in
applications ranging from surface normal estimation, feature matching, and
augmented reality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jingwei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yichao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Funkhouser_T/0/1/0/all/0/1&quot;&gt;Thomas Funkhouser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1&quot;&gt;Leonidas Guibas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12306">
<title>Acoustically Grounded Word Embeddings for Improved Acoustics-to-Word Speech Recognition. (arXiv:1903.12306v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12306</link>
<description rdf:parseType="Literal">&lt;p&gt;Direct acoustics-to-word (A2W) systems for end-to-end automatic speech
recognition are simpler to train, and more efficient to decode with, than
sub-word systems. However, A2W systems can have difficulties at training time
when data is limited, and at decoding time when recognizing words outside the
training vocabulary. To address these shortcomings, we investigate the use of
recently proposed acoustic and acoustically grounded word embedding techniques
in A2W systems. The idea is based on treating the final pre-softmax weight
matrix of an AWE recognizer as a matrix of word embedding vectors, and using an
externally trained set of word embeddings to improve the quality of this
matrix. In particular we introduce two ideas: (1) Enforcing similarity at
training time between the external embeddings and the recognizer weights, and
(2) using the word embeddings at test time for predicting out-of-vocabulary
words. Our word embedding model is acoustically grounded, that is it is learned
jointly with acoustic embeddings so as to encode the words&apos; acoustic-phonetic
content; and it is parametric, so that it can embed any arbitrary (potentially
out-of-vocabulary) sequence of characters. We find that both techniques improve
the performance of an A2W recognizer on conversational telephone speech.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Settle_S/0/1/0/all/0/1&quot;&gt;Shane Settle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Audhkhasi_K/0/1/0/all/0/1&quot;&gt;Kartik Audhkhasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livescu_K/0/1/0/all/0/1&quot;&gt;Karen Livescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1&quot;&gt;Michael Picheny&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12307">
<title>Expanding across time to deliver bandwidth efficiency and low latency. (arXiv:1903.12307v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1903.12307</link>
<description rdf:parseType="Literal">&lt;p&gt;Datacenters need networks that support both low-latency and high-bandwidth
packet delivery to meet the stringent requirements of modern applications. We
present Opera, a dynamic network that delivers latency-sensitive traffic
quickly by relying on multi-hop forwarding in the same way as
expander-graph-based approaches, but provides near-optimal bandwidth for bulk
flows through direct forwarding over time-varying source-to-destination
circuits. The key to Opera&apos;s design is the rapid and deterministic
reconfiguration of the network, piece-by-piece, such that at any moment in time
the network implements an expander graph, yet, integrated across time, the
network provides bandwidth-efficient single-hop paths between all racks. We
show that Opera supports low-latency traffic with flow completion times
comparable to cost-equivalent static topologies, while delivering up to 4x the
bandwidth for all-to-all traffic and supporting 60% higher load for published
datacenter workloads.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mellette_W/0/1/0/all/0/1&quot;&gt;William M. Mellette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1&quot;&gt;Rajdeep Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yibo Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGuinness_R/0/1/0/all/0/1&quot;&gt;Rob McGuinness&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snoeren_A/0/1/0/all/0/1&quot;&gt;Alex C. Snoeren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porter_G/0/1/0/all/0/1&quot;&gt;George Porter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12311">
<title>Mesh-based Tools to Analyze Deep Reinforcement Learning Policies for Underactuated Biped Locomotion. (arXiv:1903.12311v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1903.12311</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a mesh-based approach to analyze stability and
robustness of the policies obtained via deep reinforcement learning for various
biped gaits of a five-link planar model. Intuitively, one would expect that
including perturbations and/or other types of noise during training would
likely result in more robustness of the resulting control policy. However, one
would like to have a quantitative and computationally-efficient means of
evaluating the degree to which this might be so. Rather than relying on Monte
Carlo simulations, our goal is to provide more sophisticated tools to assess
robustness properties of such policies. Our work is motivated by the twin
hypotheses that contraction of dynamics, when achievable, can simplify control
and that control policies obtained via deep learning may therefore exhibit
tendency to contract to lower-dimensional manifolds within the full state
space, as a result. The tractability of our mesh-based tools in this work
provides some evidence that this may be so.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talele_N/0/1/0/all/0/1&quot;&gt;Nihar Talele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Byl_K/0/1/0/all/0/1&quot;&gt;Katie Byl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12312">
<title>Data structures to represent sets of k-long DNA sequences. (arXiv:1903.12312v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1903.12312</link>
<description rdf:parseType="Literal">&lt;p&gt;The analysis of biological sequencing data has been one of the biggest
applications of string algorithms. The approaches used in many such
applications are based on the analysis of k-mers, which are short fixed-length
strings present in a dataset. While these approaches are rather diverse,
storing and querying k-mer sets has emerged as a shared underlying component.
Sets of k-mers have unique features and applications that, over the last ten
years, have resulted in many specialized approaches for their representation.
In this survey, we give a unified presentation and comparison of the data
structures that have been proposed to store and query k-mer sets. We hope this
survey will not only serve as a resource for researchers in the field but also
make the area more accessible to outsiders
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chikhi_R/0/1/0/all/0/1&quot;&gt;Rayan Chikhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holub_J/0/1/0/all/0/1&quot;&gt;Jan Holub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medvedev_P/0/1/0/all/0/1&quot;&gt;Paul Medvedev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12314">
<title>Relation-aware Graph Attention Network for Visual Question Answering. (arXiv:1903.12314v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12314</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to answer semantically-complicated questions about an image, a
Visual Question Answering (VQA) model needs to fully understand the visual
scene in the image, especially the interactive dynamics between different
objects. We propose a Relation-aware Graph Attention Network (ReGAT), which
encodes each image into a graph and models multi-type inter-object relations
via a graph attention mechanism, to learn question-adaptive relation
representations. Two types of visual object relations are explored: (i)
Explicit Relations that represent geometric positions and semantic interactions
between objects; and (ii) Implicit Relations that capture the hidden dynamics
between image regions. Experiments demonstrate that ReGAT outperforms prior
state-of-the-art approaches on both VQA 2.0 and VQA-CP v2 datasets. We further
show that ReGAT is compatible to existing VQA architectures, and can be used as
a generic relation encoder to boost the model performance for VQA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Linjie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1&quot;&gt;Zhe Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yu Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingjing Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12316">
<title>Does the Lombard Effect Improve Emotional Communication in Noise? - Analysis of Emotional Speech Acted in Noise -. (arXiv:1903.12316v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1903.12316</link>
<description rdf:parseType="Literal">&lt;p&gt;Speakers usually adjust their way of talking in noisy environments
involuntarily for effective communication. This adaptation is known as the
Lombard effect. Although speech accompanying the Lombard effect can improve the
intelligibility of a speaker&apos;s voice, the changes in acoustic features (e.g.
fundamental frequency, speech intensity, and spectral tilt) caused by the
Lombard effect may also affect the listener&apos;s judgment of emotional content. To
the best of our knowledge, there is no published study on the influence of the
Lombard effect in emotional speech. Therefore, we recorded parallel emotional
speech waveforms uttered by 12 speakers under both quiet and noisy conditions
in a professional recording studio in order to explore how the Lombard effect
interacts with emotional speech. By analyzing confusion matrices and acoustic
features, we aim to answer the following questions: 1) Can speakers express
their emotions correctly even under adverse conditions? 2) Can listeners
recognize the emotion contained in speech signals even under noise? 3) How does
emotional speech uttered in noise differ from emotional speech uttered in quiet
conditions in terms of acoustic characteristic?
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yi Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ando_A/0/1/0/all/0/1&quot;&gt;Atsushi Ando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Takaki_S/0/1/0/all/0/1&quot;&gt;Shinji Takaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yamagishi_J/0/1/0/all/0/1&quot;&gt;Junichi Yamagishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kobashikawa_S/0/1/0/all/0/1&quot;&gt;Satoshi Kobashikawa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12318">
<title>User Preference Aware Lossless Data Compression at the Edge. (arXiv:1903.12318v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1903.12318</link>
<description rdf:parseType="Literal">&lt;p&gt;Data compression is an efficient technique to save data storage and
transmission costs. However, traditional data compression methods always ignore
the impact of user preferences on the statistical distributions of symbols
transmitted over the links. Notice that the development of big data
technologies and popularization of smart devices enable analyses on user
preferences based on data collected from personal handsets. This paper presents
a user preference aware lossless data compression method, termed edge source
coding, to compress data at the network edge. An optimization problem is
formulated to minimize the expected number of bits needed to represent a
requested content item in edge source coding. For edge source coding under
discrete user preferences, DCA (difference of convex functions programming
algorithm) based and k-means++ based algorithms are proposed to give codebook
designs. For edge source coding under continuous user preferences, a sampling
method is applied to give codebook designs. In addition, edge source coding is
extended to the two-user case and codebooks are elaborately designed to utilize
multicasting opportunities. Both theoretical analysis and simulations
demonstrate the optimal codebook design should take into account user
preferences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yawei Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1&quot;&gt;H. Vincent Poor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12322">
<title>Implicit Langevin Algorithms for Sampling From Log-concave Densities. (arXiv:1903.12322v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1903.12322</link>
<description rdf:parseType="Literal">&lt;p&gt;For sampling from a log-concave density, we study implicit integrators
resulting from $\theta$-method discretization of the overdamped Langevin
diffusion stochastic differential equation. Theoretical and algorithmic
properties of the resulting sampling methods for $ \theta \in [0,1] $ and a
range of step sizes are established. Our results generalize and extend prior
works in several directions. In particular, for $\theta\ge1/2$, we prove
geometric ergodicity and stability of the resulting methods for all step sizes.
We show that obtaining subsequent samples amounts to solving a strongly-convex
optimization problem, which is readily achievable using one of numerous
existing methods. Numerical examples supporting our theoretical analysis are
also presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hodgkinson_L/0/1/0/all/0/1&quot;&gt;Liam Hodgkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Salomone_R/0/1/0/all/0/1&quot;&gt;Robert Salomone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roosta_F/0/1/0/all/0/1&quot;&gt;Fred Roosta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12325">
<title>Entropy flow and De Bruijn&apos;s identity for a class of stochastic differential equations driven by fractional Brownian motion. (arXiv:1903.12325v1 [math.PR])</title>
<link>http://arxiv.org/abs/1903.12325</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the classical De Bruijn&apos;s identity for the additive Gaussian
noise channel, in this paper we consider a generalized setting where the
channel is modelled via stochastic differential equations driven by fractional
Brownian motion with Hurst parameter $H\in(1/4,1)$. We derive generalized De
Bruijn&apos;s identity for Shannon entropy and Kullback-Leibler divergence by means
of It\^o&apos;s formula, and present two applications where we relax the assumption
to $H \in (0,1)$. In the first application we demonstrate its equivalence with
Stein&apos;s identity for Gaussian distributions, while in the second application,
we show that for $H \in (0,1/2]$, the entropy power is concave in time while
for $H \in (1/2,1)$ it is convex in time when the initial distribution is
Gaussian. Compared with the classical case of $H = 1/2$, the time parameter
plays an interesting and significant role in the analysis of these quantities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Choi_M/0/1/0/all/0/1&quot;&gt;Michael C.H. Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chihoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jian Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12328">
<title>Improved Reinforcement Learning with Curriculum. (arXiv:1903.12328v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12328</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans tend to learn complex abstract concepts faster if examples are
presented in a structured manner. For instance, when learning how to play a
board game, usually one of the first concepts learned is how the game ends,
i.e. the actions that lead to a terminal state (win, lose or draw). The
advantage of learning end-games first is that once the actions which lead to a
terminal state are understood, it becomes possible to incrementally learn the
consequences of actions that are further away from a terminal state - we call
this an end-game-first curriculum. Currently the state-of-the-art machine
learning player for general board games, AlphaZero by Google DeepMind, does not
employ a structured training curriculum; instead learning from the entire game
at all times. By employing an end-game-first training curriculum to train an
AlphaZero inspired player, we empirically show that the rate of learning of an
artificial player can be improved during the early stages of training when
compared to a player not using a training curriculum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+West_J/0/1/0/all/0/1&quot;&gt;Joseph West&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maire_F/0/1/0/all/0/1&quot;&gt;Frederic Maire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Browne_C/0/1/0/all/0/1&quot;&gt;Cameron Browne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1&quot;&gt;Simon Denman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12329">
<title>Averager-copier-voter models for hybrid opinion dynamics in complex networks. (arXiv:1903.12329v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1903.12329</link>
<description rdf:parseType="Literal">&lt;p&gt;A hybrid model for opinion dynamics in complex multi-agent networks is
introduced, wherein some continuous-valued agents average neighbors&apos; opinions
to update their own, while other discrete-valued agents use stochastic copying
and voting protocols. A statistical and graph-theoretic analysis of the model
is undertaken, and consensus is shown to be achieved whenever the network
matrix is ergodic. Also, the time required for consensus is characterized, in
terms of the network&apos;s graph and the distribution of agents of different types.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1&quot;&gt;Mengran Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sandip Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12330">
<title>Neuromorphic In-Memory Computing Framework using Memtransistor Cross-bar based Support Vector Machines. (arXiv:1903.12330v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1903.12330</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel framework for designing support vector machines
(SVMs), which does not impose restriction on the SVM kernel to be
positive-definite and allows the user to define memory constraint in terms of
fixed template vectors. This makes the framework scalable and enables its
implementation for low-power, high-density and memory constrained embedded
application. An efficient hardware implementation of the same is also
discussed, which utilizes novel low power memtransistor based cross-bar
architecture, and is robust to device mismatch and randomness. We used
memtransistor measurement data, and showed that the designed SVMs can achieve
state-of-the-art classification accuracy on both synthetic and real-world
benchmark datasets. This framework would be beneficial for design of SVM based
wake-up systems for internet of things (IoTs) and edge devices where
memtransistors can be used to optimize system&apos;s energy-efficiency and perform
in-memory matrix-vector multiplication (MVM).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1&quot;&gt;P. Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1&quot;&gt;A. R. Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_O/0/1/0/all/0/1&quot;&gt;O. Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paul_T/0/1/0/all/0/1&quot;&gt;T. Paul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1&quot;&gt;A. Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakrabartty_S/0/1/0/all/0/1&quot;&gt;S. Chakrabartty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakur_C/0/1/0/all/0/1&quot;&gt;C. S. Thakur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12331">
<title>A Deep Dive into Understanding Tumor Foci Classification using Multiparametric MRI Based on Convolutional Neural Network. (arXiv:1903.12331v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12331</link>
<description rdf:parseType="Literal">&lt;p&gt;Data scarcity has refrained deep learning models from making greater progress
in prostate images analysis using multiparametric MRI. In this paper, an
efficient convolutional neural network (CNN) was developed to classify lesion
malignancy for prostate cancer patients, based on which model interpretation
was systematically analyzed to bridge the gap between natural images and MR
images, which is the first one of its kind in the literature. The problem of
small sample size was addressed and successfully tackled by feeding the
intermediate features into a traditional classification algorithm known as
weighted extreme learning machine, with imbalanced distribution among output
categories taken into consideration. Model trained on public data set was able
to generalize to data from an independent institution to make accurate
prediction. The generated saliency map was found to overlay well with the
lesion and could benefit clinicians for diagnosing purpose.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zong_W/0/1/0/all/0/1&quot;&gt;Weiwei Zong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carver_E/0/1/0/all/0/1&quot;&gt;Eric Carver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldman_A/0/1/0/all/0/1&quot;&gt;Aharon Feldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janic_B/0/1/0/all/0/1&quot;&gt;Branislava Janic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elshaikh_M/0/1/0/all/0/1&quot;&gt;Mohamed Elshaikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pantellic_M/0/1/0/all/0/1&quot;&gt;Milan Pantellic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hearshen_D/0/1/0/all/0/1&quot;&gt;David Hearshen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chetty_I/0/1/0/all/0/1&quot;&gt;Indrin Chetty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Movsas_B/0/1/0/all/0/1&quot;&gt;Benjamin Movsas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_N/0/1/0/all/0/1&quot;&gt;Ning Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12337">
<title>ESFNet: Efficient Network for Building Extraction from High-Resolution Aerial Images. (arXiv:1903.12337v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12337</link>
<description rdf:parseType="Literal">&lt;p&gt;Building footprint extraction from high-resolution aerial images is always an
essential part of urban dynamic monitoring, planning and management. It has
also been a challenging task in remote sensing research, due to complex
environments and land cover objects in the high-resolution aerial images. In
recent years, deep neural networks have made great achievement in improving
accuracy of building extraction from remote sensing imagery. However, most of
existing approaches usually requiring a large number of parameters and floating
point operations for high accuracy, it leads to high memory consumption and low
inference speed which are harmful to research. In this paper, we proposed a
novel deep architecture named ESFNet which employs separable factorized
residual block and utilizes the dilated convolutions, aiming to preserve slight
accuracy loss with low computational cost and memory consumption. This is the
first time introducing efficiency view of deep neural networks in remote
sensing area. Our ESFNet is able to run at over 100 FPS on single Tesla V100,
requires 6x less FLOPs and has 18x less parameters than state-of-the-art
real-time architecture ERFNet while preserving similar accuracy without any
additional context module, post-processing and pre-trained scheme. We evaluated
our networks on WHU Building Dataset and compared it with other
state-of-the-art architectures. The result and comprehensive analysis show that
our networks are benefit to efficient remote sensing researches and
applications, and can further extended to other areas. The code is public
available at: https://github.com/mrluin/ESFNet-Pytorch
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jingbo Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1&quot;&gt;Houbing Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jing_W/0/1/0/all/0/1&quot;&gt;Weipeng Jing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12340">
<title>A Machine Learning Framework for Biometric Authentication using Electrocardiogram. (arXiv:1903.12340v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1903.12340</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a framework for how to appropriately adopt and adjust
Machine Learning (ML) techniques used to construct Electrocardiogram (ECG)
based biometric authentication schemes. The proposed framework can help
investigators and developers on ECG based biometric authentication mechanisms
define the boundaries of required datasets and get training data with good
quality. To determine the boundaries of datasets, use case analysis is adopted.
Based on various application scenarios on ECG based authentication, three
distinct use cases (or authentication categories) are developed. With more
qualified training data given to corresponding machine learning schemes, the
precision on ML-based ECG biometric authentication mechanisms is increased in
consequence. ECG time slicing technique with the R-peak anchoring is utilized
in this framework to acquire ML training data with good quality. In the
proposed framework four new measure metrics are introduced to evaluate the
quality of ML training and testing data. In addition, a Matlab toolbox,
containing all proposed mechanisms, metrics and sample data with demonstrations
using various ML techniques, is developed and publicly available for further
investigation. For developing ML-based ECG biometric authentication, the
proposed framework can guide researchers to prepare the proper ML setups and
the ML training datasets along with three identified user case scenarios. For
researchers adopting ML techniques to design new schemes in other research
domains, the proposed framework is still useful for generating ML-based
training and testing datasets with good quality and utilizing new measure
metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Song-Kyoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeun_C/0/1/0/all/0/1&quot;&gt;Chan Yeob Yeun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damiani_E/0/1/0/all/0/1&quot;&gt;Ernesto Damiani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lo_N/0/1/0/all/0/1&quot;&gt;Nai-Wei Lo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12344">
<title>Learning Good Representation via Continuous Attention. (arXiv:1903.12344v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12344</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we present our scientific discovery that good representation
can be learned via continuous attention during the interaction between
Unsupervised Learning(UL) and Reinforcement Learning(RL) modules driven by
intrinsic motivation. Specifically, we designed intrinsic rewards generated
from UL modules for driving the RL agent to focus on objects for a period of
time and to learn good representations of objects for later object recognition
task. We evaluate our proposed algorithm in both with and without extrinsic
reward settings. Experiments with end-to-end training in simulated environments
with applications to few-shot object recognition demonstrated the effectiveness
of the proposed algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Wei Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12347">
<title>The Challenge of Predicting Meal-to-meal Blood Glucose Concentrations for Patients with Type I Diabetes. (arXiv:1903.12347v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12347</link>
<description rdf:parseType="Literal">&lt;p&gt;Patients with Type I Diabetes (T1D) must take insulin injections to prevent
the serious long term effects of hyperglycemia - high blood glucose (BG).
Patients must also be careful not to inject too much insulin because this could
induce hypoglycemia (low BG), which can potentially be fatal. Patients
therefore follow a &quot;regimen&quot; that determines how much insulin to inject at
certain times. Current methods for managing this disease require adjusting the
patient&apos;s regimen over time based on the disease&apos;s behavior (recorded in the
patient&apos;s diabetes diary). If we can accurately predict a patient&apos;s future BG
values from his/her current features (e.g., predicting today&apos;s lunch BG value
given today&apos;s diabetes diary entry for breakfast, including insulin injections,
and perhaps earlier entries), then it is relatively easy to produce an
effective regimen. This study explores the challenges of BG modeling by
applying several machine learning algorithms and various data preprocessing
variations (corresponding to 312 [learner, preprocessed-dataset] combinations),
to a new T1D dataset containing 29 601 entries from 47 different patients. Our
most accurate predictor is a weighted ensemble of two Gaussian Process
Regression models, which achieved an errL1 loss of 2.70 mmol/L (48.65 mg/dl).
This was an unexpectedly poor result given that one can obtain an errL1 of 2.91
mmol/L (52.43 mg/dl) using the naive approach of simply predicting the
patient&apos;s average BG. For each of data-variant/model combination we report
several evaluation metrics, including glucose-specific metrics, and find
similarly disappointing results (the best model was only incrementally better
than the simplest measure). These results suggest that the diabetes diary data
that is typically collected may not be sufficient to produce accurate BG
prediction models; additional data may be necessary to build accurate BG
prediction models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borle_N/0/1/0/all/0/1&quot;&gt;Neil C. Borle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryan_E/0/1/0/all/0/1&quot;&gt;Edmond A. Ryan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greiner_R/0/1/0/all/0/1&quot;&gt;Russell Greiner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12348">
<title>Reinforcement Learning for Traffic Control with Adaptive Horizon. (arXiv:1903.12348v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1903.12348</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a reinforcement learning approach for traffic control
with the adaptive horizon. To build the controller for the traffic network, a
Q-learning-based strategy that controls the green light passing time at the
network intersections is applied. The controller includes two components: the
regular Q-learning controller that controls the traffic light signal, and the
adaptive controller that continuously optimizes the action space for the
Q-learning algorithm in order to improve the efficiency of the Q-learning
algorithm. The regular Q-learning controller uses the control cost function as
a reward function to determine the action to choose. The adaptive controller
examines the control cost and updates the action space of the controller by
determining the subset of actions that are most likely to obtain optimal
results and shrinking the action space to that subset. Uncertainties in traffic
influx and turning rate are introduced to test the robustness of the controller
under a stochastic environment. Compared with those with model predictive
control (MPC), the results show that the proposed Q-learning-based controller
outperforms the MPC method by reaching a stable solution in a shorter period
and achieves lower control costs. The proposed Q-learning-based controller is
also robust under 30% traffic demand uncertainty and 15% turning rate
uncertainty.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wentao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tehuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1&quot;&gt;Guang Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12349">
<title>A User-centered Design Study in Scientific Visualization Targeting Domain Experts. (arXiv:1903.12349v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1903.12349</link>
<description rdf:parseType="Literal">&lt;p&gt;The development and design of visualization solutions that are truly usable
is essential for ensuring both their adoption and effectiveness. User-centered
design principles, which focus on involving users throughout the entire
development process, are well suited for visualization and have been shown to
be effective in numerous information visualization endeavors. In this paper, we
report a two year long collaboration with combustion scientists that, by
applying these design principles, generated multiple results including an in
situ visualization technique and a post hoc probability distribution function
(PDF) exploration tool. Furthermore, we examine the importance of user-centered
design principles and describe lessons learned over the design process in an
effort to aid others who also seek to work with scientists for developing
effective and usable scientific visualization solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yucong/0/1/0/all/0/1&quot;&gt;Yucong&lt;/a&gt; (Chris)Ye, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sauer_F/0/1/0/all/0/1&quot;&gt;Franz Sauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1&quot;&gt;Kwan-Liu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aditya_K/0/1/0/all/0/1&quot;&gt;Konduri Aditya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jacqueline Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12351">
<title>Lending Orientation to Neural Networks for Cross-view Geo-localization. (arXiv:1903.12351v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12351</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies image-based geo-localization (IBL) problem using
ground-to-aerial cross-view matching. The goal is to predict the spatial
location of a ground-level query image by matching it to a large geotagged
aerial image database (e.g., satellite imagery). This is a challenging task due
to the drastic differences in their viewpoints and visual appearances. Existing
deep learning methods for this problem have been focused on maximizing feature
similarity between spatially close-by image pairs, while minimizing other
images pairs which are far apart. They do so by deep feature embedding based on
visual appearance in those ground-and-aerial images. However, in everyday life,
humans commonly use {\em orientation} information as an important cue for the
task of spatial localization. Inspired by this insight, this paper proposes a
novel method which endows deep neural networks with the `commonsense&apos; of
orientation. Given a ground-level spherical panoramic image as query input (and
a large georeferenced satellite image database), we design a Siamese network
which explicitly encodes the orientation (i.e., spherical directions) of each
pixel of the images. Our method significantly boosts the discriminative power
of the learned deep features, leading to a much higher recall and precision
outperforming all previous methods. Our network is also more compact using only
1/5th number of parameters than a previously best-performing network. To
evaluate the generalization of our method, we also created a large-scale
cross-view localization benchmark containing 100K geotagged ground-aerial pairs
covering a city. Our codes and datasets are available at
\url{https://github.com/Liumouliu/OriCNN}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Liu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongdong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12354">
<title>Out-of-the box neural networks can support combinatorial generalization. (arXiv:1903.12354v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1903.12354</link>
<description rdf:parseType="Literal">&lt;p&gt;Combinatorial generalization - the ability to understand and produce novel
combinations of already familiar elements - is considered to be a core capacity
of the human mind and a major challenge to neural network models. A significant
body of research suggests that conventional neural networks can&apos;t solve this
problem unless they are endowed with mechanisms specifically engineered for the
purpose of representing symbols. In this paper we introduce a novel way of
representing symbolic structures in connectionist terms - the vectors approach
to representing symbols (VARS), which allows training standard neural
architectures to encode symbolic knowledge explicitly at their output layers.
In two simulations , we show that out-of-the-box neural networks not only can
learn to produce VARS representations, but in doing so they achieve
combinatorial generalization. This adds to other recent work that has shown
improved combinatorial generalization under specific training conditions, and
raises the question of whether special mechanisms are indeed needed to support
symbolic processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vankov_I/0/1/0/all/0/1&quot;&gt;Ivan Vankov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bowers_J/0/1/0/all/0/1&quot;&gt;Jeffrey Bowers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12355">
<title>Local Aggregation for Unsupervised Learning of Visual Embeddings. (arXiv:1903.12355v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12355</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised approaches to learning in neural networks are of substantial
interest for furthering artificial intelligence, both because they would enable
the training of networks without the need for large numbers of expensive
annotations, and because they would be better models of the kind of
general-purpose learning deployed by humans. However, unsupervised networks
have long lagged behind the performance of their supervised counterparts,
especially in the domain of large-scale visual recognition. Recent developments
in training deep convolutional embeddings to maximize non-parametric instance
separation and clustering objectives have shown promise in closing this gap.
Here, we describe a method that trains an embedding function to maximize a
metric of local aggregation, causing similar data instances to move together in
the embedding space, while allowing dissimilar instances to separate. This
aggregation metric is dynamic, allowing soft clusters of different scales to
emerge. We evaluate our procedure on several large-scale visual recognition
datasets, achieving state-of-the-art unsupervised transfer learning performance
on object recognition in ImageNet, scene recognition in Places 205, and object
detection in PASCAL VOC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_C/0/1/0/all/0/1&quot;&gt;Chengxu Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhai_A/0/1/0/all/0/1&quot;&gt;Alex Lin Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1&quot;&gt;Daniel Yamins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12356">
<title>A General FOFE-net Framework for Simple and Effective Question Answering over Knowledge Bases. (arXiv:1903.12356v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12356</link>
<description rdf:parseType="Literal">&lt;p&gt;Question answering over knowledge base (KB-QA) has recently become a popular
research topic in NLP. One popular way to solve the KB-QA problem is to make
use of a pipeline of several NLP modules, including entity discovery and
linking (EDL) and relation detection. Recent success on KB-QA task usually
involves complex network structures with sophisticated heuristics. Inspired by
a previous work that builds a strong KB-QA baseline, we propose a simple but
general neural model composed of fixed-size ordinally forgetting encoding
(FOFE) and deep neural networks, called FOFE-net to solve KB-QA problem at
different stages. For evaluation, we use two popular KB-QA datasets,
SimpleQuestions and WebQSP, and a newly created dataset, FreebaseQA. The
experimental results show that FOFE-net performs well on KB-QA subtasks, entity
discovery and linking (EDL) and relation detection, and in turn pushing overall
KB-QA system to achieve strong results on all datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Dekun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nosirova_N/0/1/0/all/0/1&quot;&gt;Nana Nosirova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Hui Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Mingbin Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12359">
<title>Parallelizable global conformal parameterization of simply-connected surfaces via partial welding. (arXiv:1903.12359v1 [cs.CG])</title>
<link>http://arxiv.org/abs/1903.12359</link>
<description rdf:parseType="Literal">&lt;p&gt;Conformal surface parameterization is useful in graphics, imaging and
visualization, with applications to texture mapping, atlas construction,
registration, remeshing and so on. With the increasing capability in scanning
and storing data, dense 3D surface meshes are common nowadays. While meshes
with higher resolution better resemble smooth surfaces, they pose computational
difficulties for the existing parameterization algorithms. In this work, we
propose a novel parallelizable algorithm for computing the global conformal
parameterization of simply-connected surfaces via partial welding maps. A given
simply-connected surface is first partitioned into smaller subdomains. The
local conformal parameterizations of all subdomains are then computed in
parallel. The boundaries of the parameterized subdomains are subsequently
integrated consistently using a novel technique called partial welding, which
is developed based on conformal welding theory. Finally, by solving the Laplace
equation for each subdomain using the updated boundary conditions, we obtain a
global conformal parameterization of the given surface, with bijectivity
guaranteed by quasi-conformal theory. By including additional shape
constraints, our method can be easily extended to achieve disk conformal
parameterization for simply-connected open surfaces and spherical conformal
parameterization for genus-0 closed surfaces. Experimental results are
presented to demonstrate the effectiveness of our proposed algorithm. When
compared to the state-of-the-art conformal parameterization methods, our method
achieves a significant improvement in both computational time and accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_G/0/1/0/all/0/1&quot;&gt;Gary P. T. Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leung_Liu_Y/0/1/0/all/0/1&quot;&gt;Yusan Leung-Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1&quot;&gt;Xianfeng Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lui_L/0/1/0/all/0/1&quot;&gt;Lok Ming Lui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12360">
<title>Capacity of Fading Channels without Channel Side Information. (arXiv:1903.12360v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1903.12360</link>
<description rdf:parseType="Literal">&lt;p&gt;There are currently a plurality of capacity theories of fading channels,
including the ergodic capacity for fast fading channels and outage capacity for
slow fading channels. However, analyses show that the outage capacity is a
misconception. In this paper we use the 1st order Gaussian-Markov process with
coherence coefficient $\alpha$ as the unified model for slow and fast fading
channels, the capacity of which without channel side information is studied. We
demonstrate that the information rate of a fading channel has a structure that
the rate of user message is always accompanied by a rate of channel
information. The formula for the channel information rate is derived and turns
out to be a non-increasing function of $\alpha$. We prove that there is an
asymptotically monotonic behavior of the user information rate with respect to
$\alpha$ when the input is independent, identically distributed and Gaussian in
the high signal to noise ratio regime. It is further conjectured that the
monotonic behavior of the user information rate with respect to $\alpha$ is
universal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xuezhi Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12363">
<title>CUTIE: Learning to Understand Documents with Convolutional Universal Text Information Extractor. (arXiv:1903.12363v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12363</link>
<description rdf:parseType="Literal">&lt;p&gt;Extracting key information from documents, such as receipts or invoices, and
preserving the interested texts to structured data is crucial in the
document-intensive streamline processes of office automation in areas that
includes but not limited to accounting, financial, and taxation areas. To avoid
designing expert rules for each specific type of document, some published works
attempt to tackle the problem by learning a model to explore the semantic
context in text sequences based on the Named Entity Recognition (NER) method in
the NLP field. In this paper, we propose to harness the effective information
from both semantic meaning and spatial distribution of texts in documents.
Specifically, our proposed model, Convolutional Universal Text Information
Extractor (CUTIE), applies convolutional neural networks on gridded texts where
texts are embedded as features with semantical connotations. We further explore
the effect of employing different structures of convolutional neural network
and propose a fast and portable structure. We demonstrate the effectiveness of
the proposed method on a dataset with up to 6,980 labelled receipts, without
any pre-training or post-processing, achieving state of the art performance
that is much higher than BERT but with only 1/10 parameters and without
requiring the 3,300M word dataset for pre-training. Experimental results also
demonstrate that the CUTIE being able to achieve state of the art performance
with much smaller amount of training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xiaohui Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhuo Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaoguang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12364">
<title>Synthesizing a 4D Spatio-Angular Consistent Light Field from a Single Image. (arXiv:1903.12364v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12364</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthesizing a densely sampled light field from a single image is highly
beneficial for many applications. The conventional method reconstructs a depth
map and relies on physical-based rendering and a secondary network to improve
the synthesized novel views. Simple pixel-based loss also limits the network by
making it rely on pixel intensity cue rather than geometric reasoning. In this
study, we show that a different geometric representation, namely, appearance
flow, can be used to synthesize a light field from a single image robustly and
directly. A single end-to-end deep neural network that does not require a
physical-based approach nor a post-processing subnetwork is proposed. Two novel
loss functions based on known light field domain knowledge are presented to
enable the network to preserve the spatio-angular consistency between
sub-aperture images effectively. Experimental results show that the proposed
model successfully synthesizes dense light fields and qualitatively and
quantitatively outperforms the previous model . The method can be generalized
to arbitrary scenes, rather than focusing on a particular class of object. The
synthesized light field can be used for various applications, such as depth
estimation and refocusing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivan_A/0/1/0/all/0/1&quot;&gt;Andre Ivan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williem/0/1/0/all/0/1&quot;&gt;Williem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_I/0/1/0/all/0/1&quot;&gt;In Kyu Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12365">
<title>Testing zero-dimensionality of varieties at a point. (arXiv:1903.12365v1 [cs.SC])</title>
<link>http://arxiv.org/abs/1903.12365</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective methods are introduced for testing zero-dimensionality of varieties
at a point. The motivation of this paper is to compute and analyze deformations
of isolated hypersurface singularities. As an application, methods for
computing local dimensions are also described. For the case where a given ideal
contains parameters, the proposed algorithms can output in particular a
decomposition of a parameter space into strata according to the local dimension
at a point of the associated varieties. The key of the proposed algorithms is
the use of the notion of comprehensive Gr\&quot;obner systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nabeshima_K/0/1/0/all/0/1&quot;&gt;Katsusuke Nabeshima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tajima_S/0/1/0/all/0/1&quot;&gt;Shinichi Tajima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12366">
<title>Using Structured Input and Modularity for Improved Learning. (arXiv:1903.12366v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1903.12366</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a method for utilizing the known structure of input data to make
learning more efficient. Our work is in the domain of programming languages,
and we use deep neural networks to do program analysis. Computer programs
include a lot of structural information (such as loop nests, conditional
blocks, and data scopes), which is pertinent to program analysis. In this case,
the neural network has to learn to recognize the structure, and also learn the
target function for the problem. However, the structural information in this
domain is readily accessible to software with the availability of compiler
tools and parsers for well-defined programming languages.
&lt;/p&gt;
&lt;p&gt;Our method for utilizing the known structure of input data includes: (1)
pre-processing the input data to expose relevant structures, and (2)
constructing neural networks by incorporating the structure of the input data
as an integral part of the network design. The method has the effect of
modularizing the neural network which helps break down complexity, and results
in more efficient training of the overall network. We apply this method to an
example code analysis problem, and show that it can achieve higher accuracy
with a smaller network size and fewer training examples. Further, the method is
robust, performing equally well on input data with different distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sura_Z/0/1/0/all/0/1&quot;&gt;Zehra Sura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sung_H/0/1/0/all/0/1&quot;&gt;Hyojin Sung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12368">
<title>DenseAttentionSeg: Segment Hands from Interacted Objects Using Depth Input. (arXiv:1903.12368v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12368</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a real-time DNN-based technique to segment hand and object of
interacting motions from depth inputs. Our model is called DenseAttentionSeg,
which contains a dense attention mechanism to fuse information in different
scales and improves the results quality with skip-connections. Besides, we
introduce a contour loss in model training, which helps to generate accurate
hand and object boundaries. Finally, we propose and will release our
InterSegHands dataset, a fine-scale hand segmentation dataset containing about
52k depth maps of hand-object interactions. Our experiments evaluate the
effectiveness of our techniques and datasets, and indicate that our method
outperforms the current state-of-the-art deep segmentation methods on
interaction segmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bo_Z/0/1/0/all/0/1&quot;&gt;Zihao Bo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yong_J/0/1/0/all/0/1&quot;&gt;Junhai Yong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Feng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12370">
<title>On the Anatomy of MCMC-based Maximum Likelihood Learning of Energy-Based Models. (arXiv:1903.12370v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1903.12370</link>
<description rdf:parseType="Literal">&lt;p&gt;This study investigates the effects Markov Chain Monte Carlo (MCMC) sampling
in unsupervised Maximum Likelihood (ML) learning. Our attention is restricted
to the family unnormalized probability densities for which the negative log
density (or energy function) is a ConvNet. In general, we find that the
majority of techniques used to stabilize training in previous studies can the
opposite effect. Stable ML learning with a ConvNet potential can be achieved
with only a few hyper-parameters and no regularization. With this minimal
framework, we identify a variety of ML learning outcomes depending on the
implementation of MCMC sampling.
&lt;/p&gt;
&lt;p&gt;On one hand, we show that it is easy to train an energy-based model which can
sample realistic images with short-run Langevin. ML can be effective and stable
even when MCMC samples have much higher energy than true steady-state samples
throughout training. Based on this insight, we introduce an ML method with
noise initialization for MCMC, high-quality short-run synthesis, and the same
budget as ML with informative MCMC initialization such as CD or PCD. Unlike
previous models, this model can obtain realistic high-diversity samples from a
noise signal after training with no auxiliary models.
&lt;/p&gt;
&lt;p&gt;On the other hand, models learned with highly non-convergent MCMC do not have
a valid steady-state and cannot be considered approximate unnormalized
densities of the training data because long-run MCMC samples differ greatly
from the data. We show that it is much harder to train an energy-based model
where long-run and steady-state MCMC samples have realistic appearance. To our
knowledge, long-run MCMC samples of all previous models result in unrealistic
images. With correct tuning of Langevin noise, we train the first models for
which long-run and steady-state MCMC samples are realistic images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nijkamp_E/0/1/0/all/0/1&quot;&gt;Erik Nijkamp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hill_M/0/1/0/all/0/1&quot;&gt;Mitch Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Han_T/0/1/0/all/0/1&quot;&gt;Tian Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12371">
<title>Cyber-Social Systems: Modeling, Inference, and Optimal Design. (arXiv:1903.12371v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1903.12371</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper models the cyber-social system as a cyber-network of agents
monitoring states of individuals in a social network. The state of each
individual is represented by a social node and the interactions among
individuals are represented by a social link. In the cyber-network each node
represents an agent and the links represent information sharing among agents.
Agents make an observation of social states and perform distributed inference.
In this direction, the contribution of this work is threefold: (i) A novel
distributed inference protocol is proposed that makes no assumption on the rank
of the underlying social system. This is significant as most protocols in the
literature only work on full-rank systems. (ii) A novel agent classification is
developed, where it is shown that connectivity requirement on the cyber-network
differs for each type. This is particularly important in finding the minimal
number of observations and minimal connectivity of the cyber-network as the
next contribution. (iii) The cost-optimal design of cyber-network constraint
with distributed observability is addressed. This problem is subdivided into
sensing cost optimization and networking cost optimization where both are
claimed to be NP-hard. We solve both problems for certain types of social
networks and find polynomial-order solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doostmohammadian_M/0/1/0/all/0/1&quot;&gt;Mohammadreza Doostmohammadian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabiee_H/0/1/0/all/0/1&quot;&gt;Hamid R. Rabiee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_U/0/1/0/all/0/1&quot;&gt;Usman A. Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12384">
<title>Deep Representation with ReLU Neural Networks. (arXiv:1903.12384v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12384</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider deep feedforward neural networks with rectified linear units from
a signal processing perspective. In this view, such representations mark the
transition from using a single (data-driven) linear representation to utilizing
a large collection of affine linear representations tailored to particular
regions of the signal space. This paper provides a precise description of the
individual affine linear representations and corresponding domain regions that
the (data-driven) neural network associates to each signal of the input space.
In particular, we describe atomic decompositions of the representations and,
based on estimating their Lipschitz regularity, suggest some conditions that
can stabilize learning independent of the network depth. Such an analysis may
promote further theoretical insight from both the signal processing and machine
learning communities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinecke_A/0/1/0/all/0/1&quot;&gt;Andreas Heinecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1&quot;&gt;Wen-Liang Hwang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12385">
<title>Fractional matchings and component-factors of (edge-chromatic critical) graphs. (arXiv:1903.12385v1 [math.CO])</title>
<link>http://arxiv.org/abs/1903.12385</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper studies component-factors of graphs which can be characterized in
terms of their fractional matching number. These results are used to prove that
every edge-chromatic critical graph has a $[1,2]$-factor. Furthermore,
fractional matchings of edge-chromatic critical graphs are studied and some
questions are related to Vizing&apos;s conjectures on the independence number and
2-factors of edge-chromatic critical graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Klopp_A/0/1/0/all/0/1&quot;&gt;Antje Klopp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Steffen_E/0/1/0/all/0/1&quot;&gt;Eckhard Steffen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12386">
<title>G\&apos;EANT Software Maturity Model. (arXiv:1903.12386v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1903.12386</link>
<description rdf:parseType="Literal">&lt;p&gt;G\&apos;EANT project is an example of a large organization with around 30 software
projects and around 20 software development teams. Software development teams
consist of many skilled associates coming from all members National Research
and Education Networks. Three main issues that are common for all these
software development teams and their members are: geographical distribution,
scattered manpower percentage, and parallel involvement in other high priority
projects in their native organizations. This paper presents a novel software
maturity model that is designed specifically for G\&apos;EANT software development
teams and aims to address the described issues.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanisavljevic_Z/0/1/0/all/0/1&quot;&gt;Zarko Stanisavljevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walter_B/0/1/0/all/0/1&quot;&gt;Bartosz Walter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vukasovic_M/0/1/0/all/0/1&quot;&gt;Maja Vukasovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Todosijevic_A/0/1/0/all/0/1&quot;&gt;Andrijana Todosijevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labedzki_M/0/1/0/all/0/1&quot;&gt;Maciej Labedzki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolski_M/0/1/0/all/0/1&quot;&gt;Marcin Wolski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12388">
<title>Predictability of diffusion-based recommender systems. (arXiv:1903.12388v1 [physics.soc-ph])</title>
<link>http://arxiv.org/abs/1903.12388</link>
<description rdf:parseType="Literal">&lt;p&gt;The recommendation methods based on network diffusion have been shown to
perform well in both recommendation accuracy and diversity. Nowdays, numerous
extensions have been made to further improve the performance of such methods.
However, to what extent can items be predicted by diffusion-based algorithms
still lack of understanding. Here, we mainly propose a method to quantify the
predictability of diffusion-based algorithms. Accordingly, we conduct
experiments on Movielens and Netflix data sets. The results show that the
higher recommendation accuracy based on diffusion algorithms can still be
achieved by optimizing the way of resource allocation on a density network. On
a sparse network, the possibility of improving accuracy is relatively low due
to the fact that the current accuracy of diffusion-based methods is very close
its predictability. In this case, we find that the predictability can be
improved significantly by multi-steps diffusion, especially for users with less
historical information. In contrast to common belief, there are plausible
circumstances where the higher predictability of diffusion-based methods do not
correspond to those users with more historical recording. Thus, we proposed the
diffusion coverage and item average degree to explain this phenomenon. In
addition, we demonstrate the recommendation accuracy in real online system is
overestimated by random partition used in the literature, suggesting the
recommendation in real online system may be a harder task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Peng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Xue_L/0/1/0/all/0/1&quot;&gt;Leyang Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zeng_A/0/1/0/all/0/1&quot;&gt;An Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12389">
<title>Joint training framework for text-to-speech and voice conversion using multi-source Tacotron and WaveNet. (arXiv:1903.12389v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1903.12389</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigated the training of a shared model for both text-to-speech (TTS)
and voice conversion (VC) tasks. We propose using an extended model
architecture of Tacotron, that is a multi-source sequence-to-sequence model
with a dual attention mechanism as the shared model for both the TTS and VC
tasks. This model can accomplish these two different tasks respectively
according to the type of input. An end-to-end speech synthesis task is
conducted when the model is given text as the input while a
sequence-to-sequence voice conversion task is conducted when it is given the
speech of a source speaker as the input. Waveform signals are generated by
using WaveNet, which is conditioned by using a predicted mel-spectrogram. We
propose jointly training a shared model as a decoder for a target speaker that
supports multiple sources. Listening experiments show that our proposed
multi-source encoder-decoder model can efficiently achieve both the TTS and VC
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fang_F/0/1/0/all/0/1&quot;&gt;Fuming Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haizhou Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yamagishi_J/0/1/0/all/0/1&quot;&gt;Junichi Yamagishi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12392">
<title>Training a Neural Speech Waveform Model using Spectral Losses of Short-Time Fourier Transform and Continuous Wavelet Transform. (arXiv:1903.12392v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1903.12392</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, we proposed short-time Fourier transform (STFT)-based loss
functions for training a neural speech waveform model. In this paper, we
generalize the above framework and propose a training scheme for such models
based on spectral amplitude and phase losses obtained by either STFT or
continuous wavelet transform (CWT), or both of them. Since CWT is capable of
having time and frequency resolutions different from those of STFT and is cable
of considering those closer to human auditory scales, the proposed loss
functions could provide complementary information on speech signals.
Experimental results showed that it is possible to train a high-quality model
by using the proposed CWT spectral loss and is as good as one using STFT-based
loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Takaki_S/0/1/0/all/0/1&quot;&gt;Shinji Takaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kameoka_H/0/1/0/all/0/1&quot;&gt;Hirokazu Kameoka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yamagishi_J/0/1/0/all/0/1&quot;&gt;Junichi Yamagishi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12394">
<title>Informed Machine Learning - Towards a Taxonomy of Explicit Integration of Knowledge into Machine Learning. (arXiv:1903.12394v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1903.12394</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the great successes of machine learning, it can have its limits when
dealing with insufficient training data.A potential solution is to incorporate
additional knowledge into the training process which leads to the idea of
informed machine learning. We present a research survey and structured overview
of various approaches in this field. We aim to establish a taxonomy which can
serve as a classification framework that considers the kind of additional
knowledge, its representation,and its integration into the machine learning
pipeline. The evaluation of numerous papers on the bases of the taxonomy
uncovers key methods in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rueden_L/0/1/0/all/0/1&quot;&gt;Laura von Rueden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mayer_S/0/1/0/all/0/1&quot;&gt;Sebastian Mayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garcke_J/0/1/0/all/0/1&quot;&gt;Jochen Garcke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bauckhage_C/0/1/0/all/0/1&quot;&gt;Christian Bauckhage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schuecker_J/0/1/0/all/0/1&quot;&gt;Jannis Schuecker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12395">
<title>Few-Shot Deep Adversarial Learning for Video-based Person Re-identification. (arXiv:1903.12395v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12395</link>
<description rdf:parseType="Literal">&lt;p&gt;Video-based person re-identification (re-ID) refers to matching people across
camera views from arbitrary unaligned video footages. Existing methods rely on
supervision signals to optimise a projected space under which the distances
between inter/intra-videos are maximised/minimised. However, this demands
exhaustively labelling people across camera views, rendering them unable to be
scaled in large networked cameras. Also, it is noticed that learning effective
video representations with view invariance is not explicitly addressed for
which features exhibit different distributions otherwise. Thus, matching videos
for person re-ID demands flexible models to capture the dynamics in time-series
observations and learn view-invariant representations with access to limited
labeled training samples. In this paper, we propose a novel few-shot deep
learning approach to video-based person re-ID, to learn comparable
representations that are discriminative and view-invariant. The proposed method
is developed on the variational recurrent neural networks (VRNNs) and trained
adversarially to produce latent variables with temporal dependencies that are
highly discriminative yet view-invariant in matching persons. Through extensive
experiments conducted on three benchmark datasets, we empirically show the
capability of our method in creating view-invariant temporal features and
state-of-the-art performance achieved by our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lin Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Hongzhi Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Meng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1&quot;&gt;Ling Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lovell_B/0/1/0/all/0/1&quot;&gt;B. C. Lovell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12398">
<title>Identification and Analysis of Cascading Failures in Power Grids with Protective Actions. (arXiv:1903.12398v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1903.12398</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper aims to identify and analyze the initial contingencies or
disturbances that could lead to the worst-case cascading failures of power
grids. An optimal control approach is proposed to determine the most disruptive
disturbances on the branch of power transmission system by regarding the
disturbances as the control inputs. Moreover, protective actions such as load
shedding and generation dispatch are taken into account in a convex
optimization framework to prevent the cascading outages of power grids. In
theory, the necessary conditions for identifying the most disruptive
disturbances are obtained by solving an integrated system of algebraic
equations. Finally, numerical simulations are carried out to validate the
proposed approach on the IEEE RTS 24 Bus System.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1&quot;&gt;Chao Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1&quot;&gt;Gaoxi Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hehong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12399">
<title>A Study on the Characteristics of Douyin Short Videos and Implications for Edge Caching. (arXiv:1903.12399v1 [cs.MM])</title>
<link>http://arxiv.org/abs/1903.12399</link>
<description rdf:parseType="Literal">&lt;p&gt;Douyin, internationally known as TikTok, has become one of the most
successful short-video platforms. To maintain its popularity, Douyin has to
provide better Quality of Experience (QoE) to its growing user base.
Understanding the characteristics of Douyin videos is thus critical to its
service improvement and system design. In this paper, we present an initial
study on the fundamental characteristics of Douyin videos based on a dataset of
over 260 thousand short videos collected across three months. The
characteristics of Douyin videos are found to be significantly different from
traditional online videos, ranging from video bitrate, size, to popularity. In
particular, the distributions of the bitrate and size of videos follow Weibull
distribution. We further observe that the most popular Douyin videos follow
Zifp&apos;s law on video popularity, but the rest of the videos do not. We also
investigate the correlation between popularity metrics used for Douyin videos.
It is found that the correlation between the number of views and the number of
likes are strong, while other correlations are relatively low. Finally, by
using a case study, we demonstrate that the above findings can provide
important guidance on designing an efficient edge caching system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhuang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1&quot;&gt;Qian He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1&quot;&gt;Zhifei Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1&quot;&gt;Hwei-Ming Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maharjan_S/0/1/0/all/0/1&quot;&gt;Sabita Maharjan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12400">
<title>A Force-Directed Approach for Offline GPS Trajectory Map Matching. (arXiv:1903.12400v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1903.12400</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel algorithm to match GPS trajectories onto maps offline (in
batch mode) using techniques borrowed from the field of force-directed graph
drawing. We consider a simulated physical system where each GPS trajectory is
attracted or repelled by the underlying road network via electrical-like
forces. We let the system evolve under the action of these physical forces such
that individual trajectories are attracted towards candidate roads to obtain a
map matching path. Our approach has several advantages compared to traditional,
routing-based, algorithms for map matching, including the ability to account
for noise and to avoid large detours due to outliers in the data whilst taking
into account the underlying topological restrictions (such as one-way roads).
Our empirical evaluation using real GPS traces shows that our method produces
better map matching results compared to alternative offline map matching
algorithms on average, especially for routes in dense, urban areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rappos_E/0/1/0/all/0/1&quot;&gt;Efstratios Rappos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robert_S/0/1/0/all/0/1&quot;&gt;Stephan Robert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cudre_Mauroux_P/0/1/0/all/0/1&quot;&gt;Philippe Cudr&amp;#xe9;-Mauroux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12402">
<title>Proceedings 7th International Workshop on Theorem proving components for Educational software. (arXiv:1903.12402v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1903.12402</link>
<description rdf:parseType="Literal">&lt;p&gt;The 7th International Workshop on Theorem proving components for Educational
software (ThEdu&apos;18) was held in Oxford, United Kingdom, on 18 July 2018. It was
associated to the conference, Federated Logic Conference 2018 (FLoC2018).
&lt;/p&gt;
&lt;p&gt;The major aim of the ThEdu workshop series was to link developers interested
in adapting Computer Theorem Proving (TP) to the needs of education and to
inform mathematicians and mathematics educators about TP&apos;s potential for
educational software. Topics of interest include: methods of automated
deduction applied to checking students&apos; input; methods of automated deduction
applied to prove post-conditions for particular problem solutions; combinations
of deduction and computation enabling systems to propose next steps; automated
provers specific for dynamic geometry systems; proof and proving in mathematics
education.
&lt;/p&gt;
&lt;p&gt;ThEdu&apos;18 was a vibrant workshop, with one invited talk and six contributions.
It triggered the post-proceedings at hand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quaresma_P/0/1/0/all/0/1&quot;&gt;Pedro Quaresma&lt;/a&gt; (University of Coimbra, Portugal), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neuper_W/0/1/0/all/0/1&quot;&gt;Walther Neuper&lt;/a&gt; (Graz University of Technology, Austria)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12411">
<title>MCTS-based Automated Negotiation Agent (Extended Abstract). (arXiv:1903.12411v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1903.12411</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a new Negotiating Agent for automated negotiation on
continuous domains and without considering a specified deadline. The agent
bidding strategy relies on Monte Carlo Tree Search, which is a trendy method
since it has been used with success on games with high branching factor such as
Go. It uses two opponent modeling techniques for its bidding strategy and its
utility: Gaussian process regression and Bayesian learning. Evaluation is done
by confronting the existing agents that are able to negotiate in such context:
Random Walker, Tit-for-tat and Nice Tit-for-Tat. None of those agents succeeds
in beating our agent; moreover the modular and adaptive nature of our approach
is a huge advantage when it comes to optimize it in specific applicative
contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buron_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Buron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guessoum_Z/0/1/0/all/0/1&quot;&gt;Zahia Guessoum&lt;/a&gt; (SMA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ductor_S/0/1/0/all/0/1&quot;&gt;Sylvain Ductor&lt;/a&gt; (UECE)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12416">
<title>Online Variance Reduction with Mixtures. (arXiv:1903.12416v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12416</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive importance sampling for stochastic optimization is a promising
approach that offers improved convergence through variance reduction. In this
work, we propose a new framework for variance reduction that enables the use of
mixtures over predefined sampling distributions, which can naturally encode
prior knowledge about the data. While these sampling distributions are fixed,
the mixture weights are adapted during the optimization process. We propose
VRM, a novel and efficient adaptive scheme that asymptotically recovers the
best mixture weights in hindsight and can also accommodate sampling
distributions over sets of points. We empirically demonstrate the versatility
of VRM in a range of applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borsos_Z/0/1/0/all/0/1&quot;&gt;Zal&amp;#xe1;n Borsos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Curi_S/0/1/0/all/0/1&quot;&gt;Sebastian Curi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1&quot;&gt;Kfir Y. Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12417">
<title>Nonlinear fourth order Taylor expansion of lattice Boltzmann schemes. (arXiv:1903.12417v1 [math.NA])</title>
<link>http://arxiv.org/abs/1903.12417</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a formal expansion of multiple relaxation times lattice Boltzmann
schemes in terms of a single infinitesimal numerical variable. The result is a
system of partial differential equations for the conserved moments of the
lattice Boltzmann scheme. The expansion is presented in the nonlinear case up
to fourth order accuracy. The asymptotic corrections of the nonconserved
moments are developed in terms of equilibrium values and partial differentials
of the conserved moments. Both expansions are coupled and conduct to explicit
compact formulas. The new algebraic expressions are validated with previous
results obtained with this approach. The example of isothermal D2Q9 lattice
Boltzmann scheme illustrates the theoretical framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dubois_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Dubois&lt;/a&gt; (LM-Orsay, LMSSC)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12422">
<title>Snore-GANs: Improving Automatic Snore Sound Classification with Synthesized Data. (arXiv:1903.12422v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12422</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the frontier issues that severely hamper the development of automatic
snore sound classification (ASSC) associates to the lack of sufficient
supervised training data. To cope with this problem, we propose a novel data
augmentation approach based on semi-supervised conditional Generative
Adversarial Networks (scGANs), which aims to automatically learn a mapping
strategy from a random noise space to original data distribution. The proposed
approach has the capability of well synthesizing &apos;realistic&apos; high-dimensional
data, while requiring no additional annotation process. To handle the mode
collapse problem of GANs, we further introduce an ensemble strategy to enhance
the diversity of the generated data. The systematic experiments conducted on a
widely used Munich-Passau snore sound corpus demonstrate that the scGANs-based
systems can remarkably outperform other classic data augmentation systems, and
are also competitive to other recently reported systems for ASSC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zixing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jing Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1&quot;&gt;Kun Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janott_C/0/1/0/all/0/1&quot;&gt;Christoph Janott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yanan Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bjoern Schuller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12424">
<title>Attention-Augmented End-to-End Multi-Task Learning for Emotion Prediction from Speech. (arXiv:1903.12424v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12424</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the increasing research interest in end-to-end learning systems for
speech emotion recognition, conventional systems either suffer from the
overfitting due in part to the limited training data, or do not explicitly
consider the different contributions of automatically learnt representations
for a specific task. In this contribution, we propose a novel end-to-end
framework which is enhanced by learning other auxiliary tasks and an attention
mechanism. That is, we jointly train an end-to-end network with several
different but related emotion prediction tasks, i.e., arousal, valence, and
dominance predictions, to extract more robust representations shared among
various tasks than traditional systems with the hope that it is able to relieve
the overfitting problem. Meanwhile, an attention layer is implemented on top of
the layers for each task, with the aim to capture the contribution distribution
of different segment parts for each individual task. To evaluate the
effectiveness of the proposed system, we conducted a set of experiments on the
widely used database IEMOCAP. The empirical results show that the proposed
systems significantly outperform corresponding baseline systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zixing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Bingwen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bjoern Schuller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12427">
<title>Computing huge Groebner basis like cyclic10 over $\Q$ with Giac. (arXiv:1903.12427v1 [cs.SC])</title>
<link>http://arxiv.org/abs/1903.12427</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a short description on how to fine-tune the modular algorithm
implemented in the Giac computer algebra system to reconstruct huge Groebner
basis over $\Q$.The classical cyclic10 benchmark will serve as example.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parisse_B/0/1/0/all/0/1&quot;&gt;Bernard Parisse&lt;/a&gt; (IF)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12431">
<title>Train One Get One Free: Partially Supervised Neural Network for Bug Report Duplicate Detection and Clustering. (arXiv:1903.12431v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12431</link>
<description rdf:parseType="Literal">&lt;p&gt;Tracking user reported bugs requires considerable engineering effort in going
through many repetitive reports and assigning them to the correct teams. This
paper proposes a neural architecture that can jointly (1) detect if two bug
reports are duplicates, and (2) aggregate them into latent topics. Leveraging
the assumption that learning the topic of a bug is a sub-task for detecting
duplicates, we design a loss function that can jointly perform both tasks but
needs supervision for only duplicate classification, achieving topic clustering
in an unsupervised fashion. We use a two-step attention module that uses
self-attention for topic clustering and conditional attention for duplicate
detection. We study the characteristics of two types of real world datasets
that have been marked for duplicate bugs by engineers and by non-technical
annotators. The results demonstrate that our model not only can outperform
state-of-the-art methods for duplicate classification on both cases, but can
also learn meaningful latent clusters without additional supervision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poddar_L/0/1/0/all/0/1&quot;&gt;Lahari Poddar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neves_L/0/1/0/all/0/1&quot;&gt;Leonardo Neves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1&quot;&gt;William Brendel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marujo_L/0/1/0/all/0/1&quot;&gt;Luis Marujo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1&quot;&gt;Sergey Tulyakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karuturi_P/0/1/0/all/0/1&quot;&gt;Pradeep Karuturi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12432">
<title>Color Refinement, Homomorphisms, and Hypergraphs. (arXiv:1903.12432v1 [cs.DM])</title>
<link>http://arxiv.org/abs/1903.12432</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent results show that the structural similarity of graphs can be
characterized by counting homomorphisms to them: the Tree Theorem states that
the well-known color-refinement algorithm does not distinguish two graphs G and
H if and only if, for every tree T, the number of homomorphisms Hom(T,G) from T
to G is equal to the corresponding number Hom(T,H) from T to H (Dell, Grohe,
Rattan 2018). We show how this approach transfers to hypergraphs by introducing
a generalization of color refinement. We prove that it does not distinguish two
hypergraphs G and H if and only if, for every connected Berge-acyclic
hypergraph B, we have Hom(B,G) = Hom(B,H). To this end, we show how
homomorphisms of hypergraphs and of a colored variant of their incidence graphs
are related to each other. This reduces the above statement to one about
vertex-colored graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boker_J/0/1/0/all/0/1&quot;&gt;Jan B&amp;#xf6;ker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12436">
<title>From Variational to Deterministic Autoencoders. (arXiv:1903.12436v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12436</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational Autoencoders (VAEs) provide a theoretically-backed framework for
deep generative models. However, they often produce &quot;blurry&quot; images, which is
linked to their training objective. Sampling in the most popular
implementation, the Gaussian VAE, can be interpreted as simply injecting noise
to the input of a deterministic decoder. In practice, this simply enforces a
smooth latent space structure. We challenge the adoption of the full VAE
framework on this specific point in favor of a simpler, deterministic one.
Specifically, we investigate how substituting stochasticity with other explicit
and implicit regularization schemes can lead to a meaningful latent space
without having to force it to conform to an arbitrarily chosen prior. To
retrieve a generative mechanism for sampling new data points, we propose to
employ an efficient ex-post density estimation step that can be readily adopted
both for the proposed deterministic autoencoders as well as to improve sample
quality of existing VAEs. We show in a rigorous empirical study that
regularized deterministic autoencoding achieves state-of-the-art sample quality
on the common MNIST, CIFAR-10 and CelebA datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1&quot;&gt;Partha Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sajjadi_M/0/1/0/all/0/1&quot;&gt;Mehdi S. M. Sajjadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vergari_A/0/1/0/all/0/1&quot;&gt;Antonio Vergari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1&quot;&gt;Michael Black&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12449">
<title>Multiplication method for factoring natural numbers. (arXiv:1903.12449v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1903.12449</link>
<description rdf:parseType="Literal">&lt;p&gt;We offer multiplication method for factoring big natural numbers which
extends the group of the Fermat&apos;s and Lehman&apos;s factorization algorithms and has
run-time complexity $O(n^{1/3})$. This paper is argued the finiteness of
proposed algorithm depending on the value of the factorizable number n. We
provide here comparative tests results of related algorithms on a large amount
of computational checks. We describe identified advantages of the proposed
algorithm over others. The possibilities of algorithm optimization for reducing
the complexity of factorization are also shown here.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nesiolovskiy_I/0/1/0/all/0/1&quot;&gt;Igor Nesiolovskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nesiolovskiy_A/0/1/0/all/0/1&quot;&gt;Artem Nesiolovskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12451">
<title>Energy-Efficient Distributed Processing in Vehicular Cloud Architecture. (arXiv:1903.12451v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1903.12451</link>
<description rdf:parseType="Literal">&lt;p&gt;Facilitating the revolution for smarter cities, vehicles are getting smarter
and equipped with more resources to go beyond transportation functionality.
On-Board Units (OBU) are efficient computers inside vehicles that serve safety
and non-safety based applications. However, much of these resources are
underutilised. On the other hand, more users are relying now on cloud computing
which is becoming costly and energy consuming. In this paper, we develop a
Mixed Integer linear Programming (MILP) model that optimizes the allocation of
processing demands in an architecture that encompasses the vehicles, edge and
cloud computing with the objective of minimizing power consumption. The results
show power savings of 70%-90% compared to conventional clouds for small
demands. For medium and large demand sizes, the results show 20%-30% power
saving as the cloud was used partially due to capacity limitations on the
vehicular and edge nodes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behbehani_F/0/1/0/all/0/1&quot;&gt;Fatemah S. Behbehani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musa_M/0/1/0/all/0/1&quot;&gt;Mohamed Musa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elgorashi_T/0/1/0/all/0/1&quot;&gt;Taisir Elgorashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elmirghani_J/0/1/0/all/0/1&quot;&gt;J. M. H. Elmirghani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12452">
<title>A framework for fake review detection in online consumer electronics retailers. (arXiv:1903.12452v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12452</link>
<description rdf:parseType="Literal">&lt;p&gt;The impact of online reviews on businesses has grown significantly during
last years, being crucial to determine business success in a wide array of
sectors, ranging from restaurants, hotels to e-commerce. Unfortunately, some
users use unethical means to improve their online reputation by writing fake
reviews of their businesses or competitors. Previous research has addressed
fake review detection in a number of domains, such as product or business
reviews in restaurants and hotels. However, in spite of its economical
interest, the domain of consumer electronics businesses has not yet been
thoroughly studied. This article proposes a feature framework for detecting
fake reviews that has been evaluated in the consumer electronics domain. The
contributions are fourfold: (i) Construction of a dataset for classifying fake
reviews in the consumer electronics domain in four different cities based on
scraping techniques; (ii) definition of a feature framework for fake review
detection; (iii) development of a fake review classification method based on
the proposed framework and (iv) evaluation and analysis of the results for each
of the cities under study. We have reached an 82% F-Score on the classification
task and the Ada Boost classifier has been proven to be the best one by
statistical means according to the Friedman test.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbado_R/0/1/0/all/0/1&quot;&gt;Rodrigo Barbado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Araque_O/0/1/0/all/0/1&quot;&gt;Oscar Araque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iglesias_C/0/1/0/all/0/1&quot;&gt;Carlos A. Iglesias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12453">
<title>Frowning Frodo, Wincing Leia, and a Seriously Great Friendship: Learning to Classify Emotional Relationships of Fictional Characters. (arXiv:1903.12453v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12453</link>
<description rdf:parseType="Literal">&lt;p&gt;The development of a fictional plot is centered around characters who closely
interact with each other forming dynamic social networks. In literature
analysis, such networks have mostly been analyzed without particular relation
types or focusing on roles which the characters take with respect to each
other. We argue that an important aspect for the analysis of stories and their
development is the emotion between characters. In this paper, we combine these
aspects into a unified framework to classify emotional relationships of
fictional characters. We formalize it as a new task and describe the annotation
of a corpus, based on fan-fiction short stories. The extraction pipeline which
we propose consists of character identification (which we treat as given by an
oracle here) and the relation classification. For the latter, we provide
results using several approaches previously proposed for relation
identification with neural methods. The best result of 0.45 F1 is achieved with
a GRU with character position indicators on the task of predicting undirected
emotion relations in the associated social network graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1&quot;&gt;Evgeny Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1&quot;&gt;Roman Klinger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12457">
<title>Towards Knowledge-Based Personalized Product Description Generation in E-commerce. (arXiv:1903.12457v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12457</link>
<description rdf:parseType="Literal">&lt;p&gt;Quality product descriptions are critical for providing competitive customer
experience in an E-commerce platform. An accurate and attractive description
not only helps customers make an informed decision but also improves the
likelihood of purchase. However, crafting a successful product description is
tedious and highly time-consuming. Due to its importance, automating the
product description generation has attracted considerable interests from both
research and industrial communities. Existing methods mainly use templates or
statistical methods, and their performance could be rather limited.
&lt;/p&gt;
&lt;p&gt;In this paper, we explore a new way to generate the personalized product
description by combining the power of neural networks and knowledge base.
Specifically, we propose a KnOwledge Based pEronalized (or KOBE) product
description generation model in the context of E-commerce. In KOBE, we extend
the encoder-decoder framework, the Transformer, to a sequence modeling
formulation using self-attention. In order to make the description both
informative and personalized, KOBE considers a variety of important factors
during text generation, including product aspects, user categories, and
knowledge base, etc. Experiments on real-world datasets demonstrate that the
proposed method out-performs the baseline on various metrics. KOBE can achieve
an improvement of 9.7% over state-of-the-arts in terms of BLEU. We also present
several case studies as the anecdotal evidence to further prove the
effectiveness of the proposed approach. The framework has been deployed in
Taobao, the largest online E-commerce platform in China.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Qibin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Junyang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yichang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hongxia Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jingren Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12458">
<title>Market Manipulation as a Security Problem. (arXiv:1903.12458v1 [q-fin.TR])</title>
<link>http://arxiv.org/abs/1903.12458</link>
<description rdf:parseType="Literal">&lt;p&gt;Order matching systems form the backbone of modern equity exchanges, used by
millions of investors daily. Thus, their operation is strictly controlled
through numerous regulatory directives to ensure that markets are fair and
transparent. Despite these efforts, market manipulation remains an open
problem.
&lt;/p&gt;
&lt;p&gt;In this work, we focus on a class of market manipulation techniques that
exploit technical details and glitches in the operation of the exchanges (i.e.,
mechanical arbitrage). Such techniques are used by predatory traders with deep
knowledge of the exchange&apos;s structure to gain an advantage over the other
market participants. We argue that technical solutions to the problem of
mechanical arbitrage have the potential to significantly thwart these
practices. Our work provides the first overview of the threat landscape, models
fair markets and their security assumptions, and discusses various mitigation
measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Mavroudis_V/0/1/0/all/0/1&quot;&gt;Vasilios Mavroudis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12466">
<title>Distributed Ledger Technology for Smart Mobility: Variable Delay Models. (arXiv:1903.12466v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1903.12466</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, Directed Acyclic Graph (DAG) based Distributed Ledgers have been
proposed for various applications in the smart mobility domain [1]. While many
application studies have been described in the literature, an open problem in
the DLT community concerns the lack of mathematical models describing their
behaviour, and their validation. Building on a previous work in [1], we
present, in this paper, a fluid based approximation for the IOTA Foundation DAG
based DLT that incorporates varying transaction delays. This extension, namely
the inclusion of varying delays, is important for feedback control applications
(such as transactive control [2]). Extensive simulations are presented to
illustrate the efficacy of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cullen_A/0/1/0/all/0/1&quot;&gt;Andrew Cullen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferraro_P/0/1/0/all/0/1&quot;&gt;Pietro Ferraro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+King_C/0/1/0/all/0/1&quot;&gt;Christopher King&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shorten_R/0/1/0/all/0/1&quot;&gt;Robert Shorten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12467">
<title>Deep, spatially coherent Occupancy Maps based on Radar Measurements. (arXiv:1903.12467v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1903.12467</link>
<description rdf:parseType="Literal">&lt;p&gt;One essential step to realize modern driver assistance technology is the
accurate knowledge about the location of static objects in the environment. In
this work, we use artificial neural networks to predict the occupation state of
a whole scene in an end-to-end manner. This stands in contrast to the
traditional approach of accumulating each detection&apos;s influence on the
occupancy state and allows to learn spatial priors which can be used to
interpolate the environment&apos;s occupancy state. We show that these priors make
our method suitable to predict dense occupancy estimations from sparse, highly
uncertain inputs, as given by automotive radars, even for complex urban
scenarios. Furthermore, we demonstrate that these estimations can be used for
large-scale mapping applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bauer_D/0/1/0/all/0/1&quot;&gt;Daniel Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuhnert_L/0/1/0/all/0/1&quot;&gt;Lars Kuhnert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eckstein_L/0/1/0/all/0/1&quot;&gt;Lutz Eckstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12468">
<title>Automatic Failure Explanation in CPS Models. (arXiv:1903.12468v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1903.12468</link>
<description rdf:parseType="Literal">&lt;p&gt;Debugging Cyber-Physical System (CPS) models can be extremely complex.
Indeed, only the detection of a failure is insuffcient to know how to correct a
faulty model. Faults can propagate in time and in space producing observable
misbehaviours in locations completely different from the location of the fault.
Understanding the reason of an observed failure is typically a challenging and
laborious task left to the experience and domain knowledge of the designer. \n
In this paper, we propose CPSDebug, a novel approach that by combining testing,
specification mining, and failure analysis, can automatically explain failures
in Simulink/Stateflow models. We evaluate CPSDebug on two case studies,
involving two use scenarios and several classes of faults, demonstrating the
potential value of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartocci_E/0/1/0/all/0/1&quot;&gt;Ezio Bartocci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manjunath_N/0/1/0/all/0/1&quot;&gt;Niveditha Manjunath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mariani_L/0/1/0/all/0/1&quot;&gt;Leonardo Mariani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mateis_C/0/1/0/all/0/1&quot;&gt;Cristinel Mateis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nickovic_D/0/1/0/all/0/1&quot;&gt;Dejan Ni&amp;#x10d;kovi&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12469">
<title>Corrigendum to &quot;Counting Database Repairs that Satisfy Conjunctive Queries with Self-Joins&quot;. (arXiv:1903.12469v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1903.12469</link>
<description rdf:parseType="Literal">&lt;p&gt;The helping Lemma 7 in [Maslowski and Wijsen, ICDT, 2014] is false. The lemma
is used in (and only in) the proof of Theorem 3 of that same paper. In this
corrigendum, we provide a new proof for the latter theorem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijsen_J/0/1/0/all/0/1&quot;&gt;Jef Wijsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12470">
<title>Trustworthy Experimentation Under Telemetry Loss. (arXiv:1903.12470v1 [cs.OH])</title>
<link>http://arxiv.org/abs/1903.12470</link>
<description rdf:parseType="Literal">&lt;p&gt;Failure to accurately measure the outcomes of an experiment can lead to bias
and incorrect conclusions. Online controlled experiments (aka AB tests) are
increasingly being used to make decisions to improve websites as well as mobile
and desktop applications. We argue that loss of telemetry data (during upload
or post-processing) can skew the results of experiments, leading to loss of
statistical power and inaccurate or erroneous conclusions. By systematically
investigating the causes of telemetry loss, we argue that it is not practical
to entirely eliminate it. Consequently, experimentation systems need to be
robust to its effects. Furthermore, we note that it is nontrivial to measure
the absolute level of telemetry loss in an experimentation system. In this
paper, we take a top-down approach towards solving this problem. We motivate
the impact of loss qualitatively using experiments in real applications
deployed at scale, and formalize the problem by presenting a theoretical
breakdown of the bias introduced by loss. Based on this foundation, we present
a general framework for quantitatively evaluating the impact of telemetry loss,
and present two solutions to measure the absolute levels of loss. This
framework is used by well-known applications at Microsoft, with millions of
users and billions of sessions. These general principles can be adopted by any
application to improve the overall trustworthiness of experimentation and
data-driven decision making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupchup_J/0/1/0/all/0/1&quot;&gt;Jayant Gupchup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosseinkashi_Y/0/1/0/all/0/1&quot;&gt;Yasaman Hosseinkashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dmitriev_P/0/1/0/all/0/1&quot;&gt;Pavel Dmitriev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_D/0/1/0/all/0/1&quot;&gt;Daniel Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cutler_R/0/1/0/all/0/1&quot;&gt;Ross Cutler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jefremov_A/0/1/0/all/0/1&quot;&gt;Andrei Jefremov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ellis_M/0/1/0/all/0/1&quot;&gt;Martin Ellis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12472">
<title>Real-Time Remote Estimation with Hybrid ARQ in Wireless Networked Control. (arXiv:1903.12472v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1903.12472</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time remote estimation is critical for mission-critical applications
including industrial automation, smart grid and tactile Internet. In this
paper, we propose a hybrid automatic repeat request (HARQ)-based real-time
remote estimation framework for linear time-invariant (LTI) dynamic systems.
Considering the estimation quality of such a system, there is a fundamental
tradeoff between the reliability and freshness of the sensor&apos;s measurement
transmission. We formulate a new problem to optimize the sensor&apos;s online
transmission control policy for static and Markov fading channels, which
depends on both the current estimation quality of the remote estimator and the
current number of retransmissions of the sensor, so as to minimize the
long-term remote estimation mean squared error (MSE). This problem is
non-trivial. In particular, it is challenging to derive the condition in terms
of the communication channel quality and the LTI system parameters, to ensure a
bounded long-term estimation MSE. We derive an elegant sufficient condition of
the existence of a stationary and deterministic optimal policy that stabilizes
the remote estimation system and minimizes the MSE. Also, we prove that the
optimal policy has a switching structure, and accordingly derive a
low-complexity suboptimal policy. Numerical results show that the proposed
optimal policy significantly improves the performance of the remote estimation
system compared to the conventional non-HARQ policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wanchun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shirvanimoghaddam_M/0/1/0/all/0/1&quot;&gt;Mahyar Shirvanimoghaddam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yonghui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vucetic_B/0/1/0/all/0/1&quot;&gt;Branka Vucetic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12473">
<title>Shape Robust Text Detection with Progressive Scale Expansion Network. (arXiv:1903.12473v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12473</link>
<description rdf:parseType="Literal">&lt;p&gt;Scene text detection has witnessed rapid progress especially with the recent
development of convolutional neural networks. However, there still exists two
challenges which prevent the algorithm into industry applications. On the one
hand, most of the state-of-art algorithms require quadrangle bounding box which
is in-accurate to locate the texts with arbitrary shape. On the other hand, two
text instances which are close to each other may lead to a false detection
which covers both instances. Traditionally, the segmentation-based approach can
relieve the first problem but usually fail to solve the second challenge. To
address these two challenges, in this paper, we propose a novel Progressive
Scale Expansion Network (PSENet), which can precisely detect text instances
with arbitrary shapes. More specifically, PSENet generates the different scale
of kernels for each text instance, and gradually expands the minimal scale
kernel to the text instance with the complete shape. Due to the fact that there
are large geometrical margins among the minimal scale kernels, our method is
effective to split the close text instances, making it easier to use
segmentation-based methods to detect arbitrary-shaped text instances. Extensive
experiments on CTW1500, Total-Text, ICDAR 2015 and ICDAR 2017 MLT validate the
effectiveness of PSENet. Notably, on CTW1500, a dataset full of long curve
texts, PSENet achieves a F-measure of 74.3% at 27 FPS, and our best F-measure
(82.2%) outperforms state-of-art algorithms by 6.6%. The code will be released
in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenhai Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1&quot;&gt;Enze Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1&quot;&gt;Wenbo Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1&quot;&gt;Tong Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1&quot;&gt;Gang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1&quot;&gt;Shuai Shao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12476">
<title>DNA: Deeply-supervised Nonlinear Aggregation for Salient Object Detection. (arXiv:1903.12476v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12476</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress on salient object detection mainly aims at exploiting how to
effectively integrate multi-scale convolutional features in convolutional
neural networks (CNNs). Many state-of-the-art methods impose deep supervision
to perform side-output predictions that are linearly aggregated for final
saliency prediction. In this paper, we theoretically and experimentally
demonstrate that linear aggregation of side-output predictions is suboptimal,
and it only makes limited use of the side-output information obtained by deep
supervision. To solve this problem, we propose Deeply-supervised Nonlinear
Aggregation (DNA) for better leveraging the complementary information of
various side-outputs. Compared with existing methods, it i) aggregates
side-output features rather than predictions, and ii) adopts nonlinear instead
of linear transformations. Experiments demonstrate that DNA can successfully
break through the bottleneck of current linear approaches. Specifically, the
proposed saliency detector, a modified U-Net architecture with DNA, performs
favorably against state-of-the-art methods on various datasets and evaluation
metrics without bells and whistles. Code and data will be released upon paper
acceptance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1&quot;&gt;Deng-Ping Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_G/0/1/0/all/0/1&quot;&gt;Guang-Yu Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrosyan_V/0/1/0/all/0/1&quot;&gt;Vahan Petrosyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1&quot;&gt;Ming-Ming Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12480">
<title>Data-driven multiscale decompositions for forecasting and model discovery. (arXiv:1903.12480v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1903.12480</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a data-driven method for separating complex, multiscale systems
into their constituent time-scale components using a recursive implementation
of dynamic mode decomposition (DMD). Local linear models are built from
windowed subsets of the data, and dominant time scales are discovered using
spectral clustering on their eigenvalues. This approach produces time series
data for each identified component, which sum to a faithful reconstruction of
the input signal. It differs from most other methods in the field of
multiresolution analysis (MRA) in that it 1) accounts for spatial and temporal
coherencies simultaneously, making it more robust to scale overlap between
components, and 2) yields a closed-form expression for local dynamics at each
scale, which can be used for short-term prediction of any or all components.
Our technique is an extension of multi-resolution dynamic mode decomposition
(mrDMD), generalized to treat a broader variety of multiscale systems and more
faithfully reconstruct their isolated components. In this paper we present an
overview of our algorithm and its results on two example physical systems, and
briefly discuss some advantages and potential forecasting applications for the
technique.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dylewsky_D/0/1/0/all/0/1&quot;&gt;Daniel Dylewsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1&quot;&gt;Molei Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1&quot;&gt;J. Nathan Kutz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12482">
<title>COFFEE - An MPI-parallelized Python package for the numerical evolution of differential equations. (arXiv:1903.12482v1 [cs.MS])</title>
<link>http://arxiv.org/abs/1903.12482</link>
<description rdf:parseType="Literal">&lt;p&gt;COFFEE (ConFormal Field Equation Evolver) is a Python package primarily
developed to numerically evolve systems of partial differential equations over
time using the method of lines. It includes a variety of time integrators and
finite differencing stencils with the summation-by-parts property, as well as
pseudo-spectral functionality for angular derivatives of spin-weighted
functions. Some additional capabilities include being MPI-parallelisable on
avariety of different geometries, HDF data output and post processing scripts
to visualize data, and an actions class that allows users to create code for
analysis after each timestep.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doulis_G/0/1/0/all/0/1&quot;&gt;Georgios Doulis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frauendiener_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg Frauendiener&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stevens_C/0/1/0/all/0/1&quot;&gt;Chris Stevens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whale_B/0/1/0/all/0/1&quot;&gt;Ben Whale&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12483">
<title>Online Multi-target regression trees with stacked leaf models. (arXiv:1903.12483v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12483</link>
<description rdf:parseType="Literal">&lt;p&gt;The amount of available data raises at large steps. Developing machine
learning strategies to cope with the high throughput and changing data streams
is a scope of high relevance. Among the prediction tasks in online machine
learning, multi-target regression has gained increased attention due to its
high applicability and relation with real-world problems. While reliable and
effective solutions have been proposed for batch multi-target regression, the
few existing solutions in the online scenario present gaps which should be
further investigated. Among these problems, none of the existing solutions
consider the occurrence of inter-target correlations when making predictions.
In this work, we propose an extension to existing decision tree based solutions
in online multi-target regression which tackles the problem mentioned above.
Our proposal, called Stacked Single-target Hoeffding Tree (SST-HT) uses the
inter-target dependencies as an additional information source to enhance
accuracy. Throughout an extensive experimental setup, we evaluate our proposal
against state-of-the-art decision tree-based solutions for online multi-target
regression tasks on sixteen datasets. Our observations show that SST-HT is
capable of achieving significantly smaller errors than the other methods,
whereas only increasing the needed time and memory requirements in small
amounts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mastelini_S/0/1/0/all/0/1&quot;&gt;Saulo Martiello Mastelini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbon_S/0/1/0/all/0/1&quot;&gt;Sylvio Barbon Jr.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Carlos Ponce de Leon Ferreira de Carvalho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12487">
<title>Network Structure Effects in Reservoir Computers. (arXiv:1903.12487v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1903.12487</link>
<description rdf:parseType="Literal">&lt;p&gt;A reservoir computer is a complex nonlinear dynamical system that has been
shown to be useful for solving certain problems, such as prediction of chaotic
signals, speech recognition or control of robotic systems. Typically a
reservoir computer is constructed by connecting a large number of nonlinear
nodes in a network, driving the nodes with an input signal and using the node
outputs to fit a training signal. In this work, we set up reservoirs where the
edges (or connections) between all the network nodes are either +1 or 0, and
proceed to alter the network structure by flipping some of these edges from +1
to -1. We use this simple network because it turns out to be easy to
characterize; we may use the fraction of edges flipped as a measure of how much
we have altered the network. In some cases, the network can be rearranged in a
finite number of ways without changing its structure; these rearrangements are
symmetries of the network, and the number of symmetries is also useful for
characterizing the network. We find that changing the number of edges flipped
in the network changes the rank of the covariance of a matrix consisting of the
time series from the different nodes in the network, and speculate that this
rank is important for understanding the reservoir computer performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carroll_T/0/1/0/all/0/1&quot;&gt;Thomas L. Carroll&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pecora_L/0/1/0/all/0/1&quot;&gt;Louis M. Pecora&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12489">
<title>Cross-Subject Transfer Learning in Human Activity Recognition Systems using Generative Adversarial Networks. (arXiv:1903.12489v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12489</link>
<description rdf:parseType="Literal">&lt;p&gt;Application of intelligent systems especially in smart homes and
health-related topics has been drawing more attention in the last decades.
Training Human Activity Recognition (HAR) models -- as a major module --
requires a fair amount of labeled data. Despite training with large datasets,
most of the existing models will face a dramatic performance drop when they are
tested against unseen data from new users. Moreover, recording enough data for
each new user is unviable due to the limitations and challenges of working with
human users. Transfer learning techniques aim to transfer the knowledge which
has been learned from the source domain (subject) to the target domain in order
to decrease the models&apos; performance loss in the target domain. This paper
presents a novel method of adversarial knowledge transfer named SA-GAN stands
for Subject Adaptor GAN which utilizes Generative Adversarial Network framework
to perform cross-subject transfer learning in the domain of wearable
sensor-based Human Activity Recognition. SA-GAN outperformed other
state-of-the-art methods in more than 66% of experiments and showed the second
best performance in the remaining 25% of experiments. In some cases, it reached
up to 90% of the accuracy which can be obtained by supervised training over the
same domain data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soleimani_E/0/1/0/all/0/1&quot;&gt;Elnaz Soleimani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazerfard_E/0/1/0/all/0/1&quot;&gt;Ehsan Nazerfard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12493">
<title>Asymmetric Deep Semantic Quantization for Image Retrieval. (arXiv:1903.12493v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12493</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to its fast retrieval and storage efficiency capabilities, hashing has
been widely used in nearest neighbor retrieval tasks. By using deep learning
based techniques, hashing can outperform non-learning based hashing in many
applications. However, there are some limitations to previous learning based
hashing methods (e.g., the learned hash codes are not discriminative due to the
hashing methods being unable to discover rich semantic information and the
training strategy having difficulty optimizing the discrete binary codes). In
this paper, we propose a novel learning based hashing method, named
\textbf{\underline{A}}symmetric \textbf{\underline{D}}eep
\textbf{\underline{S}}emantic \textbf{\underline{Q}}uantization
(\textbf{ADSQ}). \textbf{ADSQ} is implemented using three stream frameworks,
which consists of one \emph{LabelNet} and two \emph{ImgNets}. The
\emph{LabelNet} leverages three fully-connected layers, which is used to
capture rich semantic information between image pairs. For the two
\emph{ImgNets}, they each adopt the same convolutional neural network
structure, but with different weights (i.e., asymmetric convolutional neural
networks). The two \emph{ImgNets} are used to generate discriminative compact
hash codes. Specifically, the function of the \emph{LabelNet} is to capture
rich semantic information that is used to guide the two \emph{ImgNets} in
minimizing the gap between the real-continuous features and discrete binary
codes. By doing this, \textbf{ADSQ} can make full use of the most critical
semantic information to guide the feature learning process and consider the
consistency of the common semantic space and Hamming space. Results from our
experiments demonstrate that \textbf{ADSQ} can generate high discriminative
compact hash codes and it outperforms current state-of-the-art methods on three
benchmark datasets, CIFAR-10, NUS-WIDE, and ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raymond_O/0/1/0/all/0/1&quot;&gt;Osolo Ian Raymond&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1&quot;&gt;WuQing Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1&quot;&gt;Jun Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12495">
<title>Crowd Sourced Data Analysis: Mapping of Programming Concepts to Syntactical Patterns. (arXiv:1903.12495v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1903.12495</link>
<description rdf:parseType="Literal">&lt;p&gt;Since programming concepts do not match their syntactic representations, code
search is a very tedious task. For instance in Java or C, array doesn&apos;t match
[], so using &quot;array&quot; as a query, one cannot find what they are looking for.
Often developers have to search code whether to understand any code, or to
reuse some part of that code, or just to read it, without natural language
searching, developers have to often scroll back and forth or use variable names
as their queries. In our work, we have used Stackoverflow (SO) question and
answers to make a mapping of programming concepts with their respective natural
language keywords, and then tag these natural language terms to every line of
code, which can further we used in searching using natural language keywords.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thukral_D/0/1/0/all/0/1&quot;&gt;Deepak Thukral&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Punia_D/0/1/0/all/0/1&quot;&gt;Darvesh Punia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12497">
<title>A Stochastic Model Predictive Control Approach for Driver-Aided Intersection Crossing With Uncertain Driver Time Delay. (arXiv:1903.12497v1 [math.OC])</title>
<link>http://arxiv.org/abs/1903.12497</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the problem of coordinating human-driven vehicles in road
intersections without any traffic lights or signs by issuing speed advices. The
vehicles in the intersection are assumed to move along an a priori known path
and to be connected via vehicle-to-vehicle communication. The challenge arises
with the uncertain driver reaction to a speed advice, especially in terms of
the driver reaction time delay, as it might lead to unstable system dynamics.
For this control problem, a distributed stochastic model predictive control
concept is designed which accounts for driver uncertainties. By optimizing over
scenarios, which are sequences of independent and identically distributed
samples of the uncertainty over the prediction horizon, we can give
probabilistic guarantees on constraint satisfaction. Simulation results
demonstrate that the scenario-based approach is able to avoid collisions in
spite of uncertainty while the non-stochastic baseline controller is not.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Katriniok_A/0/1/0/all/0/1&quot;&gt;Alexander Katriniok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kojchev_S/0/1/0/all/0/1&quot;&gt;Stefan Kojchev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lefeber_E/0/1/0/all/0/1&quot;&gt;Erjen Lefeber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nijmeijer_H/0/1/0/all/0/1&quot;&gt;Henk Nijmeijer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12505">
<title>BootKeeper: Validating Software Integrity Properties on Boot Firmware Images. (arXiv:1903.12505v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1903.12505</link>
<description rdf:parseType="Literal">&lt;p&gt;Boot firmware, like UEFI-compliant firmware, has been the target of numerous
attacks, giving the attacker control over the entire system while being
undetected. The measured boot mechanism of a computer platform ensures its
integrity by using cryptographic measurements to detect such attacks. This is
typically performed by relying on a Trusted Platform Module (TPM). Recent work,
however, shows that vendors do not respect the specifications that have been
devised to ensure the integrity of the firmware&apos;s loading process. As a result,
attackers may bypass such measurement mechanisms and successfully load a
modified firmware image while remaining unnoticed. In this paper we introduce
BootKeeper, a static analysis approach verifying a set of key security
properties on boot firmware images before deployment, to ensure the integrity
of the measured boot process. We evaluate BootKeeper against several attacks on
common boot firmware implementations and demonstrate its applicability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chevalier_R/0/1/0/all/0/1&quot;&gt;Ronny Chevalier&lt;/a&gt; (CIDRE), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cristalli_S/0/1/0/all/0/1&quot;&gt;Stefano Cristalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauser_C/0/1/0/all/0/1&quot;&gt;Christophe Hauser&lt;/a&gt; (USC), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shoshitaishvili_Y/0/1/0/all/0/1&quot;&gt;Yan Shoshitaishvili&lt;/a&gt; (ASU), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruoyu Wang&lt;/a&gt; (ASU), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kruegel_C/0/1/0/all/0/1&quot;&gt;Christopher Kruegel&lt;/a&gt; (CS-UCSB), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vigna_G/0/1/0/all/0/1&quot;&gt;Giovanni Vigna&lt;/a&gt; (CS-UCSB), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruschi_D/0/1/0/all/0/1&quot;&gt;Danilo Bruschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lanzi_A/0/1/0/all/0/1&quot;&gt;Andrea Lanzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12508">
<title>A Local Approach to Forward Model Learning: Results on the Game of Life Game. (arXiv:1903.12508v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1903.12508</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the effect of learning a forward model on the
performance of a statistical forward planning agent. We transform Conway&apos;s Game
of Life simulation into a single-player game where the objective can be either
to preserve as much life as possible or to extinguish all life as quickly as
possible.
&lt;/p&gt;
&lt;p&gt;In order to learn the forward model of the game, we formulate the problem in
a novel way that learns the local cell transition function by creating a set of
supervised training data and predicting the next state of each cell in the grid
based on its current state and immediate neighbours. Using this method we are
able to harvest sufficient data to learn perfect forward models by observing
only a few complete state transitions, using either a look-up table, a decision
tree or a neural network.
&lt;/p&gt;
&lt;p&gt;In contrast, learning the complete state transition function is a much harder
task and our initial efforts to do this using deep convolutional auto-encoders
were less successful.
&lt;/p&gt;
&lt;p&gt;We also investigate the effects of imperfect learned models on prediction
errors and game-playing performance, and show that even models with significant
errors can provide good performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucas_S/0/1/0/all/0/1&quot;&gt;Simon M. Lucas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dockhorn_A/0/1/0/all/0/1&quot;&gt;Alexander Dockhorn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volz_V/0/1/0/all/0/1&quot;&gt;Vanessa Volz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bamford_C/0/1/0/all/0/1&quot;&gt;Chris Bamford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaina_R/0/1/0/all/0/1&quot;&gt;Raluca D. Gaina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bravi_I/0/1/0/all/0/1&quot;&gt;Ivan Bravi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Liebana_D/0/1/0/all/0/1&quot;&gt;Diego Perez-Liebana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mostaghim_S/0/1/0/all/0/1&quot;&gt;Sanaz Mostaghim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kruse_R/0/1/0/all/0/1&quot;&gt;Rudolf Kruse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12509">
<title>Exploring Micro-Services for Enhancing Internet QoS. (arXiv:1903.12509v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1903.12509</link>
<description rdf:parseType="Literal">&lt;p&gt;With the enhancements in the field of software-defined networking and
virtualization technologies, novel networking paradigms such as network
function virtualization (NFV) and the Internet of things (IoT) are rapidly
gaining ground. Development of IoT as well as 5G networks and explosion in
online services has resulted in an exponential growth of devices connected to
the network. As a result, application service providers (ASPs) and Internet
service providers (ISPs) are being confronted with the unprecedented challenge
of accommodating increasing service and traffic demands from the geographically
distributed users. To tackle this problem, many ASPs and ISPs, such as Netflix,
Facebook, AT&amp;amp;T and others are increasingly adopting micro-services (MS)
application architecture. Despite the success of MS in the industry, there is
no specific standard or research work for service providers as guidelines,
especially from the perspective of basic micro-service operations. In this
work, we aim to bridge this gap between industry and academia and discuss
different micro-service deployment, discovery and communication options for
service providers as a means to forming complete service chains. In addition,
we address the problem of scheduling micro-services across multiple clouds,
including micro-clouds. We consider different user-level SLAs, such as latency
and cost, while scheduling such services. We aim to reduce overall turnaround
time as well as costs for the deployment of complete end-to-end service. In
this work, we present a novel affinity-based fair weighted scheduling heuristic
to solve this problem. We also compare the results of proposed solution with
standard greedy scheduling algorithms presented in the literature and observe
significant improvements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhamare_D/0/1/0/all/0/1&quot;&gt;Deval Bhamare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samaka_M/0/1/0/all/0/1&quot;&gt;Mohammed Samaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1&quot;&gt;Aiman Erbad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1&quot;&gt;Raj Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_L/0/1/0/all/0/1&quot;&gt;Lav Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12510">
<title>Degrees of Laziness in Grounding: Effects of Lazy-Grounding Strategies on ASP Solving. (arXiv:1903.12510v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1903.12510</link>
<description rdf:parseType="Literal">&lt;p&gt;The traditional ground-and-solve approach to Answer Set Programming (ASP)
suffers from the grounding bottleneck, which makes large-scale problem
instances unsolvable. Lazy grounding is an alternative approach that
interleaves grounding with solving and thus uses space more efficiently. The
limited view on the search space in lazy grounding poses unique challenges,
however, and can have adverse effects on solving performance. In this paper we
present a novel characterization of degrees of laziness in grounding for ASP,
i.e. of compromises between lazily grounding as little as possible and the
traditional full grounding upfront. We investigate how these degrees of
laziness compare to each other formally as well as, by means of an experimental
analysis using a number of benchmarks, in terms of their effects on solving
performance. Our contributions are the introduction of a range of novel lazy
grounding strategies, a formal account on their relationships and their
correctness, and an investigation of their effects on solving performance.
Experiments show that our approach performs significantly better than
state-of-the-art lazy grounding in many cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taupe_R/0/1/0/all/0/1&quot;&gt;Richard Taupe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinzierl_A/0/1/0/all/0/1&quot;&gt;Antonius Weinzierl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedrich_G/0/1/0/all/0/1&quot;&gt;Gerhard Friedrich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12514">
<title>Evaluating Built-in ECC of FPGA on-chip Memories for the Mitigation of Undervolting Faults. (arXiv:1903.12514v1 [cs.AR])</title>
<link>http://arxiv.org/abs/1903.12514</link>
<description rdf:parseType="Literal">&lt;p&gt;Voltage underscaling below the nominal level is an effective solution for
improving energy efficiency in digital circuits, e.g., Field Programmable Gate
Arrays (FPGAs). However, further undervolting below a safe voltage level and
without accompanying frequency scaling leads to timing related faults,
potentially undermining the energy savings. Through experimental voltage
underscaling studies on commercial FPGAs, we observed that the rate of these
faults exponentially increases for on-chip memories, or Block RAMs (BRAMs). To
mitigate these faults, we evaluated the efficiency of the built-in
Error-Correction Code (ECC) and observed that more than 90% of the faults are
correctable and further 7% are detectable (but not correctable). This
efficiency is the result of the single-bit type of these faults, which are then
effectively covered by the Single-Error Correction and Double-Error Detection
(SECDED) design of the built-in ECC. Finally, motivated by the above
experimental observations, we evaluated an FPGA-based Neural Network (NN)
accelerator under low-voltage operations, while built-in ECC is leveraged to
mitigate undervolting faults and thus, prevent NN significant accuracy loss. In
consequence, we achieve 40% of the BRAM power saving through undervolting below
the minimum safe voltage level, with a negligible NN accuracy loss, thanks to
the substantial fault coverage by the built-in ECC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salami_B/0/1/0/all/0/1&quot;&gt;Behzad Salami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Unsal_O/0/1/0/all/0/1&quot;&gt;Osman S. Unsal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kestelman_A/0/1/0/all/0/1&quot;&gt;Adrian Cristal Kestelman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12516">
<title>Ham-Sandwich cuts and center transversals in subspaces. (arXiv:1903.12516v1 [cs.CG])</title>
<link>http://arxiv.org/abs/1903.12516</link>
<description rdf:parseType="Literal">&lt;p&gt;The Ham-Sandwich theorem is a well-known result in geometry. It states that
any $d$ mass distributions in $\mathbb{R}^d$ can be simultaneously bisected by
a hyperplane. The result is tight, that is, there are examples of $d+1$ mass
distributions that cannot be simultaneously bisected by a single hyperplane. In
this abstract we will study the following question: given a continuous
assignment of mass distributions to certain subsets of $\mathbb{R}^d$, is there
a subset on which we can bisect more masses than what is guaranteed by the
Ham-Sandwich theorem?
&lt;/p&gt;
&lt;p&gt;We investigate two types of subsets. The first type are linear subspaces of
$\mathbb{R}^d$, i.e., $k$-dimensional flats containing the origin. We show that
for any continuous assignment of $d$ mass distributions to the $k$-dimensional
linear subspaces of $\mathbb{R}^d$, there is always a subspace on which we can
simultaneously bisect the images of all $d$ assignments. We extend this result
to center transversals, a generalization of Ham-Sandwich cuts. As for
Ham-Sandwich cuts, we further show that for $d-k+2$ masses, we can choose $k-1$
of the vectors defining the $k$-dimensional subspace in which the solution
lies.
&lt;/p&gt;
&lt;p&gt;The second type of subsets we consider are subsets that are determined by
families of $n$ hyperplanes in $\mathbb{R}^d$. Also in this case, we find a
Ham-Sandwich-type result. In an attempt to solve a conjecture by Langerman
about bisections with several cuts, we show that our underlying topological
result can be used to prove this conjecture in a relaxed setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schnider_P/0/1/0/all/0/1&quot;&gt;Patrick Schnider&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12517">
<title>Towards Brain-inspired System: Deep Recurrent Reinforcement Learning for Simulated Self-driving Agent. (arXiv:1903.12517v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1903.12517</link>
<description rdf:parseType="Literal">&lt;p&gt;An effective way to achieve intelligence is to simulate various intelligent
behaviors in the human brain. In recent years, bio-inspired learning methods
have emerged, and they are different from the classical mathematical
programming principle. In the perspective of brain inspiration, reinforcement
learning has gained additional interest in solving decision-making tasks as
increasing neuroscientific research demonstrates that significant links exist
between reinforcement learning and specific neural substrates. Because of the
tremendous research that focuses on human brains and reinforcement learning,
scientists have investigated how robots can autonomously tackle complex tasks
in the form of a self-driving agent control in a human-like way. In this study,
we propose an end-to-end architecture using novel deep-Q-network architecture
in conjunction with a recurrence to resolve the problem in the field of
simulated self-driving. The main contribution of this study is that we trained
the driving agent using a brain-inspired trial-and-error technique, which was
in line with the real world situation. Besides, there are three innovations in
the proposed learning network: raw screen outputs are the only information
which the driving agent can rely on, a weighted layer that enhances the
differences of the lengthy episode, and a modified replay mechanism that
overcomes the problem of sparsity and accelerates learning. The proposed
network was trained and tested under a third-partied OpenAI Gym environment.
After training for several episodes, the resulting driving agent performed
advanced behaviors in the given scene. We hope that in the future, the proposed
brain-inspired learning system would inspire practicable self-driving control
solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jieneng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jingye Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruiming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xiaobin Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12519">
<title>A Provable Defense for Deep Residual Networks. (arXiv:1903.12519v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12519</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a training system, which can provably defend significantly larger
neural networks than previously possible, including ResNet-34 and DenseNet-100.
Our approach is based on differentiable abstract interpretation and introduces
two novel concepts: (i) abstract layers for fine-tuning the precision and
scalability of the abstraction, (ii) a flexible domain specific language (DSL)
for describing training objectives that combine abstract and concrete losses
with arbitrary specifications. Our training method is implemented in the DiffAI
system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirman_M/0/1/0/all/0/1&quot;&gt;Matthew Mirman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1&quot;&gt;Gagandeep Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1&quot;&gt;Martin Vechev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12520">
<title>Multimodal Emotion Classification. (arXiv:1903.12520v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12520</link>
<description rdf:parseType="Literal">&lt;p&gt;Most NLP and Computer Vision tasks are limited to scarcity of labelled data.
In social media emotion classification and other related tasks, hashtags have
been used as indicators to label data. With the rapid increase in emoji usage
of social media, emojis are used as an additional feature for major social NLP
tasks. However, this is less explored in case of multimedia posts on social
media where posts are composed of both image and text. At the same time, w.e
have seen a surge in the interest to incorporate domain knowledge to improve
machine understanding of text. In this paper, we investigate whether domain
knowledge for emoji can improve the accuracy of emotion classification task. We
exploit the importance of different modalities from social media post for
emotion classification task using state-of-the-art deep learning architectures.
Our experiments demonstrate that the three modalities (text, emoji and images)
encode different information to express emotion and therefore can complement
each other. Our results also demonstrate that emoji sense depends on the
textual context, and emoji combined with text encodes better information than
considered separately. The highest accuracy of 71.98\% is achieved with a
training data of 550k posts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Illendula_A/0/1/0/all/0/1&quot;&gt;Anurag Illendula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1&quot;&gt;Amit Sheth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12525">
<title>Shed More Light on Bloom Filter&apos;s Variants. (arXiv:1903.12525v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1903.12525</link>
<description rdf:parseType="Literal">&lt;p&gt;Bloom Filter is a probabilistic membership data structure and it is
excessively used data structure for membership query. Bloom Filter becomes the
predominant data structure in approximate membership filtering. Bloom Filter
extremely enhances the query response time, and the response time is very fast.
Bloom filter (BF) is used to detect whether an element belongs to a given set
or not. The Bloom Filter returns True Positive (TP), False Positive (FP), or
True Negative (TN). The Bloom Filter is widely adapted in numerous areas to
enhance the performance of a system. In this paper, we present a) in-depth
insight on the Bloom Filter,and b) the prominent variants of the Bloom Filters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patgiri_R/0/1/0/all/0/1&quot;&gt;Ripon Patgiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nayak_S/0/1/0/all/0/1&quot;&gt;Sabuzima Nayak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borgohain_S/0/1/0/all/0/1&quot;&gt;Samir Kumar Borgohain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12527">
<title>An Upper Bound for Minimum True Matches in Graph Isomorphism with Simulated Annealing. (arXiv:1903.12527v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1903.12527</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph matching is one of the most important problems in graph theory and
combinatorial optimization, with many applications in various domains. Although
meta-heuristic algorithms have had good performance on many NP-Hard and
NP-Complete problems, for this problem there are not reported superior
solutions by these algorithms. The reason of this inefficiency has not been
investigated yet. In this paper we show that simulated annealing as an
stochastic optimization method is unlikely to be even close to the optimal
solution for this problem. In addition to theoretical discussion, the
experimental results also verified our idea; for example, in two sample graphs,
the probability of reaching to a solution with more than three correct matches
is about $0.02$ in simulated annealing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ezzati_H/0/1/0/all/0/1&quot;&gt;Hashem Ezzati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amintoosi_M/0/1/0/all/0/1&quot;&gt;Mahmood Amintoosi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabasi_H/0/1/0/all/0/1&quot;&gt;Hashem Tabasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12529">
<title>Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels. (arXiv:1903.12529v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12529</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep neural networks (DNN) based single image super-resolution (SISR)
methods are rapidly gaining popularity, they are mainly designed for the
widely-used bicubic degradation, and there still remains the fundamental
challenge for them to super-resolve low-resolution (LR) image with arbitrary
blur kernels. In the meanwhile, plug-and-play image restoration has been
recognized with high flexibility due to its modular structure for easy plug-in
of denoiser priors. In this paper, we propose a principled formulation and
framework by extending bicubic degradation based deep SISR with the help of
plug-and-play framework to handle LR images with arbitrary blur kernels.
Specifically, we design a new SISR degradation model so as to take advantage of
existing blind deblurring methods for blur kernel estimation. To optimize the
new degradation induced energy function, we then derive a plug-and-play
algorithm via variable splitting technique, which allows us to plug any
super-resolver prior rather than the denoiser prior as a modular part.
Quantitative and qualitative evaluations on synthetic and real LR images
demonstrate that the proposed deep plug-and-play super-resolution framework is
flexible and effective to deal with blurry LR images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1&quot;&gt;Wangmeng Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12530">
<title>Photo-realistic Monocular Gaze Redirection using Generative Adversarial Networks. (arXiv:1903.12530v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12530</link>
<description rdf:parseType="Literal">&lt;p&gt;Gaze redirection is the task of changing the gaze to a desired direction for
a given monocular eye patch image. Many applications such as videoconferencing,
films and games, and generation of training data for gaze estimation require
redirecting the gaze, without distorting the appearance of the area surrounding
the eye and while producing photo-realistic images. Existing methods lack the
ability to generate perceptually plausible images. In this work, we present a
novel method to alleviate this problem by leveraging generative adversarial
training to synthesize an eye image conditioned on a target gaze direction. Our
method ensures perceptual similarity and consistency of synthesized images to
the real images. Furthermore, a gaze estimation loss is used to control the
gaze direction accurately. To attain high-quality images, we incorporate
perceptual and cycle consistency losses into our architecture. In extensive
evaluations we show that the proposed method outperforms state-of-the-art
approaches in terms of both image quality and redirection precision. Finally,
we show that generated images can bring significant improvement for the gaze
estimation task if used to augment real training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhe He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1&quot;&gt;Adrian Spurr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xucong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1&quot;&gt;Otmar Hilliges&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12536">
<title>Deep Network for Capacitive ECG Denoising. (arXiv:1903.12536v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12536</link>
<description rdf:parseType="Literal">&lt;p&gt;Continuous monitoring of cardiac health under free living condition is
crucial to provide effective care for patients undergoing post operative
recovery and individuals with high cardiac risk like the elderly. Capacitive
Electrocardiogram (cECG) is one such technology which allows comfortable and
long term monitoring through its ability to measure biopotential in conditions
without having skin contact. cECG monitoring can be done using many household
objects like chairs, beds and even car seats allowing for seamless monitoring
of individuals. This method is unfortunately highly susceptible to motion
artifacts which greatly limits its usage in clinical practice. The current use
of cECG systems has been limited to performing rhythmic analysis. In this paper
we propose a novel end-to-end deep learning architecture to perform the task of
denoising capacitive ECG. The proposed network is trained using motion
corrupted three channel cECG and a reference LEAD I ECG collected on
individuals while driving a car. Further, we also propose a novel joint loss
function to apply loss on both signal and frequency domain. We conduct
extensive rhythmic analysis on the model predictions and the ground truth. We
further evaluate the signal denoising using Mean Square Error(MSE) and Cross
Correlation between model predictions and ground truth. We report MSE of 0.167
and Cross Correlation of 0.476. The reported results highlight the feasibility
of performing morphological analysis using the filtered cECG. The proposed
approach can allow for continuous and comprehensive monitoring of the
individuals in free living conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravichandran_V/0/1/0/all/0/1&quot;&gt;Vignesh Ravichandran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murugesan_B/0/1/0/all/0/1&quot;&gt;Balamurali Murugesan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shankaranarayana_S/0/1/0/all/0/1&quot;&gt;Sharath M Shankaranarayana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ram_K/0/1/0/all/0/1&quot;&gt;Keerthi Ram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+P_P/0/1/0/all/0/1&quot;&gt;Preejith S.P&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joseph_J/0/1/0/all/0/1&quot;&gt;Jayaraj Joseph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sivaprakasam_M/0/1/0/all/0/1&quot;&gt;Mohanasankar Sivaprakasam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12542">
<title>Re-Ranking Words to Improve Interpretability of Automatically Generated Topics. (arXiv:1903.12542v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12542</link>
<description rdf:parseType="Literal">&lt;p&gt;Topics models, such as LDA, are widely used in Natural Language Processing.
Making their output interpretable is an important area of research with
applications to areas such as the enhancement of exploratory search interfaces
and the development of interpretable machine learning models. Conventionally,
topics are represented by their n most probable words, however, these
representations are often difficult for humans to interpret. This paper
explores the re-ranking of topic words to generate more interpretable topic
representations. A range of approaches are compared and evaluated in two
experiments. The first uses crowdworkers to associate topics represented by
different word rankings with related documents. The second experiment is an
automatic approach based on a document retrieval task applied on multiple
domains. Results in both experiments demonstrate that re-ranking words improves
topic interpretability and that the most effective re-ranking schemes were
those which combine information about the importance of words both within
topics and their relative frequency in the entire corpus. In addition, close
correlation between the results of the two evaluation approaches suggests that
the automatic method proposed here could be used to evaluate re-ranking methods
without the need for human judgements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alokaili_A/0/1/0/all/0/1&quot;&gt;Areej Alokaili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1&quot;&gt;Nikolaos Aletras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stevenson_M/0/1/0/all/0/1&quot;&gt;Mark Stevenson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12546">
<title>Robust Data Detection for MIMO Systems with One-Bit ADCs: A Reinforcement Learning Approach. (arXiv:1903.12546v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1903.12546</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of one-bit analog-to-digital converters (ADCs) at a receiver is a
power-efficient solution for future wireless systems operating with a large
signal bandwidth and/or a massive number of receive radio frequency chains.
This solution, however, induces a high channel estimation error and therefore
makes it difficult to perform the optimal data detection that requires perfect
knowledge of likelihood functions at the receiver. In this paper, we propose a
likelihood function learning method for multiple-input multiple-output (MIMO)
systems with one-bit ADCs using a reinforcement learning approach. The key idea
is to exploit input-output samples obtained from data detection, to compensate
the mismatch in the likelihood function. The underlying difficulty of this idea
is a label uncertainty in the samples caused by a data detection error. To
resolve this problem, we define a Markov decision process (MDP) to maximize the
accuracy of the likelihood function learned from the samples. We then develop a
reinforcement learning algorithm that efficiently finds the optimal policy by
approximating the transition function and the optimal state of the MDP.
Simulation results demonstrate that the proposed method provides significant
performance gains for the optimal data detection methods that suffer from the
mismatch in the likelihood function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jeon_Y/0/1/0/all/0/1&quot;&gt;Yo-Seb Jeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Lee_N/0/1/0/all/0/1&quot;&gt;Namyoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Poor_H/0/1/0/all/0/1&quot;&gt;H. Vincent Poor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12549">
<title>Probabilistic Forecasting of Sensory Data with Generative Adversarial Networks - ForGAN. (arXiv:1903.12549v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12549</link>
<description rdf:parseType="Literal">&lt;p&gt;Time series forecasting is one of the challenging problems for humankind.
Traditional forecasting methods using mean regression models have severe
shortcomings in reflecting real-world fluctuations. While new probabilistic
methods rush to rescue, they fight with technical difficulties like quantile
crossing or selecting a prior distribution. To meld the different strengths of
these fields while avoiding their weaknesses as well as to push the boundary of
the state-of-the-art, we introduce ForGAN - one step ahead probabilistic
forecasting with generative adversarial networks. ForGAN utilizes the power of
the conditional generative adversarial network to learn the data generating
distribution and compute probabilistic forecasts from it. We argue how to
evaluate ForGAN in opposition to regression methods. To investigate
probabilistic forecasting of ForGAN, we create a new dataset and demonstrate
our method abilities on it. This dataset will be made publicly available for
comparison. Furthermore, we test ForGAN on two publicly available datasets,
namely Mackey-Glass dataset and Internet traffic dataset (A5M) where the
impressive performance of ForGAN demonstrate its high capability in forecasting
future values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koochali_A/0/1/0/all/0/1&quot;&gt;Alireza Koochali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schichtel_P/0/1/0/all/0/1&quot;&gt;Peter Schichtel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Sheraz Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1&quot;&gt;Andreas Dengel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12551">
<title>What obstruct customer acceptance of internet banking? Security and privacy, risk, trust and website usability and the role of moderators. (arXiv:1903.12551v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1903.12551</link>
<description rdf:parseType="Literal">&lt;p&gt;Comparatively a little attention has been paid to the factors that obstruct
the acceptance of Internet banking in Sri Lanka. This research assimilates
constructs such as security and privacy, perceived trust, perceived risk, and
website usability. To test the conceptual model, we collected 186 valid
responses from customers who use Internet banking in Sri Lanka. The structural
equation modelling technique is applied and hypotheses are validated. The
findings show perceived trust and website usability are the possible
obstructing factors that highly concerned by Internet banking customers. While
security and privacy, and perceived risk are not significant and these are not
highly concerned by customers in Internet banking acceptance. The age and
gender reveal the moderating effect in each exogenous latent constructs
relationship. The practical and managerial implications of the findings are
also discussed. This country specific study contributes to the advancement of
Internet banking acceptance, and offers some useful insights to researchers,
practitioners and policy makers on how to enhance Internet banking acceptance
for country similar in context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilmudeen_A/0/1/0/all/0/1&quot;&gt;Aboobucker Ilmudeen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1&quot;&gt;Yukun Bao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12552">
<title>On the Capacity of Private Information Retrieval from Coded, Colluding, and Adversarial Servers. (arXiv:1903.12552v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1903.12552</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we first prove the capacity of coded, linear symmetric private
information retrieval (SPIR) in the presence of colluding, adversarial, and
nonresponsive servers, giving a positive closure to the conjecture stated by
Tajeddine et al. It is also shown that, further restricting to strongly-linear
PIR schemes with linear interference cancellation, the so-called star product
scheme proposed by Freij-Hollanti et al. is optimal. This observation enables
to prove the capacity of strongly-linear (non-symmetric) PIR schemes for any
number of files. Further, it also provides a positive proof in this practical
special case for the conjectures stated in the asymptotic regime by
Freij-Hollanti et al. and Tajeddine et al.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holzbaur_L/0/1/0/all/0/1&quot;&gt;Lukas Holzbaur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freij_Hollanti_R/0/1/0/all/0/1&quot;&gt;Ragnar Freij-Hollanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hollanti_C/0/1/0/all/0/1&quot;&gt;Camilla Hollanti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12553">
<title>A survey of blockchain frameworks and applications. (arXiv:1903.12553v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1903.12553</link>
<description rdf:parseType="Literal">&lt;p&gt;The applications of the blockchain technology are still being discov-ered.
When a new potential disruptive technology emerges, there is a tendency to try
to solve every problem with that technology. However, it is still necessary to
determine what approach is the best for each type of application. To find how
distributed ledgers solve existing problems, this study looks for blockchain
frameworks in the academic world. Identifying the existing frameworks can
demonstrate where the interest in the technology exists and where it can be
miss-ing. This study encountered several blockchain frameworks in development.
However, there are few references to operational needs, testing, and deploy of
the technology. With the widespread use of the technology, either integrating
with pre-existing solutions, replacing legacy systems, or new implementations,
the need for testing, deploying, exploration, and maintenance is expected to
in-tensify.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tavares_B/0/1/0/all/0/1&quot;&gt;Bruno Tavares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Correia_F/0/1/0/all/0/1&quot;&gt;Filipe Figueiredo Correia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Restivo_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Restivo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faria_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Pascoal Faria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aguiar_A/0/1/0/all/0/1&quot;&gt;Ademar Aguiar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12554">
<title>Linked Open Data Validity -- A Technical Report from ISWS 2018. (arXiv:1903.12554v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1903.12554</link>
<description rdf:parseType="Literal">&lt;p&gt;Linked Open Data (LOD) is the publicly available RDF data in the Web. Each
LOD entity is identfied by a URI and accessible via HTTP. LOD encodes
globalscale knowledge potentially available to any human as well as artificial
intelligence that may want to benefit from it as background knowledge for
supporting their tasks. LOD has emerged as the backbone of applications in
diverse fields such as Natural Language Processing, Information Retrieval,
Computer Vision, Speech Recognition, and many more. Nevertheless, regardless of
the specific tasks that LOD-based tools aim to address, the reuse of such
knowledge may be challenging for diverse reasons, e.g. semantic heterogeneity,
provenance, and data quality. As aptly stated by Heath et al. Linked Data might
be outdated, imprecise, or simply wrong&quot;: there arouses a necessity to
investigate the problem of linked data validity. This work reports a
collaborative effort performed by nine teams of students, guided by an equal
number of senior researchers, attending the International Semantic Web Research
School (ISWS 2018) towards addressing such investigation from different
perspectives coupled with different approaches to tackle the issue.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghor_T/0/1/0/all/0/1&quot;&gt;Tayeb Abderrahmani Ghor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_E/0/1/0/all/0/1&quot;&gt;Esha Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1&quot;&gt;Mehwish Alam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alqawasmeh_O/0/1/0/all/0/1&quot;&gt;Omar Alqawasmeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damato_C/0/1/0/all/0/1&quot;&gt;Claudia D&amp;#x27;amato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Annane_A/0/1/0/all/0/1&quot;&gt;Amina Annane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azzam_A/0/1/0/all/0/1&quot;&gt;Amr Azzam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berezovskyi_A/0/1/0/all/0/1&quot;&gt;Andrew Berezovskyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biswas_R/0/1/0/all/0/1&quot;&gt;Russa Biswas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonduel_M/0/1/0/all/0/1&quot;&gt;Mathias Bonduel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brabant_Q/0/1/0/all/0/1&quot;&gt;Quentin Brabant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bucur_C/0/1/0/all/0/1&quot;&gt;Cristina-iulia Bucur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camossi_E/0/1/0/all/0/1&quot;&gt;Elena Camossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carriero_V/0/1/0/all/0/1&quot;&gt;Valentina Anita Carriero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chari_S/0/1/0/all/0/1&quot;&gt;Shruthi Chari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fraga_D/0/1/0/all/0/1&quot;&gt;David Chaves Fraga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciroku_F/0/1/0/all/0/1&quot;&gt;Fiorela Ciroku&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1&quot;&gt;Michael Cochez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Curien_H/0/1/0/all/0/1&quot;&gt;Hubert Curien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cutrona_V/0/1/0/all/0/1&quot;&gt;Vincenzo Cutrona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dandan_R/0/1/0/all/0/1&quot;&gt;Rahma Dandan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dess_D/0/1/0/all/0/1&quot;&gt;Danilo Dess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlo_V/0/1/0/all/0/1&quot;&gt;Valerio Di Carlo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Djebri_A/0/1/0/all/0/1&quot;&gt;Ahmed El Amine Djebri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erp_M/0/1/0/all/0/1&quot;&gt;Marieke Van Erp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Falakh_F/0/1/0/all/0/1&quot;&gt;Faiq Miftakhul Falakh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izquierdo_A/0/1/0/all/0/1&quot;&gt;Alba Fernndez Izquierdo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Futia_G/0/1/0/all/0/1&quot;&gt;Giuseppe Futia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gangemi_A/0/1/0/all/0/1&quot;&gt;Aldo Gangemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasperoni_S/0/1/0/all/0/1&quot;&gt;Simone Gasperoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grall_A/0/1/0/all/0/1&quot;&gt;Arnaud Grall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heling_L/0/1/0/all/0/1&quot;&gt;Lars Heling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henri_P/0/1/0/all/0/1&quot;&gt;Pierre Henri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herradi_N/0/1/0/all/0/1&quot;&gt;Noura Herradi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Issa_S/0/1/0/all/0/1&quot;&gt;Subhi Issa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jozashoori_S/0/1/0/all/0/1&quot;&gt;Samaneh Jozashoori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juniarta_N/0/1/0/all/0/1&quot;&gt;Nyoman Juniarta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaffee_L/0/1/0/all/0/1&quot;&gt;Lucie-aime Kaffee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keles_I/0/1/0/all/0/1&quot;&gt;Ilkcan Keles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khare_P/0/1/0/all/0/1&quot;&gt;Prashant Khare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovtun_V/0/1/0/all/0/1&quot;&gt;Viktor Kovtun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leone_V/0/1/0/all/0/1&quot;&gt;Valentina Leone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Siying Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lieber_S/0/1/0/all/0/1&quot;&gt;Sven Lieber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lisena_P/0/1/0/all/0/1&quot;&gt;Pasquale Lisena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makhalova_T/0/1/0/all/0/1&quot;&gt;Tatiana Makhalova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marinucci_L/0/1/0/all/0/1&quot;&gt;Ludovica Marinucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minier_T/0/1/0/all/0/1&quot;&gt;Thomas Minier&lt;/a&gt;, et al. (23 additional authors not shown)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12556">
<title>Capacity of Quantum Private Information Retrieval with Collusion of All But One of Servers. (arXiv:1903.12556v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1903.12556</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum private information retrieval (QPIR) is the problem to retrieve one
of $\mathsf{f}$ classical files by downloading quantum systems from
non-communicating $\mathsf{n}$ servers each of which contains the copy of
$\mathsf{f}$ files, while the identity of the retrieving file is unknown to
each server. As an extension, we consider the colluded QPIR that the identity
of the retrieving file is secret even if any $\mathsf{n}-1$ servers collude,
and derive the QPIR capacity for this problem which is defined as the maximum
rate of the retrieving file size over the download size. For an even number
$\mathsf{n}$ of servers, we show that the capacity of the colluded QPIR is
$2/\mathsf{n}$, when we assume that there are preexisting entanglements among
the servers and require that no information of the non-retrieving files is
retrieved. We construct a colluded QPIR protocol of rate
$\lceil\mathsf{n}/2\rceil^{-1}$ and prove that the capacity is upper bounded by
$2/\mathsf{n}$. The colluded QPIR capacity is strictly higher than the
classical counterpart.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Seunghoan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Hayashi_M/0/1/0/all/0/1&quot;&gt;Masahito Hayashi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12561">
<title>Second Rethinking of Network Pruning in the Adversarial Setting. (arXiv:1903.12561v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12561</link>
<description rdf:parseType="Literal">&lt;p&gt;It is well known that deep neural networks (DNNs) are vulnerable to
adversarial attacks, which are implemented by adding crafted perturbations onto
benign examples. Min-max robust optimization based adversarial training can
provide a notion of security against adversarial attacks. However, adversarial
robustness requires a significantly larger capacity of the network than that
for the natural training with only benign examples. This paper proposes a
framework of concurrent adversarial training and weight pruning that enables
model compression while still preserving the adversarial robustness and
essentially tackles the dilemma of adversarial training. Furthermore, this work
studies two hypotheses about weight pruning in the conventional network pruning
setting and finds that weight pruning is essential for reducing the network
model size in the adversarial setting, i.e., training a small model from
scratch even with inherited initialization from the large model cannot achieve
both adversarial robustness and model compression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1&quot;&gt;Shaokai Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kaidi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1&quot;&gt;Hao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lambrechts_J/0/1/0/all/0/1&quot;&gt;Jan-Henrik Lambrechts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Aojun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1&quot;&gt;Kaisheng Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xue Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12564">
<title>Infinite Brain MR Images: PGGAN-based Data Augmentation for Tumor Detection. (arXiv:1903.12564v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12564</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the lack of available annotated medical images, accurate
computer-assisted diagnosis requires intensive Data Augmentation (DA)
techniques, such as geometric/intensity transformations of original images;
however, those transformed images intrinsically have a similar distribution to
the original ones, leading to limited performance improvement. To fill the data
lack in the real image distribution, we synthesize brain contrast-enhanced
Magnetic Resonance (MR) images---realistic but completely different from the
original ones---using Generative Adversarial Networks (GANs). This study
exploits Progressive Growing of GANs (PGGANs), a multi-stage generative
training method, to generate original-sized 256 X 256 MR images for
Convolutional Neural Network-based brain tumor detection, which is challenging
via conventional GANs; difficulties arise due to unstable GAN training with
high resolution and a variety of tumors in size, location, shape, and contrast.
Our preliminary results show that this novel PGGAN-based DA method can achieve
promising performance improvement, when combined with classical DA, in tumor
detection and also in other medical imaging tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1&quot;&gt;Changhee Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rundo_L/0/1/0/all/0/1&quot;&gt;Leonardo Rundo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Araki_R/0/1/0/all/0/1&quot;&gt;Ryosuke Araki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1&quot;&gt;Yujiro Furukawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mauri_G/0/1/0/all/0/1&quot;&gt;Giancarlo Mauri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakayama_H/0/1/0/all/0/1&quot;&gt;Hideki Nakayama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayashi_H/0/1/0/all/0/1&quot;&gt;Hideaki Hayashi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12570">
<title>Sparse graphs are near-bipartite. (arXiv:1903.12570v1 [math.CO])</title>
<link>http://arxiv.org/abs/1903.12570</link>
<description rdf:parseType="Literal">&lt;p&gt;A multigraph $G$ is near-bipartite if $V(G)$ can be partitioned as $I,F$ such
that $I$ is an independent set and $F$ induces a forest. We prove that a
multigraph $G$ is near-bipartite when $3|W|-2|E(G[W])|\ge -1$ for every
$W\subseteq V(G)$, and $G$ contains no $K_4$ and no Moser spindle. We prove
that a simple graph $G$ is near-bipartite when $8|W|-5|E(G[W])|\ge -4$ for
every $W\subseteq V(G)$, and $G$ contains no subgraph from some finite family
$\mathcal{H}$. We also construct infinite families to show that both results
are best possible in a very sharp sense.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cranston_D/0/1/0/all/0/1&quot;&gt;Daniel W. Cranston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yancey_M/0/1/0/all/0/1&quot;&gt;Matthew P. Yancey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12571">
<title>CNN-based Prostate Zonal Segmentation on T2-weighted MR Images: A Cross-dataset Study. (arXiv:1903.12571v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12571</link>
<description rdf:parseType="Literal">&lt;p&gt;Prostate cancer is the most common cancer among US men. However, prostate
imaging is still challenging despite the advances in multi-parametric Magnetic
Resonance Imaging (MRI), which provides both morphologic and functional
information pertaining to the pathological regions. Along with whole prostate
gland segmentation, distinguishing between the Central Gland (CG) and
Peripheral Zone (PZ) can guide towards differential diagnosis, since the
frequency and severity of tumors differ in these regions; however, their
boundary is often weak and fuzzy. This work presents a preliminary study on
Deep Learning to automatically delineate the CG and PZ, aiming at evaluating
the generalization ability of Convolutional Neural Networks (CNNs) on two
multi-centric MRI prostate datasets. Especially, we compared three CNN-based
architectures: SegNet, U-Net, and pix2pix. In such a context, the segmentation
performances achieved with/without pre-training were compared in 4-fold
cross-validation. In general, U-Net outperforms the other methods, especially
when training and testing are performed on multiple datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rundo_L/0/1/0/all/0/1&quot;&gt;Leonardo Rundo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1&quot;&gt;Changhee Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hataya_R/0/1/0/all/0/1&quot;&gt;Ryuichiro Hataya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagano_Y/0/1/0/all/0/1&quot;&gt;Yudai Nagano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Militello_C/0/1/0/all/0/1&quot;&gt;Carmelo Militello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferretti_C/0/1/0/all/0/1&quot;&gt;Claudio Ferretti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nobile_M/0/1/0/all/0/1&quot;&gt;Marco S. Nobile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tangherloni_A/0/1/0/all/0/1&quot;&gt;Andrea Tangherloni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilardi_M/0/1/0/all/0/1&quot;&gt;Maria Carla Gilardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vitabile_S/0/1/0/all/0/1&quot;&gt;Salvatore Vitabile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakayama_H/0/1/0/all/0/1&quot;&gt;Hideki Nakayama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mauri_G/0/1/0/all/0/1&quot;&gt;Giancarlo Mauri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12575">
<title>Invariance-Preserving Localized Activation Functions for Graph Neural Networks. (arXiv:1903.12575v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1903.12575</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph signals are signals with an irregular structure that can be described
by a graph. Graph neural networks (GNNs) are information processing
architectures tailored to these graph signals and made of stacked layers that
compose graph convolutional filters with nonlinear activation functions. Graph
convolutions endow GNNs with invariance to permutations of the graph nodes&apos;
labels. In this paper, we consider the design of trainable nonlinear activation
functions that take into consideration the structure of the graph. This is
accomplished by using graph median filters and graph max filters, which mimic
linear graph convolutions and are shown to retain the permutation invariance of
GNNs. We also discuss modifications to the backpropagation algorithm necessary
to train local activation functions. The advantages of localized activation
function architectures are demonstrated in three numerical experiments: source
localization on synthetic graphs, authorship attribution of 19th century novels
and prediction of movie ratings. In all cases, localized activation functions
are shown to improve model capacity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ruiz_L/0/1/0/all/0/1&quot;&gt;Luana Ruiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gama_F/0/1/0/all/0/1&quot;&gt;Fernando Gama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Marques_A/0/1/0/all/0/1&quot;&gt;Antonio G. Marques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Alejandro Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12576">
<title>Practical Synthesis of Reactive Systems from LTL Specifications via Parity Games. (arXiv:1903.12576v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1903.12576</link>
<description rdf:parseType="Literal">&lt;p&gt;The synthesis - the automatic construction - of reactive systems from linear
temporal logic (LTL) specifications has recently seen a revival of the classic
automata-theoretic approach based on parity-tree-automata, which outperformed
other synthesis approaches in the last synthesis competition (Syntcomp2018). We
describe a complete synthesis procedure that is based on the translation of LTL
to deterministic parity automata and the emptiness check of the corresponding
tree automata.
&lt;/p&gt;
&lt;p&gt;The described approach is (1) structured, meaning that the states used in the
construction have a structure, which is also (partly) preserved in the
synthesis result, performs a (2) forward exploration and thus often only
constructs a small subset of the reachable states, and is (3) incremental in
the sense that it reuses results from previous unsuccessful solution attempts.
We further explore the impact of different guiding heuristics that determine
where to expand the on-the-fly built arena and present several mechanisms for
extracting an implementation (Mealy machine or circuit). Furthermore, several
data structures used in the implementation can be encoded symbolically reducing
time and memory consumption. We compare the proposed techniques on the
Syntcomp2017 benchmark set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luttenberger_M/0/1/0/all/0/1&quot;&gt;Michael Luttenberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyer_P/0/1/0/all/0/1&quot;&gt;Philipp J. Meyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sickert_S/0/1/0/all/0/1&quot;&gt;Salomon Sickert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12577">
<title>Learning Relational Representations with Auto-encoding Logic Programs. (arXiv:1903.12577v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12577</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning methods capable of handling relational data have proliferated
over the last years. In contrast to traditional relational learning methods
that leverage first-order logic for representing such data, these deep learning
methods aim at re-representing symbolic relational data in Euclidean spaces.
They offer better scalability, but can only numerically approximate relational
structures and are less flexible in terms of reasoning tasks supported. This
paper introduces a novel framework for relational representation learning that
combines the best of both worlds. This framework, inspired by the auto-encoding
principle, uses first-order logic as a data representation language, and the
mapping between the original and latent representation is done by means of
logic programs instead of neural networks. We show how learning can be cast as
a constraint optimisation problem for which existing solvers can be used. The
use of logic as a representation language makes the proposed framework more
accurate (as the representation is exact, rather than approximate), more
flexible, and more interpretable than deep learning methods. We experimentally
show that these latent representations are indeed beneficial in relational
learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumancic_S/0/1/0/all/0/1&quot;&gt;Sebastijan Dumancic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guns_T/0/1/0/all/0/1&quot;&gt;Tias Guns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meert_W/0/1/0/all/0/1&quot;&gt;Wannes Meert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blockeel_H/0/1/0/all/0/1&quot;&gt;Hendrik Blockeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12579">
<title>Predicting complex user behavior from CDR based social networks. (arXiv:1903.12579v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1903.12579</link>
<description rdf:parseType="Literal">&lt;p&gt;Call Detail Record (CDR) datasets provide enough information about personal
interactions to support building and analyzing detailed empirical social
networks. We take one such dataset and describe the various ways of using it to
create a true social network in spite of the highly noisy data source. We use
the resulting network to predict each individual&apos;s likelihood to default on
payments for the network services, a complex behavior that involves a
combination of social, economic, and legal considerations. We use a large
number of features extracted from the network to build a model for predicting
which users will default. By analyzing the relative contributions of features,
we choose their best performing subsets ranging in size from small to medium.
Features based on the number of close ties maintained by a user performed
better than those derived from user&apos;s geographical location. The paper
contributions include systematic impact analysis that the number of calls
cutoff has on the properties of the network derived from CDR, and a methodology
for building complex behavior models by creating very large sets of diverse
features and systematically choosing those which perform best for the final
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doyle_C/0/1/0/all/0/1&quot;&gt;Casey Doyle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herga_Z/0/1/0/all/0/1&quot;&gt;Zala Herga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dipple_S/0/1/0/all/0/1&quot;&gt;Stephen Dipple&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szymanski_B/0/1/0/all/0/1&quot;&gt;Boleslaw K. Szymanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korniss_G/0/1/0/all/0/1&quot;&gt;Gyorgy Korniss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mladenic_D/0/1/0/all/0/1&quot;&gt;Dunja Mladenic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12581">
<title>CroP: Color Constancy Benchmark Dataset Generator. (arXiv:1903.12581v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12581</link>
<description rdf:parseType="Literal">&lt;p&gt;Implementing color constancy as a pre-processing step in contemporary digital
cameras is of significant importance as it removes the influence of scene
illumination on object colors. Several benchmark color constancy datasets have
been created for the purpose of developing and testing new color constancy
methods. However, they all have numerous drawbacks including a small number of
images, erroneously extracted ground-truth illuminations, long histories of
misuses, violations of their stated assumptions, etc. To overcome such and
similar problems, in this paper a color constancy benchmark dataset generator
is proposed. For a given camera sensor it enables generation of any number of
realistic raw images taken in a subset of the real world, namely images of
printed photographs. Datasets with such images share many positive features
with other existing real-world datasets, while some of the negative features
are completely eliminated. The generated images can be successfully used to
train methods that afterward achieve high accuracy on real-world datasets. This
opens the way for creating large enough datasets for advanced deep learning
techniques. Experimental results are presented and discussed. The source code
is available at &lt;a href=&quot;http://www.fer.unizg.hr/ipg/resources/color_constancy/.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banic_N/0/1/0/all/0/1&quot;&gt;Nikola Bani&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koscevic_K/0/1/0/all/0/1&quot;&gt;Karlo Ko&amp;#x161;&amp;#x10d;evi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subasic_M/0/1/0/all/0/1&quot;&gt;Marko Suba&amp;#x161;i&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loncaric_S/0/1/0/all/0/1&quot;&gt;Sven Lon&amp;#x10d;ari&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12582">
<title>Methodology for Designing Decision Support Systems for Visualising and Mitigating Supply Chain Cyber Risk from IoT Technologies. (arXiv:1903.12582v1 [cs.OH])</title>
<link>http://arxiv.org/abs/1903.12582</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a methodology for designing decision support systems for
visualising and mitigating the Internet of Things cyber risks. Digital
technologies present new cyber risk in the supply chain which are often not
visible to companies participating in the supply chains. This study
investigates how the Internet of Things cyber risks can be visualised and
mitigated in the process of designing business and supply chain strategies. The
emerging DSS methodology present new findings on how digital technologies
affect business and supply chain systems. Through epistemological analysis, the
article derives with a decision support system for visualising supply chain
cyber risk from Internet of Things digital technologies. Such methods do not
exist at present and this represents the first attempt to devise a decision
support system that would enable practitioners to develop a step by step
process for visualising, assessing and mitigating the emerging cyber risk from
IoT technologies on shared infrastructure in legacy supply chain systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radanliev_P/0/1/0/all/0/1&quot;&gt;Petar Radanliev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roure_D/0/1/0/all/0/1&quot;&gt;David Charles De Roure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nurse_J/0/1/0/all/0/1&quot;&gt;Jason R.C. Nurse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burnap_P/0/1/0/all/0/1&quot;&gt;Peter Burnap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montalvo_R/0/1/0/all/0/1&quot;&gt;Rafael Mantilla Montalvo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12584">
<title>The False Positive Control Lasso. (arXiv:1903.12584v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1903.12584</link>
<description rdf:parseType="Literal">&lt;p&gt;In high dimensional settings where a small number of regressors are expected
to be important, the Lasso estimator can be used to obtain a sparse solution
vector with the expectation that most of the non-zero coefficients are
associated with true signals. While several approaches have been developed to
control the inclusion of false predictors with the Lasso, these approaches are
limited by relying on asymptotic theory, having to empirically estimate terms
based on theoretical quantities, assuming a continuous response class with
Gaussian noise and design matrices, or high computation costs. In this paper we
show how: (1) an existing model (the SQRT-Lasso) can be recast as a method of
controlling the number of expected false positives, (2) how a similar estimator
can used for all other generalized linear model classes, and (3) this approach
can be fit with existing fast Lasso optimization solvers. Our justification for
false positive control using randomly weighted self-normalized sum theory is to
our knowledge novel. Moreover, our estimator&apos;s properties hold in finite
samples up to some approximation error which we find in practical settings to
be negligible under a strict mutual incoherence condition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Drysdale_E/0/1/0/all/0/1&quot;&gt;Erik Drysdale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peng_Y/0/1/0/all/0/1&quot;&gt;Yingwei Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hanna_T/0/1/0/all/0/1&quot;&gt;Timothy P. Hanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Paul Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldenberg_A/0/1/0/all/0/1&quot;&gt;Anna Goldenberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12589">
<title>Coordinated Beam Selection in Millimeter Wave Multi-User MIMO Using Out-of-Band Information. (arXiv:1903.12589v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1903.12589</link>
<description rdf:parseType="Literal">&lt;p&gt;Using out-of-band (OOB) side-information has recently been shown to
accelerate beam selection in single-user millimeter wave (mmWave) massive MIMO
communications. In this paper, we propose a novel OOB-aided beam selection
framework for a mmWave uplink multi-user system. In particular, we exploit
spatial information extracted from lower (sub-6 GHz) bands in order to assist
with an inter-user coordination scheme at mmWave bands. To enforce
coordination, we propose an exchange protocol exploiting device-to-device
communications, where low-rate beam-related information is exchanged between
the mobile terminals. The decentralized coordination mechanism allows the
suppression of the so-called co-beam interference which would otherwise lead to
irreducible interference at the base station side, thereby triggering
substantial spectral efficiency gains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Maschietti_F/0/1/0/all/0/1&quot;&gt;Flavio Maschietti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gesbert_D/0/1/0/all/0/1&quot;&gt;David Gesbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kerret_P/0/1/0/all/0/1&quot;&gt;Paul de Kerret&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12600">
<title>A proof of convergence of multi-class logistic regression network. (arXiv:1903.12600v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1903.12600</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper revisits the special type of a neural network known under two
names. In the statistics and machine learning community it is known as a
multi-class logistic regression neural network. In the neural network
community, it is simply the soft-max layer. The importance is underscored by
its role in deep learning: as the last layer, whose autput is actually the
classification of the input patterns, such as images. Our exposition focuses on
mathematically rigorous derivation of the key equation expressing the gradient.
The fringe benefit of our approach is a fully vectorized expression, which is a
basis of an efficient implementation. The second result of this paper is the
positivity of the second derivative of the cross-entropy loss function as
function of the weights. This result proves that optimization methods based on
convexity may be used to train this network. As a corollary, we demonstrate
that no $L^2$-regularizer is needed to guarantee convergence of gradient
descent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rychlik_M/0/1/0/all/0/1&quot;&gt;Marek Rychlik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12605">
<title>Stable, Concurrent Controller Composition for Multi-Objective Robotic Tasks. (arXiv:1903.12605v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1903.12605</link>
<description rdf:parseType="Literal">&lt;p&gt;Robotic systems often need to consider multiple tasks concurrently. This
challenge calls for control synthesis algorithms that are capable of fulfilling
multiple control specifications simultaneously while maintaining the stability
of the overall system. In this paper, we decompose complex, multi-objective
tasks into subtasks, where individual subtask controllers are designed
independently and then combined to generate the overall control policy. In
particular, we adopt Riemannian Motion Policies (RMPs), a recently proposed
controller structure in robotics, and, RMPflow, its associated computational
framework for combining RMP controllers. We re-establish and extend the
stability results of RMPflow through a rigorous Control Lyapunov Function (CLF)
treatment. We then show that RMPflow can stably combine individually designed
subtask controllers that satisfy certain CLF constraints. This new insight
leads to an efficient CLF-based computational framework to generate stable
controllers that consider all the subtasks simultaneously. Compared with the
original usage of RMPflow, our framework provides users the flexibility to
incorporate design heuristics through nominal controllers for the subtasks. We
validate the proposed computational framework through numerical simulation and
robotic implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Anqi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Ching-An Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1&quot;&gt;Byron Boots&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Egerstedt_M/0/1/0/all/0/1&quot;&gt;Magnus Egerstedt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12616">
<title>Activity Classification Using Smartphone Gyroscope and Accelerometer Data. (arXiv:1903.12616v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1903.12616</link>
<description rdf:parseType="Literal">&lt;p&gt;Activities, such as walking and sitting, are commonly used in biomedical
settings either as an outcome or covariate of interest. Researchers have
traditionally relied on surveys to quantify activity levels of subjects in both
research and clinical settings, but surveys are not objective in nature and
have many known limitations, such as recall bias. Smartphones provide an
opportunity for unobtrusive objective measurement of various activities in
naturalistic settings, but their data tends to be noisy and needs to be
analyzed with care. We explored the potential of smartphone accelerometer and
gyroscope data to distinguish between five different types of activity:
walking, sitting, standing, ascending stairs, and descending stairs. We
conducted a study in which four participants followed a study protocol and
performed a sequence of various activities with one phone in their front pocket
and another phone in their back pocket. The subjects were filmed throughout,
and the obtained footage was annotated to establish ground truth activity. We
applied the so-called movelet method to classify their activity. Our results
demonstrate the promise of smartphones for activity detection in naturalistic
settings, but they also highlight common challenges in this field of research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_E/0/1/0/all/0/1&quot;&gt;Emily Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Onnela_J/0/1/0/all/0/1&quot;&gt;Jukka-Pekka Onnela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12617">
<title>Some Experimental Results of Relieving Discomfort in Virtual Reality by Disturbing Feedback Loop in Human Brain. (arXiv:1903.12617v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1903.12617</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, great progress has been made in virtual reality(VR) research and
application. However, virtual reality faces a big problem since its appearance,
i.e. discomfort (nausea, stomach awareness, etc). Discomfort can be relieved by
increasing hardware (sensor, cpu and display) speed. But this will increase
cost. This paper gives another low cost solution. The phenomenon of
cybersickness is explained with the control theory: discomfort arises if
feedback scene differs from expectation, so it can be relieved by disturbing
feedback loop in human brain. A hardware platform is build to test this
explanation. The VR display on a Samsung S6 is blurred while head movement is
detected. The effect is evaluated by comparing responses to the Simulated
Sickness Questionnaire (SSQ) between a control and experimental condition.
Experimental results show that the new method can ease discomfort remarkably
with little extra cost. As a result, VR may be used more widely in teaching
(like foreign language, medicine). It&apos;s also reasonable to expect likewise
merits in other VR applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qionghua_W/0/1/0/all/0/1&quot;&gt;Wei Qionghua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hui_W/0/1/0/all/0/1&quot;&gt;Wang Hui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiang_W/0/1/0/all/0/1&quot;&gt;Wei Qiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12620">
<title>Alternating Weak Automata from Universal Trees. (arXiv:1903.12620v1 [cs.FL])</title>
<link>http://arxiv.org/abs/1903.12620</link>
<description rdf:parseType="Literal">&lt;p&gt;An improved translation from alternating parity automata on infinite words to
alternating weak automata is given. The blow-up of the number of states is
related to the size of the smallest universal ordered trees and hence it is
quasi-polynomial, and only polynomial if the asymptotic number of priorities is
logarithmic in the number of states.
&lt;/p&gt;
&lt;p&gt;This is an exponential improvement on the translation of Kupferman and Vardi
(2001) and a quasi-polynomial improvement on the translation of Boker and
Lehtinen (2018). Any slightly better such translation would (if---like all
presently known such translations---it is efficiently constructive) lead to
algorithms for solving parity games that are asymptotically faster in the worst
case than the current state of the art (Calude, Jain, Khoussainov, Li, and
Stephan, 2017; Jurdzi\&apos;nski and Lazi\&apos;c, 2017; and Fearnley, Jain, Schewe,
Stephan, and Wojtczak, 2017), and hence it would yield a significant
breakthrough.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daviaud_L/0/1/0/all/0/1&quot;&gt;Laure Daviaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jurdzinski_M/0/1/0/all/0/1&quot;&gt;Marcin Jurdzinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehtinen_K/0/1/0/all/0/1&quot;&gt;Karoliina Lehtinen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12626">
<title>Integrating Semantic Knowledge to Tackle Zero-shot Text Classification. (arXiv:1903.12626v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1903.12626</link>
<description rdf:parseType="Literal">&lt;p&gt;Insufficient or even unavailable training data of emerging classes is a big
challenge of many classification tasks, including text classification.
Recognising text documents of classes that have never been seen in the learning
stage, so-called zero-shot text classification, is therefore difficult and only
limited previous works tackled this problem. In this paper, we propose a
two-phase framework together with data augmentation and feature augmentation to
solve this problem. Four kinds of semantic knowledge (word embeddings, class
descriptions, class hierarchy, and a general knowledge graph) are incorporated
into the proposed framework to deal with instances of unseen classes
effectively. Experimental results show that each and the combination of the two
phases achieve the best overall accuracy compared with baselines and recent
approaches in classifying real-world texts under the zero-shot scenario.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lertvittayakumjorn_P/0/1/0/all/0/1&quot;&gt;Piyawat Lertvittayakumjorn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yike Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12641">
<title>Connected max cut is polynomial for graphs without $K_5\backslash e$ as a minor. (arXiv:1903.12641v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1903.12641</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a graph $G=(V, E)$, a connected cut $\delta (U)$ is the set of edges of
E linking all vertices of U to all vertices of $V\backslash U$ such that the
induced subgraphs $G[U]$ and $G[V\backslash U]$ are connected. Given a positive
weight function $w$ defined on $E$, the connected maximum cut problem (CMAX
CUT) is to find a connected cut $\Omega$ such that $w(\Omega)$ is maximum among
all connected cuts. CMAX CUT is NP-hard even for planar graphs. In this paper,
we prove that CMAX CUT is polynomial for graphs without $K_5\backslash e$ as a
minor. We deduce a quadratic time algorithm for the minimum cut problem in the
same class of graphs without computing the maximum flow.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaourar_B/0/1/0/all/0/1&quot;&gt;Brahim Chaourar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12644">
<title>Optimising maintenance: What are the expectations for Cyber Physical Systems. (arXiv:1903.12644v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1903.12644</link>
<description rdf:parseType="Literal">&lt;p&gt;The need for maintenance is based on the wear of components of machinery. If
this need can be defined reliably beforehand so that no unpredicted failures
take place then the maintenance actions can be carried out economically with
mini-mum disturbances to production. There are two basic challenges in solving
the above. First understanding the development of wear and failures, and second
managing the measurement and diagnosis of such parameters that can reveal the
development of wear. In principle the development of wear and failures can be
predicted through monitoring time, load or wear as such. Moni-toring time is
not very efficient, as there are only limited numbers of components that suffer
from aging which as such is the result of chemical wear i.e. changes in the
material. In most cases the loading of components influences their wear. In
principle the loading can be stable or varying in nature. Of these two cases
the varying load case is much more challenging than the stable one. The
monitoring of wear can be done either directly e.g. optical methods or
indirectly e.g. vibration. Monitoring actual wear is naturally the most
reliable approach, but it often means that additional investments are needed.
The paper discusses how the monitoring of wear and need for maintenance can be
done based on the use of Cyber Physical Systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jantunen_E/0/1/0/all/0/1&quot;&gt;Erkki Jantunen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zurutuza_U/0/1/0/all/0/1&quot;&gt;Urko Zurutuza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ferreira_L/0/1/0/all/0/1&quot;&gt;Luis Lino Ferreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Varga_P/0/1/0/all/0/1&quot;&gt;Pal Varga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12648">
<title>Incremental Learning with Unlabeled Data in the Wild. (arXiv:1903.12648v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1903.12648</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are known to suffer from catastrophic forgetting in
class-incremental learning, where the performance on previous tasks drastically
degrades when learning a new task. To alleviate this effect, we propose to
leverage a continuous and large stream of unlabeled data in the wild. In
particular, to leverage such transient external data effectively, we design a
novel class-incremental learning scheme with (a) a new distillation loss,
termed global distillation, (b) a learning strategy to avoid overfitting to the
most recent task, and (c) a sampling strategy for the desired external data.
Our experimental results on various datasets, including CIFAR and ImageNet,
demonstrate the superiority of the proposed methods over prior methods,
particularly when a stream of unlabeled data is accessible: we achieve up to
9.3% of relative performance improvement compared to the state-of-the-art
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kibok Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kimin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinwoo Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12650">
<title>Yet Another Accelerated SGD: ResNet-50 Training on ImageNet in 74.7 seconds. (arXiv:1903.12650v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1903.12650</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been a strong demand for algorithms that can execute machine
learning as faster as possible and the speed of deep learning has accelerated
by 30 times only in the past two years. Distributed deep learning using the
large mini-batch is a key technology to address the demand and is a great
challenge as it is difficult to achieve high scalability on large clusters
without compromising accuracy. In this paper, we introduce optimization methods
which we applied to this challenge. We achieved the training time of 74.7
seconds using 2,048 GPUs on ABCI cluster applying these methods. The training
throughput is over 1.73 million images/sec and the top-1 validation accuracy is
75.08%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamazaki_M/0/1/0/all/0/1&quot;&gt;Masafumi Yamazaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasagi_A/0/1/0/all/0/1&quot;&gt;Akihiko Kasagi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabuchi_A/0/1/0/all/0/1&quot;&gt;Akihiro Tabuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honda_T/0/1/0/all/0/1&quot;&gt;Takumi Honda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miwa_M/0/1/0/all/0/1&quot;&gt;Masahiro Miwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fukumoto_N/0/1/0/all/0/1&quot;&gt;Naoto Fukumoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabaru_T/0/1/0/all/0/1&quot;&gt;Tsuguchika Tabaru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ike_A/0/1/0/all/0/1&quot;&gt;Atsushi Ike&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakashima_K/0/1/0/all/0/1&quot;&gt;Kohta Nakashima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12653">
<title>Fooling the Parallel Or Tester with Probability $8/27$. (arXiv:1903.12653v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1903.12653</link>
<description rdf:parseType="Literal">&lt;p&gt;It is well-known that the higher-order language PCF is not fully abstract:
there is a program - the so-called parallel or tester, meant to test whether
its input behaves as a parallel or - which never terminates on any input,
operationally, but is denotationally non-trivial. We explore a probabilistic
variant of PCF, and ask whether the parallel or tester exhibits a similar
behavior there. The answer is no: operationally, one can feed the parallel or
tester an input that will fool it into thinking it is a parallel or. We show
that the largest probability of success of such would-be parallel ors is
exactly $8/27$. The bound is reached by a very simple probabilistic program.
The difficult part is to show that that bound cannot be exceeded.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goubault_Larrecq_J/0/1/0/all/0/1&quot;&gt;Jean Goubault-Larrecq&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/cs/0601132">
<title>A Study on the Global Convergence Time Complexity of Estimation of Distribution Algorithms. (arXiv:cs/0601132v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/cs/0601132</link>
<description rdf:parseType="Literal">&lt;p&gt;The Estimation of Distribution Algorithm is a new class of population based
search methods in that a probabilistic model of individuals is estimated based
on the high quality individuals and used to generate the new individuals. In
this paper we compute 1) some upper bounds on the number of iterations required
for global convergence of EDA 2) the exact number of iterations needed for EDA
to converge to global optima.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastegar_R/0/1/0/all/0/1&quot;&gt;R. Rastegar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meybodi_M/0/1/0/all/0/1&quot;&gt;M. R. Meybodi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1505.02847">
<title>Minimal conditions for parametric continuity of a utility representation. (arXiv:1505.02847v2 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1505.02847</link>
<description rdf:parseType="Literal">&lt;p&gt;Dependence on the parameter is continuous when perturbations of the parameter
preserves strict preference for one alternative over another. We characterise
this property via a utility function over alternatives that depends
continuously on the parameter. The class of parameter spaces where such a
representation is guaranteed to exist is also identified. When the parameter is
the type or belief of a player, these results have implications for Bayesian
and psychological games. When alternatives are discrete, the representation is
jointly continuous and an extension of Berge&apos;s theorem of the maximum yields a
continuous value function. We apply this result to generalise a standard
consumer choice problem where parameters are price-wealth vectors. When the
parameter space is lexicographically ordered, a novel application to
reference-dependent preferences is possible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OCallaghan_P/0/1/0/all/0/1&quot;&gt;Patrick H. O&amp;#x27;Callaghan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.01234">
<title>Ensemble Validation: Selectivity has a Price, but Variety is Free. (arXiv:1610.01234v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.01234</link>
<description rdf:parseType="Literal">&lt;p&gt;Suppose some classifiers are selected from a set of hypothesis classifiers to
form an equally-weighted ensemble that selects a member classifier at random
for each input example. Then the ensemble has an error bound consisting of the
average error bound for the member classifiers, a term for selectivity that
varies from zero (if all hypothesis classifiers are selected) to a standard
uniform error bound (if only a single classifier is selected), and small
constants. There is no penalty for using a richer hypothesis set if the same
fraction of the hypothesis classifiers are selected for the ensemble.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bax_E/0/1/0/all/0/1&quot;&gt;Eric Bax&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kooti_F/0/1/0/all/0/1&quot;&gt;Farshad Kooti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.00229">
<title>Dense point sets with many halving lines. (arXiv:1704.00229v2 [math.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1704.00229</link>
<description rdf:parseType="Literal">&lt;p&gt;A planar point set of $n$ points is called {\em $\gamma$-dense} if the ratio
of the largest and smallest distances among the points is at most
$\gamma\sqrt{n}$. We construct a dense set of $n$ points in the plane with
$ne^{\Omega\left({\sqrt{\log n}}\right)}$ halving lines. This improves the
bound $\Omega(n\log n)$ of Edelsbrunner, Valtr and Welzl from 1997.
&lt;/p&gt;
&lt;p&gt;Our construction can be generalized to higher dimensions, for any $d$ we
construct a dense point set of $n$ points in $\mathbb{R}^d$ with
$n^{d-1}e^{\Omega\left({\sqrt{\log n}}\right)}$ halving hyperplanes. Our lower
bounds are asymptotically the same as the best known lower bounds for general
point sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kovacs_I/0/1/0/all/0/1&quot;&gt;Istv&amp;#xe1;n Kov&amp;#xe1;cs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Toth_G/0/1/0/all/0/1&quot;&gt;G&amp;#xe9;za T&amp;#xf3;th&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.09606">
<title>Theoretical Performance Analysis of Vehicular Broadcast Communications at Intersection and their Optimization. (arXiv:1706.09606v3 [cs.PF] UPDATED)</title>
<link>http://arxiv.org/abs/1706.09606</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose an optimization method for the broadcast rate in
vehicle-to-vehicle (V2V) broadcast communications at an intersection on the
basis of theoretical analysis. We consider a model in which locations of
vehicles are modeled separately as queuing and running segments and derive key
performance metrics of V2V broadcast communications via a stochastic geometry
approach. Since these theoretical expressions are mathematically intractable,
we developed closed-form approximate formulae for them. Using them, we optimize
the broadcast rate such that the mean number of successful receivers per unit
time is maximized. Because of the closed form approximation, the optimal rate
can be used as a guideline for a real-time control-method, which is not
achieved through time-consuming simulations. We evaluated our method through
numerical examples and demonstrated the effectiveness of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimura_T/0/1/0/all/0/1&quot;&gt;Tatsuaki Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saito_H/0/1/0/all/0/1&quot;&gt;Hiroshi Saito&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07230">
<title>Optimism-Based Adaptive Regulation of Linear-Quadratic Systems. (arXiv:1711.07230v3 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07230</link>
<description rdf:parseType="Literal">&lt;p&gt;The main challenge for adaptive regulation of linear-quadratic systems is the
trade-off between identification and control. An adaptive policy needs to
address both the estimation of unknown dynamics parameters (exploration), as
well as the regulation of the underlying system (exploitation). To this end,
optimism-based methods which bias the identification in favor of optimistic
approximations of the true parameter are employed in the literature. A number
of asymptotic results have been established, but their finite time counterparts
are few, with important restrictions.
&lt;/p&gt;
&lt;p&gt;This study establishes results for the worst-case regret of optimism-based
adaptive policies. The presented high probability upper bounds are optimal up
to logarithmic factors. The non-asymptotic analysis of this work requires very
mild assumptions; (i) stabilizability of the system&apos;s dynamics, and (ii)
limiting the degree of heaviness of the noise distribution. To establish such
bounds, certain novel techniques are developed to comprehensively address the
probabilistic behavior of dependent random matrices with heavy-tailed
distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faradonbeh_M/0/1/0/all/0/1&quot;&gt;Mohamad Kazem Shirani Faradonbeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1&quot;&gt;Ambuj Tewari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michailidis_G/0/1/0/all/0/1&quot;&gt;George Michailidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02719">
<title>Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing. (arXiv:1712.02719v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02719</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep convolutional neural network (DCNN) based supervised learning is a
widely practiced approach for large-scale image classification. However,
retraining these large networks to accommodate new, previously unseen data
demands high computational time and energy requirements. Also, previously seen
training samples may not be available at the time of retraining. We propose an
efficient training methodology and incrementally growing DCNN to allow new
classes to be learned while sharing part of the base network. Our proposed
methodology is inspired by transfer learning techniques, although it does not
forget previously learned classes. An updated network for learning new set of
classes is formed using previously learned convolutional layers (shared from
initial part of base network) with addition of few newly added convolutional
kernels included in the later layers of the network. We employed a
`clone-and-branch&apos; technique which allows the network to learn new tasks one
after another without any performance loss in old tasks. We evaluated the
proposed scheme on several recognition applications. The classification
accuracy achieved by our approach is comparable to the regular incremental
learning approach (where networks are updated with new training samples only,
without any network sharing), while achieving energy efficiency, reduction in
storage requirements, memory access and training time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarwar_S/0/1/0/all/0/1&quot;&gt;Syed Shakib Sarwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ankit_A/0/1/0/all/0/1&quot;&gt;Aayush Ankit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1&quot;&gt;Kaushik Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04054">
<title>Information Dissemination Speed in Delay Tolerant Urban Vehicular Networks in a Hyperfractal Setting. (arXiv:1712.04054v2 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04054</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the fundamental communication properties of urban vehicle
networks by exploiting the self-similarity and hierarchical organization of
modern cities. We use an innovative model called &quot;hyperfractal&quot; that captures
the self-similarities of both the traffic and vehicle locations but avoids the
extremes of regularity and randomness. We use analytical tools to derive
theoretical upper and lower bounds for the information propagation speed in an
urban delay tolerant network (i.e., a network that is disconnected at all time,
and thus uses a store-carry-and-forward routing model). We prove that the
average broadcast time behaves as $n^{1-\delta}$ times a slowly varying
function, where $\delta$ depends on the precise fractal dimension.
&lt;/p&gt;
&lt;p&gt;Furthermore, we show that the broadcast speedup is due in part to an
interesting self-similar phenomenon, that we denote as {\em information
teleportation}. This phenomenon arises as a consequence of the topology of the
vehicle traffic, and triggers an acceleration of the broadcast time. We show
that our model fits real cities where open traffic data sets are available. We
present simulations confirming the validity of the bounds in multiple realistic
settings, including scenarios with variable speed, using both QualNet and a
discrete-event simulator in Matlab.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popescu_D/0/1/0/all/0/1&quot;&gt;Dalia Popescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacquet_P/0/1/0/all/0/1&quot;&gt;Philippe Jacquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mans_B/0/1/0/all/0/1&quot;&gt;Bernard Mans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumitru_R/0/1/0/all/0/1&quot;&gt;Robert Dumitru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pastrav_A/0/1/0/all/0/1&quot;&gt;Andra Pastrav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puschita_E/0/1/0/all/0/1&quot;&gt;Emanuel Puschita&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.10365">
<title>Synchronized Detection and Recovery of Steganographic Messages with Adversarial Learning. (arXiv:1801.10365v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1801.10365</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we mainly study the mechanism of learning the steganographic
algorithm as well as combining the learning process with adversarial learning
to learn a good steganographic algorithm. To handle the problem of embedding
secret messages into the specific medium, we design a novel adversarial modules
to learn the steganographic algorithm, and simultaneously train three modules
called generator, discriminator and steganalyzer. Different from existing
methods, the three modules are formalized as a game to communicate with each
other. In the game, the generator and discriminator attempt to communicate with
each other using secret messages hidden in an image. While the steganalyzer
attempts to analyze whether there is a transmission of confidential
information. We show that through unsupervised adversarial training, the
adversarial model can produce robust steganographic solutions, which act like
an encryption. Furthermore, we propose to utilize supervised adversarial
training method to train a robust steganalyzer, which is utilized to
discriminate whether an image contains secret information. Numerous experiments
are conducted on publicly available dataset to demonstrate the effectiveness of
the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1&quot;&gt;Haichao Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiao-Yu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01751">
<title>Near-Optimal Coresets of Kernel Density Estimates. (arXiv:1802.01751v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01751</link>
<description rdf:parseType="Literal">&lt;p&gt;We construct near-optimal coresets for kernel density estimates for points in
$\mathbb{R}^d$ when the kernel is positive definite. Specifically we show a
polynomial time construction for a coreset of size $O(\sqrt{d}/\varepsilon\cdot
\sqrt{\log 1/\varepsilon} )$, and we show a near-matching lower bound of size
$\Omega(\min\{\sqrt{d}/\varepsilon, 1/\varepsilon^2\})$. When $d\geq
1/\varepsilon^2$, it is known that the size of coreset can be
$O(1/\varepsilon^2)$. The upper bound is a polynomial-in-$(1/\varepsilon)$
improvement when $d \in [3,1/\varepsilon^2)$ and the lower bound is the first
known lower bound to depend on $d$ for this problem. Moreover, the upper bound
restriction that the kernel is positive definite is significant in that it
applies to a wide-variety of kernels, specifically those most important for
machine learning. This includes kernels for information distances and the sinc
kernel which can be negative.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1&quot;&gt;Jeff M. Phillips&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_W/0/1/0/all/0/1&quot;&gt;Wai Ming Tai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02607">
<title>Learning from Past Mistakes: Improving Automatic Speech Recognition Output via Noisy-Clean Phrase Context Modeling. (arXiv:1802.02607v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02607</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic speech recognition (ASR) systems often make unrecoverable errors
due to subsystem pruning (acoustic, language and pronunciation models); for
example pruning words due to acoustics using short-term context, prior to
rescoring with long-term context based on linguistics. In this work we model
ASR as a phrase-based noisy transformation channel and propose an error
correction system that can learn from the aggregate errors of all the
independent modules constituting the ASR and attempt to invert those. The
proposed system can exploit long-term context using a neural network language
model and can better choose between existing ASR output possibilities as well
as re-introduce previously pruned or unseen (out-of-vocabulary) phrases. It
provides corrections under poorly performing ASR conditions without degrading
any accurate transcriptions; such corrections are greater on top of
out-of-domain and mismatched data ASR. Our system consistently provides
improvements over the baseline ASR, even when baseline is further optimized
through recurrent neural network language model rescoring. This demonstrates
that any ASR improvements can be exploited independently and that our proposed
system can potentially still provide benefits on highly optimized ASR. Finally,
we present an extensive analysis of the type of errors corrected by our system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shivakumar_P/0/1/0/all/0/1&quot;&gt;Prashanth Gurunath Shivakumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haoqi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knight_K/0/1/0/all/0/1&quot;&gt;Kevin Knight&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Georgiou_P/0/1/0/all/0/1&quot;&gt;Panayiotis Georgiou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04364">
<title>Junction Tree Variational Autoencoder for Molecular Graph Generation. (arXiv:1802.04364v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04364</link>
<description rdf:parseType="Literal">&lt;p&gt;We seek to automate the design of molecules based on specific chemical
properties. In computational terms, this task involves continuous embedding and
generation of molecular graphs. Our primary contribution is the direct
realization of molecular graphs, a task previously approached by generating
linear SMILES strings instead of graphs. Our junction tree variational
autoencoder generates molecular graphs in two phases, by first generating a
tree-structured scaffold over chemical substructures, and then combining them
into a molecule with a graph message passing network. This approach allows us
to incrementally expand molecules while maintaining chemical validity at every
step. We evaluate our model on multiple tasks ranging from molecular generation
to optimization. Across these tasks, our model outperforms previous
state-of-the-art baselines by a significant margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1&quot;&gt;Wengong Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1&quot;&gt;Regina Barzilay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1&quot;&gt;Tommi Jaakkola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10681">
<title>Motion Guided LIDAR-camera Self-calibration and Accelerated Depth Upsampling. (arXiv:1803.10681v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10681</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we describe a novel motion guided method for targetless
self-calibration of a LiDAR and camera and use the re-projection of LiDAR
points onto the image reference frame for real-time depth upsampling. The
calibration parameters are estimated by optimizing an objective function that
penalizes distances between 2D and re-projected 3D motion vectors obtained from
time-synchronized image and point cloud sequences. For upsampling, we propose a
simple, yet effective and time efficient formulation that minimizes depth
gradients subject to an equality constraint involving the LiDAR measurements.
We test our algorithms on real data from urban environments and demonstrate
that our two methods are effective and suitable to mobile robotics and
autonomous vehicle applications imposing real-time requirements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castorena_J/0/1/0/all/0/1&quot;&gt;Juan Castorena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puskorius_G/0/1/0/all/0/1&quot;&gt;Gint Puskorius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandey_G/0/1/0/all/0/1&quot;&gt;Gaurav Pandey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03295">
<title>MmWave MU-MIMO for Aerial Networks. (arXiv:1804.03295v5 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03295</link>
<description rdf:parseType="Literal">&lt;p&gt;Millimeter wave offers high bandwidth for air-to-air (A2A) communication. In
this paper, we evaluate the rate performance of a multiuser MIMO (MU-MIMO)
configuration where several aircraft communicate with a central hub. We
consider a hybrid subarray architecture, single path channels, and realistic
atmospheric attenuation effects. We propose a mathematical framework for the
analysis of millimeter wave (mmWave) MU-MIMO networks. Via Monte Carlo
simulation, we demonstrate that mmWave is a promising technology for delivering
gigabit connectivity in next-generation aerial networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cuvelier_T/0/1/0/all/0/1&quot;&gt;Travis Cuvelier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heath_R/0/1/0/all/0/1&quot;&gt;Robert W. Heath Jr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10445">
<title>Adaptive Transmission in Cellular Networks: Fixed-Rate Codes with Power Control vs Physical Layer Rateless Codes. (arXiv:1804.10445v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10445</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive transmission schemes are a crucial aspect of the radio design for
future wireless networks. The paper studies the performance of two classes of
adaptive transmission schemes in a cellular downlink. One class is based on
physical layer rateless codes with constant transmit power and the other uses
fixed-rate codes in conjunction with power adaptation. Using a simple
stochastic geometry model for the cellular downlink, the focus is to compare
the adaptivity of fixed-rate codes with power adaptation to that of physical
layer rateless codes only. The performance of both rateless and fixed-rate
coded adaptive transmission schemes are compared by evaluating the typical user
success probability and rate achievable with the two schemes. Based on both the
theoretical analysis and simulation results, it is clearly shown that
fixed-rate codes require power control to maintain good performance whereas
physical layer rateless codes with constant power can still provide robust
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajanna_A/0/1/0/all/0/1&quot;&gt;Amogh Rajanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dettmann_C/0/1/0/all/0/1&quot;&gt;Carl P. Dettmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.05086">
<title>Unsupervised Intuitive Physics from Visual Observations. (arXiv:1805.05086v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.05086</link>
<description rdf:parseType="Literal">&lt;p&gt;While learning models of intuitive physics is an increasingly active area of
research, current approaches still fall short of natural intelligences in one
important regard: they require external supervision, such as explicit access to
physical states, at training and sometimes even at test times. Some authors
have relaxed such requirements by supplementing the model with an handcrafted
physical simulator. Still, the resulting methods are unable to automatically
learn new complex environments and to understand physical interactions within
them. In this work, we demonstrated for the first time learning such predictors
directly from raw visual observations and without relying on simulators. We do
so in two steps: first, we learn to track mechanically-salient objects in
videos using causality and equivariance, two unsupervised learning principles
that do not require auto-encoding. Second, we demonstrate that the extracted
positions are sufficient to successfully train visual motion predictors that
can take the underlying environment into account. We validate our predictors on
synthetic datasets; then, we introduce a new dataset, ROLL4REAL, consisting of
real objects rolling on complex terrains (pool table, elliptical bowl, and
random height-field). We show that in all such cases it is possible to learn
reliable extrapolators of the object trajectories from raw videos alone,
without any form of external supervision and with no more prior knowledge than
the choice of a convolutional neural network architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ehrhardt_S/0/1/0/all/0/1&quot;&gt;Sebastien Ehrhardt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monszpart_A/0/1/0/all/0/1&quot;&gt;Aron Monszpart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1&quot;&gt;Niloy Mitra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1&quot;&gt;Andrea Vedaldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11519">
<title>Face Recognition in Low Quality Images: A Survey. (arXiv:1805.11519v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11519</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-resolution face recognition (LRFR) has received increasing attention over
the past few years. Its applications lie widely in the real-world environment
when high-resolution or high-quality images are hard to capture. One of the
biggest demands for LRFR technologies is video surveillance. As the the number
of surveillance cameras in the city increases, the videos that captured will
need to be processed automatically. However, those videos or images are usually
captured with large standoffs, arbitrary illumination condition, and diverse
angles of view. Faces in these images are generally small in size. Several
studies addressed this problem employed techniques like super resolution,
deblurring, or learning a relationship between different resolution domains. In
this paper, we provide a comprehensive review of approaches to low-resolution
face recognition in the past five years. First, a general problem definition is
given. Later, systematically analysis of the works on this topic is presented
by catogory. In addition to describing the methods, we also focus on datasets
and experiment settings. We further address the related works on unconstrained
low-resolution face recognition and compare them with the result that use
synthetic low-resolution data. Finally, we summarized the general limitations
and speculate a priorities for the future effort.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Pei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prieto_L/0/1/0/all/0/1&quot;&gt;Loreto Prieto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mery_D/0/1/0/all/0/1&quot;&gt;Domingo Mery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flynn_P/0/1/0/all/0/1&quot;&gt;Patrick Flynn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11529">
<title>On Low-Resolution Face Recognition in the Wild: Comparisons and New Techniques. (arXiv:1805.11529v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11529</link>
<description rdf:parseType="Literal">&lt;p&gt;Although face recognition systems have achieved impressive performance in
recent years, the low-resolution face recognition (LRFR) task remains
challenging, especially when the LR faces are captured under non-ideal
conditions, as is common in surveillance-based applications. Faces captured in
such conditions are often contaminated by blur, nonuniform lighting, and
nonfrontal face pose. In this paper, we analyze face recognition techniques
using data captured under low-quality conditions in the wild. We provide a
comprehensive analysis of experimental results for two of the most important
applications in real surveillance applications, and demonstrate practical
approaches to handle both cases that show promising performance. The following
three contributions are made: {\em (i)} we conduct experiments to evaluate
super-resolution methods for low-resolution face recognition; {\em (ii)} we
study face re-identification on various public face datasets including real
surveillance and low-resolution subsets of large-scale datasets, present a
baseline result for several deep learning based approaches, and improve them by
introducing a GAN pre-training approach and fully convolutional architecture;
and {\em (iii)} we explore low-resolution face identification by employing a
state-of-the-art supervised discriminative learning approach. Evaluations are
conducted on challenging portions of the SCFace and UCCSface datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Pei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prieto_L/0/1/0/all/0/1&quot;&gt;Loreto Prieto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mery_D/0/1/0/all/0/1&quot;&gt;Domingo Mery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flynn_P/0/1/0/all/0/1&quot;&gt;Patrick Flynn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01825">
<title>The Effect of Planning Shape on Dyna-style Planning in High-dimensional State Spaces. (arXiv:1806.01825v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01825</link>
<description rdf:parseType="Literal">&lt;p&gt;Dyna is a fundamental approach to model-based reinforcement learning (MBRL)
that interleaves planning, acting, and learning in an online setting. In the
most typical application of Dyna, the dynamics model is used to generate
one-step transitions from selected start states from the agent&apos;s history, which
are used to update the agent&apos;s value function or policy as if they were real
experiences. In this work, one-step Dyna was applied to several games from the
Arcade Learning Environment (ALE). We found that the model-based updates
offered surprisingly little benefit over simply performing more updates with
the agent&apos;s existing experience, even when using a perfect model. We
hypothesize that to get the most from planning, the model must be used to
generate unfamiliar experience. To test this, we experimented with the &quot;shape&quot;
of planning in multiple different concrete instantiations of Dyna, performing
fewer, longer rollouts, rather than many short rollouts. We found that planning
shape has a profound impact on the efficacy of Dyna for both perfect and
learned models. In addition to these findings regarding Dyna in general, our
results represent, to our knowledge, the first time that a learned dynamics
model has been successfully used for planning in the ALE, suggesting that Dyna
may be a viable approach to MBRL in the ALE and other high-dimensional
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holland_G/0/1/0/all/0/1&quot;&gt;G. Zacharias Holland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talvitie_E/0/1/0/all/0/1&quot;&gt;Erin J. Talvitie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bowling_M/0/1/0/all/0/1&quot;&gt;Michael Bowling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07307">
<title>Estimation from Non-Linear Observations via Convex Programming with Application to Bilinear Regression. (arXiv:1806.07307v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07307</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a computationally efficient estimator, formulated as a convex
program, for a broad class of non-linear regression problems that involve
difference of convex (DC) non-linearities. The proposed method can be viewed as
a significant extension of the &quot;anchored regression&quot; method formulated and
analyzed in [10] for regression with convex non-linearities. Our main
assumption, in addition to other mild statistical and computational
assumptions, is availability of a certain approximation oracle for the average
of the gradients of the observation functions at a ground truth. Under this
assumption and using a PAC-Bayesian analysis we show that the proposed
estimator produces an accurate estimate with high probability. As a concrete
example, we study the proposed framework in the bilinear regression problem
with Gaussian factors and quantify a sufficient sample complexity for exact
recovery. Furthermore, we describe a computationally tractable scheme that
provably produces the required approximation oracle in the considered bilinear
regression problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahmani_S/0/1/0/all/0/1&quot;&gt;Sohail Bahmani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11306">
<title>Excavate Condition-invariant Space by Intrinsic Encoder. (arXiv:1806.11306v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1806.11306</link>
<description rdf:parseType="Literal">&lt;p&gt;As the human, we can recognize the places across a wide range of changing
environmental conditions such as those caused by weathers, seasons, and
day-night cycles. We excavate and memorize the stable semantic structure of
different places and scenes. For example, we can recognize tree whether the
bare tree in winter or lush tree in summer. Therefore, the intrinsic features
that are corresponding to specific semantic contents and condition-invariant of
appearance changes can be employed to improve the performance of long-term
place recognition significantly.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a novel intrinsic encoder that excavates the
condition-invariant latent space of different places under drastic appearance
changes. Our method excavates the space of intrinsic structure and semantic
information by proposed self-supervised encoder loss. Different from previous
learning based place recognition methods that need paired training data of each
place with appearance changes, we employ the weakly-supervised strategy to
utilize unpaired set-based training data of different environmental conditions.
&lt;/p&gt;
&lt;p&gt;We conduct comprehensive experiments and show that our semi-supervised
intrinsic encoder achieves remarkable performance for place recognition under
drastic appearance changes. The proposed intrinsic encoder outperforms the
state-of-the-art image-level place recognition methods on standard benchmark
Nordland.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jian Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chunheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1&quot;&gt;Cunzhao Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1&quot;&gt;Baihua Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01697">
<title>Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations. (arXiv:1807.01697v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01697</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we establish rigorous benchmarks for image classifier
robustness. Our first benchmark, ImageNet-C, standardizes and expands the
corruption robustness topic, while showing which classifiers are preferable in
safety-critical applications. Unlike recent robustness research, this benchmark
evaluates performance on commonplace corruptions not worst-case adversarial
corruptions. We find that there are negligible changes in relative corruption
robustness from AlexNet to ResNet classifiers, and we discover ways to enhance
corruption robustness. Then we propose a new dataset called Icons-50 which
opens research on a new kind of robustness, surface variation robustness. With
this dataset we evaluate the frailty of classifiers on new styles of known
objects and unexpected instances of known classes. We also demonstrate two
methods that improve surface variation robustness. Together our benchmarks may
aid future work toward networks that learn fundamental class structure and also
robustly generalize.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1&quot;&gt;Dan Hendrycks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dietterich_T/0/1/0/all/0/1&quot;&gt;Thomas G. Dietterich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02631">
<title>Some Insights on Synthesizing Optimal Linear Quadratic Controller Using Krotov&apos;s Sufficiency Conditions. (arXiv:1807.02631v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1807.02631</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper revisits the problem of optimal control law design for linear
systems using the global optimal control framework introduced by Vadim Krotov.
Krotov&apos;s approach is based on the idea of total decomposition of the original
optimal control problem (OCP) with respect to time, by an $ad$ $hoc$ choice of
the so-called Krotov&apos;s function or solving function, thereby providing
sufficient conditions for the existence of global solution based on another
optimization problem, which is completely equivalent to the original OCP. It is
well known that the solution of this equivalent optimization problem is
obtained using an iterative method. In this paper, we propose suitable Krotov&apos;s
functions for linear quadratic OCP and subsequently, show that by imposing
convexity condition on this equivalent optimization problem, there is no need
to compute an iterative solution. We also give some key insights into the
solution procedure of the linear quadratic OCP using the proposed methodology
in contrast to the celebrated Calculus of Variations (CoV) and
Hamilton-Jacobi-Bellman (HJB) equation based approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Avinash Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jain_T/0/1/0/all/0/1&quot;&gt;Tushar Jain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07560">
<title>Compositional GAN: Learning Image-Conditional Binary Composition. (arXiv:1807.07560v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.07560</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) can produce images of remarkable
complexity and realism but are generally structured to sample from a single
latent source ignoring the explicit spatial interaction between multiple
entities that could be present in a scene. Capturing such complex interactions
between different objects in the world, including their relative scaling,
spatial layout, occlusion, or viewpoint transformation is a challenging
problem. In this work, we propose a novel self-consistent
Composition-by-Decomposition (CoDe) network to compose a pair of objects. Given
object images from two distinct distributions, our model can generate a
realistic composite image from their joint distribution following the texture
and shape of the input objects. We evaluate our approach through qualitative
experiments and user evaluations. Our results indicate that the learned model
captures potential interactions between the two object domains, and generates
realistic composed scenes at test time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azadi_S/0/1/0/all/0/1&quot;&gt;Samaneh Azadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1&quot;&gt;Deepak Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1&quot;&gt;Sayna Ebrahimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1&quot;&gt;Trevor Darrell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08284">
<title>Predicting breast tumor proliferation from whole-slide images: the TUPAC16 challenge. (arXiv:1807.08284v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.08284</link>
<description rdf:parseType="Literal">&lt;p&gt;Tumor proliferation is an important biomarker indicative of the prognosis of
breast cancer patients. Assessment of tumor proliferation in a clinical setting
is highly subjective and labor-intensive task. Previous efforts to automate
tumor proliferation assessment by image analysis only focused on mitosis
detection in predefined tumor regions. However, in a real-world scenario,
automatic mitosis detection should be performed in whole-slide images (WSIs)
and an automatic method should be able to produce a tumor proliferation score
given a WSI as input. To address this, we organized the TUmor Proliferation
Assessment Challenge 2016 (TUPAC16) on prediction of tumor proliferation scores
from WSIs. The challenge dataset consisted of 500 training and 321 testing
breast cancer histopathology WSIs. In order to ensure fair and independent
evaluation, only the ground truth for the training dataset was provided to the
challenge participants. The first task of the challenge was to predict mitotic
scores, i.e., to reproduce the manual method of assessing tumor proliferation
by a pathologist. The second task was to predict the gene expression based
PAM50 proliferation scores from the WSI. The best performing automatic method
for the first task achieved a quadratic-weighted Cohen&apos;s kappa score of
$\kappa$ = 0.567, 95% CI [0.464, 0.671] between the predicted scores and the
ground truth. For the second task, the predictions of the top method had a
Spearman&apos;s correlation coefficient of r = 0.617, 95% CI [0.581 0.651] with the
ground truth. This was the first study that investigated tumor proliferation
assessment from WSIs. The achieved results are promising given the difficulty
of the tasks and weakly-labelled nature of the ground truth. However, further
research is needed to improve the practical utility of image analysis methods
for this task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veta_M/0/1/0/all/0/1&quot;&gt;Mitko Veta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heng_Y/0/1/0/all/0/1&quot;&gt;Yujing J. Heng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stathonikos_N/0/1/0/all/0/1&quot;&gt;Nikolas Stathonikos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bejnordi_B/0/1/0/all/0/1&quot;&gt;Babak Ehteshami Bejnordi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beca_F/0/1/0/all/0/1&quot;&gt;Francisco Beca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wollmann_T/0/1/0/all/0/1&quot;&gt;Thomas Wollmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohr_K/0/1/0/all/0/1&quot;&gt;Karl Rohr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1&quot;&gt;Manan A. Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dayong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rousson_M/0/1/0/all/0/1&quot;&gt;Mikael Rousson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hedlund_M/0/1/0/all/0/1&quot;&gt;Martin Hedlund&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tellez_D/0/1/0/all/0/1&quot;&gt;David Tellez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciompi_F/0/1/0/all/0/1&quot;&gt;Francesco Ciompi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zerhouni_E/0/1/0/all/0/1&quot;&gt;Erwan Zerhouni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lanyi_D/0/1/0/all/0/1&quot;&gt;David Lanyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viana_M/0/1/0/all/0/1&quot;&gt;Matheus Viana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovalev_V/0/1/0/all/0/1&quot;&gt;Vassili Kovalev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liauchuk_V/0/1/0/all/0/1&quot;&gt;Vitali Liauchuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phoulady_H/0/1/0/all/0/1&quot;&gt;Hady Ahmady Phoulady&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qaiser_T/0/1/0/all/0/1&quot;&gt;Talha Qaiser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graham_S/0/1/0/all/0/1&quot;&gt;Simon Graham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajpoot_N/0/1/0/all/0/1&quot;&gt;Nasir Rajpoot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sjoblom_E/0/1/0/all/0/1&quot;&gt;Erik Sj&amp;#xf6;blom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molin_J/0/1/0/all/0/1&quot;&gt;Jesper Molin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paeng_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Paeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1&quot;&gt;Sangheum Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Sunggyun Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1&quot;&gt;Eric I-Chao Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beck_A/0/1/0/all/0/1&quot;&gt;Andrew H. Beck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diest_P/0/1/0/all/0/1&quot;&gt;Paul J. van Diest&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pluim_J/0/1/0/all/0/1&quot;&gt;Josien P. W. Pluim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02223">
<title>Character-Aware Decoder for Translation into Morphologically Rich Languages. (arXiv:1809.02223v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02223</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural machine translation (NMT) systems operate primarily on words (or
subwords), ignoring lower-level patterns of morphology. We present a
character-aware decoder designed to capture such patterns when translating into
morphologically rich languages. We achieve character-awareness by augmenting
both the softmax and embedding layers of an attention-based encoder-decoder
model with convolutional neural networks that operate on the spelling of a
word. To investigate performance on a wide variety of morphological phenomena,
we translate English into $14$ typologically diverse target languages using the
TED multi-target dataset. In this low-resource setting, the character-aware
decoder provides consistent improvements with BLEU score gains of up to
$+3.05$. In addition, we analyze the relationship between the gains obtained
and properties of the target language and find evidence that our model does
indeed exploit morphological patterns.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renduchintala_A/0/1/0/all/0/1&quot;&gt;Adithya Renduchintala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapiro_P/0/1/0/all/0/1&quot;&gt;Pamela Shapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duh_K/0/1/0/all/0/1&quot;&gt;Kevin Duh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1&quot;&gt;Philipp Koehn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.05929">
<title>Solving for multi-class: a survey and synthesis. (arXiv:1809.05929v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1809.05929</link>
<description rdf:parseType="Literal">&lt;p&gt;We review common methods of solving for multi-class from binary and
generalize them to a common framework. Since conditional probabilties are
useful both for quantifying the accuracy of an estimate and for calibration
purposes, these are a required part of the solution. There is some indication
that the best solution for multi-class classification is dependent on the
particular dataset. As such, we are especially interested in data-driven
solution design, whether based on a priori considerations or empirical
examination of the data. Numerical results indicate that while a
one-size-fits-all solution consisting of one-versus-one is appropriate for most
datasets, a minority will benefit from a more customized approach. The
techniques discussed in this paper allow for a large variety of multi-class
configurations and solution methods to be explored so as to optimize
classification accuracy, accuracy of conditional probabilities and speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mills_P/0/1/0/all/0/1&quot;&gt;Peter Mills&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.10243">
<title>Segmentation of Skin Lesions and their Attributes Using Multi-Scale Convolutional Neural Networks and Domain Specific Augmentations. (arXiv:1809.10243v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1809.10243</link>
<description rdf:parseType="Literal">&lt;p&gt;Computer-aided diagnosis systems for classification of different type of skin
lesions have been an active field of research in recent decades. It has been
shown that introducing lesions and their attributes masks into lesion
classification pipeline can greatly improve the performance. In this paper, we
propose a framework by incorporating transfer learning for segmenting lesions
and their attributes based on the convolutional neural networks. The proposed
framework is based on the encoder-decoder architecture which utilizes a variety
of pre-trained networks in the encoding path and generates the prediction map
by combining multi-scale information in decoding path using a pyramid pooling
manner. To address the lack of training data and increase the proposed model
generalization, an extensive set of novel domain-specific augmentation routines
have been applied to simulate the real variations in dermoscopy images.
Finally, by performing broad experiments on three different data sets obtained
from International Skin Imaging Collaboration archive (ISIC2016, ISIC2017, and
ISIC2018 challenges data sets), we show that the proposed method outperforms
other state-of-the-art approaches for ISIC2016 and ISIC2017 segmentation task
and achieved the first rank on the leader-board of ISIC2018 attribute detection
task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jahanifar_M/0/1/0/all/0/1&quot;&gt;Mostafa Jahanifar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tajeddin_N/0/1/0/all/0/1&quot;&gt;Neda Zamani Tajeddin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koohbanani_N/0/1/0/all/0/1&quot;&gt;Navid Alemi Koohbanani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gooya_A/0/1/0/all/0/1&quot;&gt;Ali Gooya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajpoot_N/0/1/0/all/0/1&quot;&gt;Nasir Rajpoot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.04369">
<title>$\epsilon$-Nash Equilibria for Major Minor LQG Mean Field Games with Partial Observations of All Agents. (arXiv:1810.04369v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1810.04369</link>
<description rdf:parseType="Literal">&lt;p&gt;The partially observed major minor LQG and nonlinear mean field game (PO MM
LQG MFG) systems where it is assumed the major agent&apos;s state is partially
observed by each minor agent, and the major agent completely observes its own
state have been analysed in the literature. In this paper, PO MM LQG MFG
problems with general information patterns are studied where (i) the major
agent has partial observations of its own state, and (ii) each minor agent has
partial observations of its own state and the major agent&apos;s state. The
assumption of partial observations by all agents leads to a new situation
involving the recursive estimation by each minor agent of the major agent&apos;s
estimate of its own state. For a general case of indefinite LQG MFG systems,
the existence of $\epsilon$-Nash equilibria together with the individual
agents&apos; control laws yielding the equilibria are established via the Separation
Principle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Firoozi_D/0/1/0/all/0/1&quot;&gt;Dena Firoozi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Caines_P/0/1/0/all/0/1&quot;&gt;Peter E. Caines&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1810.09948">
<title>Comments on &quot;Towards Unambiguous Edge Bundling: Investigating Confluent Drawings for Network Visualization&quot;. (arXiv:1810.09948v2 [cs.CG] UPDATED)</title>
<link>http://arxiv.org/abs/1810.09948</link>
<description rdf:parseType="Literal">&lt;p&gt;Bach et al. [1] recently presented an algorithm for constructing confluent
drawings, by leveraging power graph decomposition to generate an auxiliary
routing graph. We identify two problems with their method and offer a single
solution to solve both. We then recognize a limitation regarding planarity, and
help to guide future research by introducing a new classification of
&apos;power-confluent&apos; drawing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jonathan X. Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawar_S/0/1/0/all/0/1&quot;&gt;Samraat Pawar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodman_D/0/1/0/all/0/1&quot;&gt;Dan F. M. Goodman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.00656">
<title>Exposing DeepFake Videos By Detecting Face Warping Artifacts. (arXiv:1811.00656v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.00656</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we describe a new deep learning based method that can
effectively distinguish AI-generated fake videos (referred to as {\em DeepFake}
videos hereafter) from real videos. Our method is based on the observations
that current DeepFake algorithm can only generate images of limited
resolutions, which need to be further warped to match the original faces in the
source video. Such transforms leave distinctive artifacts in the resulting
DeepFake videos, and we show that they can be effectively captured by
convolutional neural networks (CNNs). Compared to previous methods which use a
large amount of real and DeepFake generated images to train CNN classifier, our
method does not need DeepFake generated images as negative training examples
since we target the artifacts in affine face warping as the distinctive feature
to distinguish real and fake images. The advantages of our method are two-fold:
(1) Such artifacts can be simulated directly using simple image processing
operations on a image to make it as negative example. Since training a DeepFake
model to generate negative examples is time-consuming and resource-demanding,
our method saves a plenty of time and resources in training data collection;
(2) Since such artifacts are general existed in DeepFake videos from different
sources, our method is more robust compared to others. Our method is evaluated
on two sets of DeepFake video datasets for its effectiveness in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuezun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Siwei Lyu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.03199">
<title>Confusion2Vec: Towards Enriching Vector Space Word Representations with Representational Ambiguities. (arXiv:1811.03199v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1811.03199</link>
<description rdf:parseType="Literal">&lt;p&gt;Word vector representations are a crucial part of Natural Language Processing
(NLP) and Human Computer Interaction. In this paper, we propose a novel word
vector representation, Confusion2Vec, motivated from the human speech
production and perception that encodes representational ambiguity. Humans
employ both acoustic similarity cues and contextual cues to decode information
and we focus on a model that incorporates both sources of information. The
representational ambiguity of acoustics, which manifests itself in word
confusions, is often resolved by both humans and machines through contextual
cues. A range of representational ambiguities can emerge in various domains
further to acoustic perception, such as morphological transformations,
paraphrasing for NLP tasks like machine translation etc. In this work, we
present a case study in application to Automatic Speech Recognition (ASR),
where the word confusions are related to acoustic similarity. We present
several techniques to train an acoustic perceptual similarity representation
ambiguity. We term this Confusion2Vec and learn on unsupervised-generated data
from ASR confusion networks or lattice-like structures. Appropriate evaluations
for the Confusion2Vec are formulated for gauging acoustic similarity in
addition to semantic-syntactic and word similarity evaluations. The
Confusion2Vec is able to model word confusions efficiently, without
compromising on the semantic-syntactic word relations, thus effectively
enriching the word vector space with extra task relevant ambiguity information.
We provide an intuitive exploration of the 2-dimensional Confusion2Vec space
using Principal Component Analysis of the embedding and relate to semantic,
syntactic and acoustic relationships. The potential of Confusion2Vec in the
utilization of uncertainty present in lattices is demonstrated through small
examples relating to ASR error correction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shivakumar_P/0/1/0/all/0/1&quot;&gt;Prashanth Gurunath Shivakumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Georgiou_P/0/1/0/all/0/1&quot;&gt;Panayiotis Georgiou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.03706">
<title>Maximizing Diversity of Opinion in Social Networks. (arXiv:1811.03706v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1811.03706</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of maximizing opinion diversity in a social network that
includes opinion leaders with binary opposing opinions. The members of the
network who are not leaders form their opinions using the French-DeGroot model
of opinion dynamics. To quantify the diversity of such a system, we adapt two
diversity measures from ecology to our setting, the Simpson Diversity Index and
the Shannon Index. Using these two measures, we formalize the problem of how to
place a single leader with opinion 1, given a network with a leader with
opinion 0, so as to maximize the opinion diversity. We give analytical
solutions to these problems for paths, cycles, and trees, and we highlight our
results through a numerical example.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mackin_E/0/1/0/all/0/1&quot;&gt;Erika Mackin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Patterson_S/0/1/0/all/0/1&quot;&gt;Stacy Patterson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.04918">
<title>Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers. (arXiv:1811.04918v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1811.04918</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have great success in many machine learning applications, but
the fundamental learning theory behind them remains largely unsolved. Learning
neural networks is NP-hard, but in practice, simple algorithms like stochastic
gradient descent (SGD) often produce good solutions. Moreover, it is observed
that overparameterization (that is, designing networks whose number of
parameters is larger than statistically needed to perfectly fit the training
data) improves both optimization and generalization, appearing to contradict
traditional learning theory.
&lt;/p&gt;
&lt;p&gt;In this work, we prove that using overparameterized neural networks with
rectified linear units, one can (improperly) learn some notable hypothesis
classes, including two and three-layer neural networks with fewer parameters
and smooth activations. Moreover, the learning process can be simply done by
SGD or its variants in polynomial time using polynomially many samples. We also
show that for a fixed sample size, the population risk of the solution found by
some SGD variant can be made almost independent of the number of parameters in
the overparameterized network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Allen-Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yingyu Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.07619">
<title>Adversarial Soft-detection-based Aggregation Network for Image Retrieval. (arXiv:1811.07619v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.07619</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent year, the compact representations based on activations of
Convolutional Neural Network (CNN) achieve remarkable performance in image
retrieval. However, retrieval of some interested object that only takes up a
small part of the whole image is still a challenging problem. Therefore, it is
significant to extract the discriminative representations that contain regional
information of the pivotal small object. In this paper, we propose a novel
adversarial soft-detection-based aggregation (ASDA) method free from bounding
box annotations for image retrieval, based on adversarial detector and soft
region proposal layer. Our trainable adversarial detector generates semantic
maps based on adversarial erasing strategy to preserve more discriminative and
detailed information. Computed based on semantic maps corresponding to various
discriminative patterns and semantic contents, our soft region proposal is
arbitrary shape rather than only rectangle and it reflects the significance of
objects. The aggregation based on trainable soft region proposal highlights
discriminative semantic contents and suppresses the noise of background.
&lt;/p&gt;
&lt;p&gt;We conduct comprehensive experiments on standard image retrieval datasets.
Our weakly supervised ASDA method achieves state-of-the-art performance on most
datasets. The results demonstrate that the proposed ASDA method is effective
for image retrieval.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jian Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chunheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1&quot;&gt;Cunzhao Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1&quot;&gt;Baihua Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.10719">
<title>Learning View Priors for Single-view 3D Reconstruction. (arXiv:1811.10719v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.10719</link>
<description rdf:parseType="Literal">&lt;p&gt;There is some ambiguity in the 3D shape of an object when the number of
observed views is small. Because of this ambiguity, although a 3D object
reconstructor can be trained using a single view or a few views per object,
reconstructed shapes only fit the observed views and appear incorrect from the
unobserved viewpoints. To reconstruct shapes that look reasonable from any
viewpoint, we propose to train a discriminator that learns prior knowledge
regarding possible views. The discriminator is trained to distinguish the
reconstructed views of the observed viewpoints from those of the unobserved
viewpoints. The reconstructor is trained to correct unobserved views by fooling
the discriminator. Our method outperforms current state-of-the-art methods on
both synthetic and natural image datasets; this validates the effectiveness of
our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kato_H/0/1/0/all/0/1&quot;&gt;Hiroharu Kato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harada_T/0/1/0/all/0/1&quot;&gt;Tatsuya Harada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.11742">
<title>3D human pose estimation in video with temporal convolutions and semi-supervised training. (arXiv:1811.11742v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.11742</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we demonstrate that 3D poses in video can be effectively
estimated with a fully convolutional model based on dilated temporal
convolutions over 2D keypoints. We also introduce back-projection, a simple and
effective semi-supervised training method that leverages unlabeled video data.
We start with predicted 2D keypoints for unlabeled video, then estimate 3D
poses and finally back-project to the input 2D keypoints. In the supervised
setting, our fully-convolutional model outperforms the previous best result
from the literature by 6 mm mean per-joint position error on Human3.6M,
corresponding to an error reduction of 11%, and the model also shows
significant improvements on HumanEva-I. Moreover, experiments with
back-projection show that it comfortably outperforms previous state-of-the-art
results in semi-supervised settings where labeled data is scarce. Code and
models are available at https://github.com/facebookresearch/VideoPose3D
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavllo_D/0/1/0/all/0/1&quot;&gt;Dario Pavllo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feichtenhofer_C/0/1/0/all/0/1&quot;&gt;Christoph Feichtenhofer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grangier_D/0/1/0/all/0/1&quot;&gt;David Grangier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1&quot;&gt;Michael Auli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.12197">
<title>Iterative Residual CNNs for Burst Photography Applications. (arXiv:1811.12197v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.12197</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern inexpensive imaging sensors suffer from inherent hardware constraints
which often result in captured images of poor quality. Among the most common
ways to deal with such limitations is to rely on burst photography, which
nowadays acts as the backbone of all modern smartphone imaging applications. In
this work, we focus on the fact that every frame of a burst sequence can be
accurately described by a forward (physical) model. This in turn allows us to
restore a single image of higher quality from a sequence of low quality images
as the solution of an optimization problem. Inspired by an extension of the
gradient descent method that can handle non-smooth functions, namely the
proximal gradient descent, and modern deep learning techniques, we propose a
convolutional iterative network with a transparent architecture. Our network,
uses a burst of low quality image frames and is able to produce an output of
higher image quality recovering fine details which are not distinguishable in
any of the original burst frames. We focus both on the burst photography
pipeline as a whole, i.e. burst demosaicking and denoising, as well as on the
traditional Gaussian denoising task. The developed method demonstrates
consistent state-of-the art performance across the two tasks and as opposed to
other recent deep learning approaches does not have any inherent restrictions
either to the number of frames or their ordering. Code can be found at
https://fkokkinos.github.io/deep_burst/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokkinos_F/0/1/0/all/0/1&quot;&gt;Filippos Kokkinos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lefkimmiatis_S/0/1/0/all/0/1&quot;&gt;Stamatios Lefkimmiatis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1811.12784">
<title>The GAN that Warped: Semantic Attribute Editing with Unpaired Data. (arXiv:1811.12784v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1811.12784</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have recently been used to edit images with great
success, in particular for faces. However, they are often limited to only being
able to work at a restricted range of resolutions. Many methods are so flexible
that face edits can often result in an unwanted loss of identity. This work
proposes to learn how to perform semantic image edits through the application
of smooth warp fields. Previous approaches that attempted to use warping for
semantic edits required paired data, i.e. example images of the same subject
with different semantic attributes. In contrast, we employ recent advances in
Generative Adversarial Networks that allow our model to be trained with
unpaired data. We demonstrate face editing at very high resolutions (4k images)
with a single forward pass of a deep network at a lower resolution. We also
show that our edits are substantially better at preserving the subject&apos;s
identity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dorta_G/0/1/0/all/0/1&quot;&gt;Garoe Dorta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vicente_S/0/1/0/all/0/1&quot;&gt;Sara Vicente&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_N/0/1/0/all/0/1&quot;&gt;Neill D.F. Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simpson_I/0/1/0/all/0/1&quot;&gt;Ivor Simpson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.00573">
<title>Towards Visual Feature Translation. (arXiv:1812.00573v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.00573</link>
<description rdf:parseType="Literal">&lt;p&gt;Most existing visual search systems are deployed based upon fixed kinds of
visual features, which prohibits the feature reusing across different systems
or when upgrading systems with a new type of feature. Such a setting is
obviously inflexible and time/memory consuming, which is indeed mendable if
visual features can be &quot;translated&quot; across systems. In this paper, we make the
first attempt towards visual feature translation to break through the barrier
of using features across different visual search systems. To this end, we
propose a Hybrid Auto-Encoder (HAE) to translate visual features, which learns
a mapping by minimizing the translation and reconstruction errors. Based upon
HAE, an Undirected Affinity Measurement (UAM) is further designed to quantify
the affinity among different types of visual features. Extensive experiments
have been conducted on several public datasets with sixteen different types of
widely-used features in visual search systems. Quantitative results show the
encouraging possibilities of feature translation. For the first time, the
affinity among widely-used features like SIFT and DELF is reported.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jie Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1&quot;&gt;Rongrong Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shengchuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1&quot;&gt;Cheng Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1&quot;&gt;Qi Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.01946">
<title>Unsupervised Generation of Optical Flow Datasets. (arXiv:1812.01946v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.01946</link>
<description rdf:parseType="Literal">&lt;p&gt;Dense optical flow ground truths of non-rigid motion for real-world images
are not available due to the non-intuitive annotation. Aiming at training
optical flow deep networks, we present an unsupervised algorithm to generate
optical flow ground truth from real-world videos. The algorithm extracts and
matches objects of interest from pairs of images in videos to find initial
constraints, and applies as-rigid-as-possible deformation over the objects of
interest to obtain dense flow fields. The ground truth correctness is enforced
by warping the objects in the first frames using the flow fields. We apply the
algorithm on the DAVIS dataset to obtain optical flow ground truths for
non-rigid movement of real-world objects, using either ground truth or
predicted segmentation. We discuss several methods to increase the optical flow
variations in the dataset. Extensive experimental results show that training on
non-rigid real motion is beneficial compared to training on rigid synthetic
data. Moreover, we show that our pipeline generates training data suitable to
train successfully FlowNet-S, PWC-Net, and LiteFlowNet deep networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1&quot;&gt;Hoang-An Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nimbhorkar_T/0/1/0/all/0/1&quot;&gt;Tushar Nimbhorkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mensink_T/0/1/0/all/0/1&quot;&gt;Thomas Mensink&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baslamisli_A/0/1/0/all/0/1&quot;&gt;Anil S. Baslamisli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karaoglu_S/0/1/0/all/0/1&quot;&gt;Sezer Karaoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gevers_T/0/1/0/all/0/1&quot;&gt;Theo Gevers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.02849">
<title>A Survey of Unsupervised Deep Domain Adaptation. (arXiv:1812.02849v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1812.02849</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has produced state-of-the-art results for a variety of tasks.
While such approaches for supervised learning have performed well, they assume
that training and testing data are drawn from the same distribution, which may
not always be the case. As a complement to this challenge, unsupervised domain
adaptation can handle situations where a network is trained on labeled data
from a source domain and unlabeled data from a related but different target
domain with the goal of performing well at test-time on the target domain. Many
unsupervised deep domain adaptation approaches have thus been developed. This
survey will compare these approaches by examining alternative methods, the
unique and common elements, results, and theoretical insights. We follow this
with a look at application areas and open research directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_G/0/1/0/all/0/1&quot;&gt;Garrett Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cook_D/0/1/0/all/0/1&quot;&gt;Diane J. Cook&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.03952">
<title>A Scalable Thermal Reservoir Simulator for Giant Models on Parallel Computers. (arXiv:1812.03952v8 [cs.CE] UPDATED)</title>
<link>http://arxiv.org/abs/1812.03952</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces the model, numerical methods, algorithms and parallel
implementation of a thermal reservoir simulator that designed for numerical
simulations of thermal reservoir with multiple components in three dimensional
domain using distributed-memory parallel computers. Its full mathematical model
is introduced with correlations for important properties and well modeling.
Various well constraints, such as fixed bottom hole pressure, fixed oil, water,
gas and liquid rates, constant heat transfer model, convective heat transfer
model, heater model (temperature control, rate control, dual rate/temperature
control), and subcool (steam trap), are introduced in details, including their
mathematical models and methods. Efficient numerical methods and parallel
computing technologies are presented. The simulator is designed for giant
models with billions or even trillions of grid blocks using hundreds of
thousands of CPUs. Numerical experiments show that our results match commercial
simulators, which confirms the correctness of our methods and implementations.
SAGD simulation with 15106 well pairs is also presented to study the
effectiveness of our numerical methods. Scalability testings demonstrate that
our simulator can handle giant models with over 200 billion grid blocks using
98,000 CPU cores and the simulator has good scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhangxin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.04948">
<title>A Style-Based Generator Architecture for Generative Adversarial Networks. (arXiv:1812.04948v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1812.04948</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an alternative generator architecture for generative adversarial
networks, borrowing from style transfer literature. The new architecture leads
to an automatically learned, unsupervised separation of high-level attributes
(e.g., pose and identity when trained on human faces) and stochastic variation
in the generated images (e.g., freckles, hair), and it enables intuitive,
scale-specific control of the synthesis. The new generator improves the
state-of-the-art in terms of traditional distribution quality metrics, leads to
demonstrably better interpolation properties, and also better disentangles the
latent factors of variation. To quantify interpolation quality and
disentanglement, we propose two new, automated methods that are applicable to
any generator architecture. Finally, we introduce a new, highly varied and
high-quality dataset of human faces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karras_T/0/1/0/all/0/1&quot;&gt;Tero Karras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laine_S/0/1/0/all/0/1&quot;&gt;Samuli Laine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aila_T/0/1/0/all/0/1&quot;&gt;Timo Aila&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.06570">
<title>Defense-VAE: A Fast and Accurate Defense against Adversarial Attacks. (arXiv:1812.06570v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.06570</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have been enormously successful across a variety
of prediction tasks. However, recent research shows that DNNs are particularly
vulnerable to adversarial attacks, which poses a serous threat to their
applications in security-sensitive systems. In this paper, we propose a simple
yet effective defense algorithm Defense-VAE that uses variational autoencoder
(VAE) to purge adversarial perturbations from contaminated images. The proposed
method is generic and can defend white-box and black-box attacks without the
need of retraining the original CNN classifiers, and can further strengthen the
defense by retraining CNN or end-to-end finetuning the whole pipeline. In
addition, the proposed method is very efficient compared to the
optimization-based alternatives, such as Defense-GAN, since no iterative
optimization is needed for online prediction. Extensive experiments on MNIST,
Fashion-MNIST, CelebA and CIFAR-10 demonstrate the superior defense accuracy of
Defense-VAE compared to Defense-GAN, while being 50x faster than the latter.
This makes Defense-VAE widely deployable in real-time security-sensitive
systems. We plan to open source our implementation to facilitate the research
in this area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1&quot;&gt;Shihao Ji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.09638">
<title>AEPecker: L0 Adversarial Examples are not Strong Enough. (arXiv:1812.09638v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1812.09638</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the great achievements made by neural networks on tasks such as image
classification, they are brittle and vulnerable to adversarial examples (AEs).
By adding adversarial noise to input images, adversarial examples can be
crafted to mislead neural network based image classifiers. One type of AE
attack in particular, known as an L0 AE, has been used in several notable
real-world incidents. Our observation is that, while L0 corruptions modify as
few pixels as possible, they tend to cause large-amplitude perturbations to the
modified pixels. We consider this to be an inherent limitation of L0 AEs which
can be exploited. To show the weakness of L0 AEs, we thwart samples of these
attacks by both detecting and rectifying them. The main novelty of the proposed
detector is that we convert the AE detection problem into an image comparison
problem by exploiting the inherent characteristics of L0 AEs. More concretely,
given an image I, it is pre-processed to obtain another image I&apos;. We use a
Siamese network which is known to be effective in comparison, to take I and I&apos;
as the input pair. A well trained Siamese network can automatically capture the
discrepancy between I and I&apos; to detect L0 noises. In addition, the
straightforward pre-processor based on heuristics can be deployed as an
effective defense, having a high probability of removing the adversarial
influence of L0 perturbations. The proposed technique shows not only a high
accuracy but also a resilience to the adaptive adversary, which outperforms
other state-of-the-art methods. We accordingly argue that L0 attacks are not
strong enough.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_F/0/1/0/all/0/1&quot;&gt;Fei Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bokai Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaopeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1&quot;&gt;Lannan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1&quot;&gt;Qiang Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.11448">
<title>Removing Malicious Nodes from Networks. (arXiv:1812.11448v6 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1812.11448</link>
<description rdf:parseType="Literal">&lt;p&gt;A fundamental challenge in networked systems is detection and removal of
suspected malicious nodes. In reality, detection is always imperfect, and the
decision about which potentially malicious nodes to remove must trade off false
positives (erroneously removing benign nodes) and false negatives (mistakenly
failing to remove malicious nodes). However, in network settings this
conventional tradeoff must now account for node connectivity. In particular,
malicious nodes may exert malicious influence, so that mistakenly leaving some
of these in the network may cause damage to spread. On the other hand, removing
benign nodes causes direct harm to these, and indirect harm to their benign
neighbors who would wish to communicate with them.
&lt;/p&gt;
&lt;p&gt;We formalize the problem of removing potentially malicious nodes from a
network under uncertainty through an objective that takes connectivity into
account. We show that optimally solving the resulting problem is NP-Hard. We
then propose a tractable solution approach based on a convex relaxation of the
objective. Finally, we experimentally demonstrate that our approach
significantly outperforms both a simple baseline that ignores network
structure, as well as a state-of-the-art approach for a related problem, on
both synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Sixie Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1&quot;&gt;Yevgeniy Vorobeychik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.11631">
<title>Actor Conditioned Attention Maps for Video Action Detection. (arXiv:1812.11631v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.11631</link>
<description rdf:parseType="Literal">&lt;p&gt;While observing complex events with multiple actors, humans do not assess
each actor separately, but infer from the context. The surrounding context
provides essential information for understanding actions. To this end, we
propose to replace region of interest(RoI) pooling with an attention module,
which ranks each spatio-temporal region&apos;s relevance to a detected actor instead
of cropping. We refer to these as Actor-Conditioned Attention Maps (ACAM),
which weight the features extracted from the entire scene. The resulting
actor-conditioned features focus the model on regions that are relevant to the
conditioned actor. For actor localization, we leverage pre-trained object
detectors, which generalize better. The proposed model is efficient and our
action detection pipeline achieves near real-time performance. Experimental
results on AVA 2.1 and JHMDB demonstrate the effectiveness of attention maps,
with improvements of 5 mAP on AVA and 4 mAP on JHMDB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ulutan_O/0/1/0/all/0/1&quot;&gt;Oytun Ulutan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rallapalli_S/0/1/0/all/0/1&quot;&gt;Swati Rallapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivatsa_M/0/1/0/all/0/1&quot;&gt;Mudhakar Srivatsa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torres_C/0/1/0/all/0/1&quot;&gt;Carlos Torres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manjunath_B/0/1/0/all/0/1&quot;&gt;B.S. Manjunath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1812.11771">
<title>Predicting Group Cohesiveness in Images. (arXiv:1812.11771v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1812.11771</link>
<description rdf:parseType="Literal">&lt;p&gt;Cohesiveness of a group is an essential indicator of emotional state,
structure and success of a group of people. We study the factors that influence
the perception of group-level cohesion and propose methods for estimating the
human-perceived cohesion to the group cohesiveness scale. In order to identify
the visual cues (attributes) for cohesion, we conducted a user survey. Image
analysis is performed at a group-level via a multi-task convolutional neural
network. For analyzing the contribution of facial expressions of the group
members for predicting Group Cohesion Score (GCS), capsule network is explored.
We add GCS on the Group Affect database and propose the `GAF-Cohesion
database&apos;. The proposed model performs well on the database and is able to
achieve near human-level performance in predicting group&apos;s cohesion score. It
is interesting to note that group cohesion as an attribute, when jointly
trained for group-level emotion prediction, helps in increasing the performance
for the later task. This suggests that group-level emotion and cohesion are
correlated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Shreya Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhall_A/0/1/0/all/0/1&quot;&gt;Abhinav Dhall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1&quot;&gt;Nicu Sebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1&quot;&gt;Tom Gedeon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.00224">
<title>Ancient Painting to Natural Image: A New Solution for Painting Processing. (arXiv:1901.00224v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1901.00224</link>
<description rdf:parseType="Literal">&lt;p&gt;Collecting a large-scale and well-annotated dataset for image processing has
become a common practice in computer vision. However, in the ancient painting
area, this task is not practical as the number of paintings is limited and
their style is greatly diverse. We, therefore, propose a novel solution for the
problems that come with ancient painting processing. This is to use domain
transfer to convert ancient paintings to photo-realistic natural images. By
doing so, the ancient painting processing problems become natural image
processing problems and models trained on natural images can be directly
applied to the transferred paintings. Specifically, we focus on Chinese ancient
flower, bird and landscape paintings in this work. A novel Domain Style
Transfer Network (DSTN) is proposed to transfer ancient paintings to natural
images which employ a compound loss to ensure that the transferred paintings
still maintain the color composition and content of the input paintings. The
experiment results show that the transferred paintings generated by the DSTN
have a better performance in both the human perceptual test and other image
processing tasks than other state-of-art methods, indicating the authenticity
of the transferred paintings and the superiority of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_T/0/1/0/all/0/1&quot;&gt;Tingting Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weijing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Miao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zixuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Duanqing Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.04713">
<title>Global-to-local Memory Pointer Networks for Task-Oriented Dialogue. (arXiv:1901.04713v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1901.04713</link>
<description rdf:parseType="Literal">&lt;p&gt;End-to-end task-oriented dialogue is challenging since knowledge bases are
usually large, dynamic and hard to incorporate into a learning framework. We
propose the global-to-local memory pointer (GLMP) networks to address this
issue. In our model, a global memory encoder and a local memory decoder are
proposed to share external knowledge. The encoder encodes dialogue history,
modifies global contextual representation, and generates a global memory
pointer. The decoder first generates a sketch response with unfilled slots.
Next, it passes the global memory pointer to filter the external knowledge for
relevant information, then instantiates the slots via the local memory
pointers. We empirically show that our model can improve copy accuracy and
mitigate the common out-of-vocabulary problem. As a result, GLMP is able to
improve over the previous state-of-the-art models in both simulated bAbI
Dialogue dataset and human-human Stanford Multi-domain Dialogue dataset on
automatic and human evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chien-Sheng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1&quot;&gt;Richard Socher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.07879">
<title>Physical reservoir computing built by spintronic devices for temporal information processing. (arXiv:1901.07879v2 [cs.ET] UPDATED)</title>
<link>http://arxiv.org/abs/1901.07879</link>
<description rdf:parseType="Literal">&lt;p&gt;Spintronic nanodevices have ultrafast nonlinear dynamic and recurrence
behaviors on a nanosecond scale that promises to enable spintronic reservoir
computing (RC) system. Here two physical RC systems based on a single magnetic
skyrmion memristor (MSM) and 24 spin-torque nano-oscillators (STNOs) were
proposed and modeled to process image classification task and nonlinear dynamic
system prediction, respectively. Based on our micromagnetic simulation results
on the nonlinear responses of MSM and STNO with current pulses stimulation, the
handwritten digits recognition task domesticates that an RC system using one
single MSM has the outstanding performance on image classification. In
addition, the complex unknown nonlinear dynamic problems can also be well
solved by a physical RC system consisted of 24 STNOs confirmed in a
second-order nonlinear dynamic system and NARMA10 tasks. The capability of both
high accuracy and fast information processing promises to enable one type of
brain-like chip based on spintronics for various artificial intelligence tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1&quot;&gt;Wencong Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lina Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1&quot;&gt;Kaiyuan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Liyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1&quot;&gt;Qingwei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1&quot;&gt;Youwei Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Ronghua Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1901.09109">
<title>DADAM: A Consensus-based Distributed Adaptive Gradient Method for Online Optimization. (arXiv:1901.09109v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1901.09109</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive gradient-based optimization methods such as \textsc{Adagrad},
\textsc{Rmsprop}, and \textsc{Adam} are widely used in solving large-scale
machine learning problems including deep learning. A number of schemes have
been proposed in the literature aiming at parallelizing them, based on
communications of peripheral nodes with a central node, but incur high
communications cost. To address this issue, we develop a novel consensus-based
distributed adaptive moment estimation method (\textsc{Dadam}) for online
optimization over a decentralized network that enables data parallelization, as
well as decentralized computation. The method is particularly useful, since it
can accommodate settings where access to local data is allowed. Further, as
established theoretically in this work, it can outperform centralized adaptive
algorithms, for certain classes of loss functions used in applications. We
analyze the convergence properties of the proposed algorithm and provide a
dynamic regret bound on the convergence rate of adaptive moment estimation
methods in both stochastic and deterministic settings. Empirical results
demonstrate that \textsc{Dadam} works also well in practice and compares
favorably to competing online optimization methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazari_P/0/1/0/all/0/1&quot;&gt;Parvin Nazari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1&quot;&gt;Davoud Ataee Tarzanagh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michailidis_G/0/1/0/all/0/1&quot;&gt;George Michailidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.03368">
<title>Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC). (arXiv:1902.03368v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1902.03368</link>
<description rdf:parseType="Literal">&lt;p&gt;This work summarizes the results of the largest skin image analysis challenge
in the world, hosted by the International Skin Imaging Collaboration (ISIC), a
global partnership that has organized the world&apos;s largest public repository of
dermoscopic images of skin. The challenge was hosted in 2018 at the Medical
Image Computing and Computer Assisted Intervention (MICCAI) conference in
Granada, Spain. The dataset included over 12,500 images across 3 tasks. 900
users registered for data download, 115 submitted to the lesion segmentation
task, 25 submitted to the lesion attribute detection task, and 159 submitted to
the disease classification task. Novel evaluation protocols were established,
including a new test for segmentation algorithm performance, and a test for
algorithm ability to generalize. Results show that top segmentation algorithms
still fail on over 10% of images on average, and algorithms with equal
performance on test data can have different abilities to generalize. This is an
important consideration for agencies regulating the growing set of machine
learning tools in the healthcare domain, and sets a new standard for future
public challenges in healthcare.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Codella_N/0/1/0/all/0/1&quot;&gt;Noel Codella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rotemberg_V/0/1/0/all/0/1&quot;&gt;Veronica Rotemberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tschandl_P/0/1/0/all/0/1&quot;&gt;Philipp Tschandl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celebi_M/0/1/0/all/0/1&quot;&gt;M. Emre Celebi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dusza_S/0/1/0/all/0/1&quot;&gt;Stephen Dusza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutman_D/0/1/0/all/0/1&quot;&gt;David Gutman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helba_B/0/1/0/all/0/1&quot;&gt;Brian Helba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalloo_A/0/1/0/all/0/1&quot;&gt;Aadi Kalloo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liopyris_K/0/1/0/all/0/1&quot;&gt;Konstantinos Liopyris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marchetti_M/0/1/0/all/0/1&quot;&gt;Michael Marchetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kittler_H/0/1/0/all/0/1&quot;&gt;Harald Kittler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halpern_A/0/1/0/all/0/1&quot;&gt;Allan Halpern&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.05679">
<title>ProxSARAH: An Efficient Algorithmic Framework for Stochastic Composite Nonconvex Optimization. (arXiv:1902.05679v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1902.05679</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new stochastic first-order algorithmic framework to solve
stochastic composite nonconvex optimization problems that covers both
finite-sum and expectation settings. Our algorithms rely on the SARAH estimator
introduced in (Nguyen et al, 2017) and consist of two steps: a proximal
gradient and an averaging step making them different from existing nonconvex
proximal-type algorithms. The algorithms only require an average smoothness
assumption of the nonconvex objective term and additional bounded variance
assumption if applied to expectation problems. They work with both constant and
adaptive step-sizes, while allowing single sample and mini-batches. In all
these cases, we prove that our algorithms can achieve the best-known complexity
bounds. One key step of our methods is new constant and adaptive step-sizes
that help to achieve desired complexity bounds while improving practical
performance. Our constant step-size is much larger than existing methods
including proximal SVRG schemes in the single sample case. We also specify the
algorithm to the non-composite case that covers existing state-of-the-arts in
terms of complexity bounds. Our update also allows one to trade-off between
step-sizes and mini-batch sizes to improve performance. We test the proposed
algorithms on two composite nonconvex problems and neural networks using
several well-known datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pham_N/0/1/0/all/0/1&quot;&gt;Nhan H. Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nguyen_L/0/1/0/all/0/1&quot;&gt;Lam M. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Phan_D/0/1/0/all/0/1&quot;&gt;Dzung T. Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tran_Dinh_Q/0/1/0/all/0/1&quot;&gt;Quoc Tran-Dinh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.07836">
<title>ERSFQ 8-bit Parallel Binary Shifter for Energy-Efficient Superconducting CPU. (arXiv:1902.07836v2 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/1902.07836</link>
<description rdf:parseType="Literal">&lt;p&gt;We have designed and tested a parallel 8-bit ERSFQ binary shifter that is one
of the essential circuits in the design of the energy-efficient superconducting
CPU. The binary shifter performs a bi-directional SHIFT instruction of an 8-bit
argument. It consists of a bi-direction triple-port shift register controlled
by two (left and right) shift pulse generators asynchronously generating a set
number of shift pulses. At first clock cycle, an 8-bit word is loaded into the
binary shifter and a 3-bit shift argument is loaded into the desired
shift-pulse generator. Next, the generator produces the required number of
shift SFQ pulses (from 0 to 7) asynchronously, with a repetition rate set by
the internal generator delay of ~ 30 ps. These SFQ pulses are applied to the
left (positive) or the right (negative) input of the binary shifter. Finally,
after the shift operation is completed, the resulting 8-bit word goes to the
parallel output. The complete 8-bit ERSFQ binary shifter, consisting of 820
Josephson junctions, was simulated and optimized using PSCAN2. It was
fabricated in MIT Lincoln Lab 10-kA/cm2 SFQ5ee fabrication process with a
high-kinetic inductance layer. We have successfully tested the binary shifter
at both the LSB-to-MSB and MSB-to-LSB propagation regimes for all eight shift
arguments. A single shift operation on a single input word demonstrated
operational margins of +/-16% of the dc bias current. The correct functionality
of the 8-bit ERSFQ binary shifter with the large, exhaustive data pattern was
observed within +/-10% margins of the dc bias current. In this paper, we
describe the design and present the test results for the ERSFQ 8-bit parallel
binary shifter.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirichenko_A/0/1/0/all/0/1&quot;&gt;A. F. Kirichenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamkar_M/0/1/0/all/0/1&quot;&gt;M. Y. Kamkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walter_J/0/1/0/all/0/1&quot;&gt;J. Walter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vernik_I/0/1/0/all/0/1&quot;&gt;I. V. Vernik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.07848">
<title>Gradient Scheduling with Global Momentum for Non-IID Data Distributed Asynchronous Training. (arXiv:1902.07848v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1902.07848</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed asynchronous offline training has received widespread attention
in recent years because of its high performance on large-scale data and complex
models. As data are processed from cloud-centric positions to edge locations, a
big challenge for distributed systems is how to handle native and natural
non-independent and identically distributed (non-IID) data for training.
Previous asynchronous training methods do not have a satisfying performance on
non-IID data because it would result in that the training process fluctuates
greatly which leads to an abnormal convergence. We propose a gradient
scheduling algorithm with global momentum (GSGM) for non-IID data distributed
asynchronous training. Our key idea is to schedule the gradients contributed by
computing nodes based on a white list so that each training node&apos;s update
frequency remains even. Furthermore, our new momentum method can solve the
biased gradient problem. GSGM can make model converge effectively, and maintain
high availability eventually. Experimental results show that for non-IID data
training under the same experimental conditions, GSGM on popular optimization
algorithms can achieve an 20% increase in training stability with a slight
improvement in accuracy on Fashion-Mnist and CIFAR-10 datasets. Meanwhile, when
expanding distributed scale on CIFAR-100 dataset that results in sparse data
distribution, GSGM can perform an 37% improvement on training stability.
Moreover, only GSGM can converge well when the number of computing nodes is 30,
compared to the state-of-the-art distributed asynchronous algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chengjie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruixuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1&quot;&gt;Pan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haozhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuhua Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Song Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Keqin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.09130">
<title>An Attention Enhanced Graph Convolutional LSTM Network for Skeleton-Based Action Recognition. (arXiv:1902.09130v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1902.09130</link>
<description rdf:parseType="Literal">&lt;p&gt;Skeleton-based action recognition is an important task that requires the
adequate understanding of movement characteristics of a human action from the
given skeleton sequence. Recent studies have shown that exploring spatial and
temporal features of the skeleton sequence is vital for this task.
Nevertheless, how to effectively extract discriminative spatial and temporal
features is still a challenging problem. In this paper, we propose a novel
Attention Enhanced Graph Convolutional LSTM Network (AGC-LSTM) for human action
recognition from skeleton data. The proposed AGC-LSTM can not only capture
discriminative features in spatial configuration and temporal dynamics but also
explore the co-occurrence relationship between spatial and temporal domains. We
also present a temporal hierarchical architecture to increases temporal
receptive fields of the top AGC-LSTM layer, which boosts the ability to learn
the high-level semantic representation and significantly reduces the
computation cost. Furthermore, to select discriminative spatial information,
the attention mechanism is employed to enhance information of key joints in
each AGC-LSTM layer. Experimental results on two datasets are provided: NTU
RGB+D dataset and Northwestern-UCLA dataset. The comparison results demonstrate
the effectiveness of our approach and show that our approach outperforms the
state-of-the-art methods on both datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1&quot;&gt;Chenyang Si&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wentao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1&quot;&gt;Tieniu Tan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.09500">
<title>ERSFQ 8-bit Parallel Arithmetic Logic Unit. (arXiv:1902.09500v2 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/1902.09500</link>
<description rdf:parseType="Literal">&lt;p&gt;We have designed and tested a parallel 8-bit ERSFQ arithmetic logic unit
(ALU). The ALU design employs wave-pipelined instruction execution and features
modular bit-slice architecture that is easily extendable to any number of bits
and adaptable to current recycling. A carry signal synchronized with an
asynchronous instruction propagation provides the wave-pipeline operation of
the ALU. The ALU instruction set consists of 14 arithmetical and logical
instructions. It has been designed and simulated for operation up to a 10 GHz
clock rate at the 10-kA/cm2 fabrication process. The ALU is embedded into a
shift-register-based high-frequency testbed with on-chip clock generator to
allow for comprehensive high frequency testing for all possible operands. The
8-bit ERSFQ ALU, comprising 6840 Josephson junctions, has been fabricated with
MIT Lincoln Lab 10-kA/cm2 SFQ5ee fabrication process featuring eight Nb wiring
layers and a high-kinetic inductance layer needed for ERSFQ technology. We
evaluated the bias margins for all instructions and various operands at both
low and high frequency clock. At low frequency, clock and all instruction
propagation through ALU were observed with bias margins of +/-11% and +/-9%,
respectively. Also at low speed, the ALU exhibited correct functionality for
all arithmetical and logical instructions with +/-6% bias margins. We tested
the 8-bit ALU for all instructions up to 2.8 GHz clock frequency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirichenko_A/0/1/0/all/0/1&quot;&gt;A. F. Kirichenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vernik_I/0/1/0/all/0/1&quot;&gt;I. V. Vernik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamkar_M/0/1/0/all/0/1&quot;&gt;M. Y. Kamkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walter_J/0/1/0/all/0/1&quot;&gt;J. Walter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_M/0/1/0/all/0/1&quot;&gt;M. Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albu_L/0/1/0/all/0/1&quot;&gt;L. R. Albu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhanov_O/0/1/0/all/0/1&quot;&gt;O. A. Mukhanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.10505">
<title>Viable Dependency Parsing as Sequence Labeling. (arXiv:1902.10505v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1902.10505</link>
<description rdf:parseType="Literal">&lt;p&gt;We recast dependency parsing as a sequence labeling problem, exploring
several encodings of dependency trees as labels. While dependency parsing by
means of sequence labeling had been attempted in existing work, results
suggested that the technique was impractical. We show instead that with a
conventional BiLSTM-based model it is possible to obtain fast and accurate
parsers. These parsers are conceptually simple, not needing traditional parsing
algorithms or auxiliary structures. However, experiments on the PTB and a
sample of UD treebanks show that they provide a good speed-accuracy tradeoff,
with results competitive with more complex approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strzyz_M/0/1/0/all/0/1&quot;&gt;Michalina Strzyz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vilares_D/0/1/0/all/0/1&quot;&gt;David Vilares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_C/0/1/0/all/0/1&quot;&gt;Carlos G&amp;#xf3;mez-Rodr&amp;#xed;guez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1902.11191">
<title>A Complexity Dichotomy for Colourful Components Problems on $k$-caterpillars and Small-Degree Planar Graphs. (arXiv:1902.11191v3 [cs.DM] UPDATED)</title>
<link>http://arxiv.org/abs/1902.11191</link>
<description rdf:parseType="Literal">&lt;p&gt;A connected component of a vertex-coloured graph is said to be colourful if
all its vertices have different colours, and a graph is colourful if all its
connected components are colourful. Given a vertex-coloured graph, the
Colourful Components problem asks whether there exist at most $p$ edges whose
removal makes the graph colourful, and the Colourful Partition problem asks
whether there exists a partition of the vertex set with at most $p$ parts such
that each part induces a colourful component. We study the problems on
$k$-caterpillars (caterpillars with hairs of length at most $k$) and explore
the boundary between polynomial and NP-complete cases. It is known that the
problems are NP-complete on $2$-caterpillars with unbounded maximum degree. We
prove that both problems remain NP-complete on binary $4$-caterpillars and on
ternary $3$-caterpillars. This answers an open question regarding the
complexity of the problems on trees with maximum degree at most $5$. On the
positive side, we give a linear time algorithm for $1$-caterpillars with
unbounded degree, even if the backbone is a cycle, which outperforms the
previous best complexity on paths and widens the class of graphs. Finally, we
answer an open question regarding the complexity of Colourful Components on
graphs with maximum degree at most $5$. We show that the problem is NP-complete
on $5$-coloured planar graphs with maximum degree $4$, and on $12$-coloured
planar graphs with maximum degree $3$. Since the problem can be solved in
polynomial-time on graphs with maximum degree $2$, the results are the best
possible with regard to the maximum degree.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chlebikova_J/0/1/0/all/0/1&quot;&gt;Janka Chlebikova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dallard_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Dallard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.00709">
<title>PartNet: A Recursive Part Decomposition Network for Fine-grained and Hierarchical Shape Segmentation. (arXiv:1903.00709v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.00709</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning approaches to 3D shape segmentation are typically formulated as
a multi-class labeling problem. Existing models are trained for a fixed set of
labels, which greatly limits their flexibility and adaptivity. We opt for
top-down recursive decomposition and develop the first deep learning model for
hierarchical segmentation of 3D shapes, based on recursive neural networks.
Starting from a full shape represented as a point cloud, our model performs
recursive binary decomposition, where the decomposition network at all nodes in
the hierarchy share weights. At each node, a node classifier is trained to
determine the type (adjacency or symmetry) and stopping criteria of its
decomposition. The features extracted in higher level nodes are recursively
propagated to lower level ones. Thus, the meaningful decompositions in higher
levels provide strong contextual cues constraining the segmentations in lower
levels. Meanwhile, to increase the segmentation accuracy at each node, we
enhance the recursive contextual feature with the shape feature extracted for
the corresponding part. Our method segments a 3D shape in point cloud into an
unfixed number of parts, depending on the shape complexity, showing strong
generality and flexibility. It achieves the state-of-the-art performance, both
for fine-grained and semantic segmentation, on the public benchmark and a new
benchmark of fine-grained segmentation proposed in this work. We also
demonstrate its application for fine-grained part refinements in image-to-shape
reconstruction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Fenggen Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Kun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Chenyang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kai Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.01698">
<title>Improving Cross-Domain Chinese Word Segmentation with Word Embeddings. (arXiv:1903.01698v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.01698</link>
<description rdf:parseType="Literal">&lt;p&gt;Cross-domain Chinese Word Segmentation (CWS) remains a challenge despite
recent progress in neural-based CWS. The limited amount of annotated data in
the target domain has been the key obstacle to a satisfactory performance. In
this paper, we propose a semi-supervised word-based approach to improving
cross-domain CWS given a baseline segmenter. Particularly, our model only
deploys word embeddings trained on raw text in the target domain, discarding
complex hand-crafted features and domain-specific dictionaries. Innovative
subsampling and negative sampling methods are proposed to derive word
embeddings optimized for CWS. We conduct experiments on five datasets in
special domains, covering domains in novels, medicine, and patent. Results show
that our model can obviously improve cross-domain CWS, especially in the
segmentation of domain-specific noun entities. The word F-measure increases by
over 3.0% on four datasets, outperforming state-of-the-art semi-supervised and
unsupervised cross-domain CWS approaches with a large margin. We make our code
and data available on Github.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yuxiao Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yue Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weikang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1&quot;&gt;Likun Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jian Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.02728">
<title>Graphical Contrastive Losses for Scene Graph Generation. (arXiv:1903.02728v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.02728</link>
<description rdf:parseType="Literal">&lt;p&gt;Most scene graph generators use a two-stage pipeline to detect visual
relationships: the first stage detects entities, and the second predicts the
predicate for each entity pair using a softmax distribution. We find that such
pipelines, trained with only a cross entropy loss over predicate classes,
suffer from two common errors. The first, Entity Instance Confusion, occurs
when the model confuses multiple instances of the same type of entity (e.g.
multiple cups). The second, Proximal Relationship Ambiguity, arises when
multiple subject-predicate-object triplets appear in close proximity with the
same predicate, and the model struggles to infer the correct subject-object
pairings (e.g. mis-pairing musicians and their instruments). We propose a set
of contrastive loss formulations that specifically target these types of errors
within the scene graph generation problem, collectively termed the Graphical
Contrastive Losses. These losses explicitly force the model to disambiguate
related and unrelated instances through margin constraints specific to each
type of confusion. We further construct a relationship detector, called RelDN,
using the aforementioned pipeline to demonstrate the efficacy of our proposed
losses. Our model outperforms the winning method of the OpenImages Relationship
Detection Challenge by 4.7\% (16.5\% relative) on the test set. We also show
improved results over the best previous methods on the Visual Genome and Visual
Relationship Detection datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Ji Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shih_K/0/1/0/all/0/1&quot;&gt;Kevin J. Shih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elgammal_A/0/1/0/all/0/1&quot;&gt;Ahmed Elgammal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_A/0/1/0/all/0/1&quot;&gt;Andrew Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1&quot;&gt;Bryan Catanzaro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.06494">
<title>Content Differences in Syntactic and Semantic Representations. (arXiv:1903.06494v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.06494</link>
<description rdf:parseType="Literal">&lt;p&gt;Syntactic analysis plays an important role in semantic parsing, but the
nature of this role remains a topic of ongoing debate. The debate has been
constrained by the scarcity of empirical comparative studies between syntactic
and semantic schemes, which hinders the development of parsing methods informed
by the details of target schemes and constructions. We target this gap, and
take Universal Dependencies (UD) and UCCA as a test case. After abstracting
away from differences of convention or formalism, we find that most content
divergences can be ascribed to: (1) UCCA&apos;s distinction between a Scene and a
non-Scene; (2) UCCA&apos;s distinction between primary relations, secondary ones and
participants; (3) different treatment of multi-word expressions, and (4)
different treatment of inter-clause linkage. We further discuss the long tail
of cases where the two schemes take markedly different approaches. Finally, we
show that the proposed comparison methodology can be used for fine-grained
evaluation of UCCA parsing, highlighting both challenges and potential sources
for improvement. The substantial differences between the schemes suggest that
semantic parsers are likely to benefit downstream text understanding
applications beyond their syntactic counterparts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1&quot;&gt;Daniel Hershcovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1&quot;&gt;Omri Abend&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rappoport_A/0/1/0/all/0/1&quot;&gt;Ari Rappoport&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.08252">
<title>MP net as Abstract Model of Communication for Message-passing Applications. (arXiv:1903.08252v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1903.08252</link>
<description rdf:parseType="Literal">&lt;p&gt;MP net is a formal model specifically designed for the field of parallel
applications that use a message passing interface. The main idea is to use MP
net as a comprehensible way of presenting the actual structure of communication
within MPI applications. The goal is to provide users with the kind of feedback
that can help them to check quickly whether or not the actual communication
within their application corresponds to the intended one. This paper introduces
MP net that focuses on the communication part of parallel applications and
emphasizes its spatial character, which is rather hidden in sequential
(textual) form.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Surkovsky_M/0/1/0/all/0/1&quot;&gt;Martin &amp;#x160;urkovsk&amp;#xfd;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.08450">
<title>Decay-Function-Free Time-Aware Attention to Context and Speaker Indicator for Spoken Language Understanding. (arXiv:1903.08450v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.08450</link>
<description rdf:parseType="Literal">&lt;p&gt;To capture salient contextual information for spoken language understanding
(SLU) of a dialogue, we propose time-aware models that automatically learn the
latent time-decay function of the history without a manual time-decay function.
We also propose a method to identify and label the current speaker to improve
the SLU accuracy. In experiments on the benchmark dataset used in Dialog State
Tracking Challenge 4, the proposed models achieved significantly higher F1
scores than the state-of-the-art contextual models. Finally, we analyze the
effectiveness of the introduced models in detail. The analysis demonstrates
that the proposed methods were effective to improve SLU accuracy individually.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jonggu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jong-Hyeok Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09333">
<title>A Type-coherent, Expressive Representation as an Initial Step to Language Understanding. (arXiv:1903.09333v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09333</link>
<description rdf:parseType="Literal">&lt;p&gt;A growing interest in tasks involving language understanding by the NLP
community has led to the need for effective semantic parsing and inference.
Modern NLP systems use semantic representations that do not quite fulfill the
nuanced needs for language understanding: adequately modeling language
semantics, enabling general inferences, and being accurately recoverable. This
document describes underspecified logical forms (ULF) for Episodic Logic (EL),
which is an initial form for a semantic representation that balances these
needs. ULFs fully resolve the semantic type structure while leaving issues such
as quantifier scope, word sense, and anaphora unresolved; they provide a
starting point for further resolution into EL, and enable certain structural
inferences without further resolution. This document also presents preliminary
results of creating a hand-annotated corpus of ULFs for the purpose of training
a precise ULF parser, showing a three-person pairwise interannotator agreement
of 0.88 on confident annotations. We hypothesize that a divide-and-conquer
approach to semantic parsing starting with derivation of ULFs will lead to
semantic analyses that do justice to subtle aspects of linguistic meaning, and
will enable construction of more accurate semantic parsers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1&quot;&gt;Gene Louis Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schubert_L/0/1/0/all/0/1&quot;&gt;Lenhart Schubert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09465">
<title>Managing Recurrent Virtual Network Updates in Multi-Tenant Datacenters: A System Perspective. (arXiv:1903.09465v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09465</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advent of software-defined networking, network configuration through
programmable interfaces becomes practical, leading to various on-demand
opportunities for network routing update in multi-tenant datacenters, where
tenants have diverse requirements on network routings such as short latency,
low path inflation, large bandwidth, high reliability, etc. Conventional
solutions that rely on topology search coupled with an objective function to
find desired routings have at least two shortcomings: (i) they run into
scalability issues when handling consistent and frequent routing updates and
(ii) they restrict the flexibility and capability to satisfy various routing
requirements. To address these issues, this paper proposes a novel search and
optimization decoupled design, which not only saves considerable topology
search costs via search result reuse, but also avoids possible sub-optimality
in greedy routing search algorithms by making decisions based on the global
view of all possible routings. We implement a prototype of our proposed system,
OpReduce, and perform extensive evaluations to validate its design goals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhuotao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yuan Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuewu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Changping Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09717">
<title>Instance and Output Optimal Parallel Algorithms for Acyclic Joins. (arXiv:1903.09717v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09717</link>
<description rdf:parseType="Literal">&lt;p&gt;Massively parallel join algorithms have received much attention in recent
years, while most prior work has focused on worst-optimal algorithms. However,
the worst-case optimality of these join algorithms relies on hard instances
having very large output sizes, which rarely appear in practice. A stronger
notion of optimality is {\em output-optimal}, which requires an algorithm to be
optimal within the class of all instances sharing the same input and output
size. An even stronger optimality is {\em instance-optimal}, i.e., the
algorithm is optimal on every single instance, but this may not always be
achievable.
&lt;/p&gt;
&lt;p&gt;In the traditional RAM model of computation, the classical Yannakakis
algorithm is instance-optimal on any acyclic join. But in the massively
parallel computation (MPC) model, the situation becomes much more complicated.
We first show that for the class of r-hierarchical joins, instance-optimality
can still be achieved in the MPC model. Then, we give a new MPC algorithm for
an arbitrary acyclic join with load $O ({\IN \over p} + {\sqrt{\IN \cdot \OUT}
\over p})$, where $\IN,\OUT$ are the input and output sizes of the join, and
$p$ is the number of servers in the MPC model. This improves the MPC version of
the Yannakakis algorithm by an $O (\sqrt{\OUT \over \IN} )$ factor.
Furthermore, we show that this is output-optimal when $\OUT = O(p \cdot \IN)$,
for every acyclic but non-r-hierarchical join. Finally, we give the first
output-sensitive lower bound for the triangle join in the MPC model, showing
that it is inherently more difficult than acyclic joins.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xiao Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_K/0/1/0/all/0/1&quot;&gt;Ke Yi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.09755">
<title>Trifocal Relative Pose from Lines at Points and its Efficient Solution. (arXiv:1903.09755v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.09755</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new minimal problem for relative pose estimation mixing point
features with lines incident at points observed in three views and its
efficient homotopy continuation solver. We demonstrate the generality of the
approach by analyzing and solving an additional problem with mixed point and
line correspondences in three views. The minimal problems include
correspondences of (i) three points and one line and (ii) three points and two
lines through two of the points which is reported and analyzed here for the
first time. These are difficult to solve, as they have 216 and - as shown here
- 312 solutions, but cover important practical situations when line and point
features appear together, e.g., in urban scenes or when observing curves. We
demonstrate that even such difficult problems can be solved robustly using a
suitable homotopy continuation technique and we provide an implementation
optimized for minimal problems that can be integrated into engineering
applications. Our simulated and real experiments demonstrate our solvers in the
camera geometry computation task in structure from motion. We show that new
solvers allow for reconstructing challenging scenes where the standard two-view
initialization of structure from motion fails.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fabbri_R/0/1/0/all/0/1&quot;&gt;Ricardo Fabbri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duff_T/0/1/0/all/0/1&quot;&gt;Timothy Duff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1&quot;&gt;Hongyi Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regan_M/0/1/0/all/0/1&quot;&gt;Margaret Regan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinho_D/0/1/0/all/0/1&quot;&gt;David da Costa de Pinho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsigaridas_E/0/1/0/all/0/1&quot;&gt;Elias Tsigaridas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wrampler_C/0/1/0/all/0/1&quot;&gt;Charles Wrampler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauenstein_J/0/1/0/all/0/1&quot;&gt;Jonathan Hauenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimia_B/0/1/0/all/0/1&quot;&gt;Benjamin Kimia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leykin_A/0/1/0/all/0/1&quot;&gt;Anton Leykin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pajdla_T/0/1/0/all/0/1&quot;&gt;Tomas Pajdla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.10605">
<title>Q-Learning for Continuous Actions with Cross-Entropy Guided Policies. (arXiv:1903.10605v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1903.10605</link>
<description rdf:parseType="Literal">&lt;p&gt;Off-Policy reinforcement learning (RL) is an important class of methods for
many problem domains, such as robotics, where the cost of collecting data is
high and on-policy methods are consequently intractable. Standard methods for
applying Q-learning to continuous-valued action domains involve iteratively
sampling the Q-function to find a good action (e.g. via hill-climbing), or by
learning a policy network at the same time as the Q-function (e.g. DDPG). Both
approaches make tradeoffs between stability, speed, and accuracy. We propose a
novel approach, called Cross-Entropy Guided Policies, or CGP, that draws
inspiration from both classes of techniques. CGP aims to combine the stability
and performance of iterative sampling policies with the low computational cost
of a policy network. Our approach trains the Q-function using iterative
sampling with the Cross-Entropy Method (CEM), while training a policy network
to imitate CEM&apos;s sampling behavior. We demonstrate that our method is more
stable to train than state of the art policy network methods, while preserving
equivalent inference time compute costs, and achieving competitive total reward
on standard benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simmons_Edler_R/0/1/0/all/0/1&quot;&gt;Riley Simmons-Edler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eisner_B/0/1/0/all/0/1&quot;&gt;Ben Eisner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1&quot;&gt;Eric Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seung_S/0/1/0/all/0/1&quot;&gt;Sebastian Seung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daniel Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11242">
<title>An Empirical Study on Practicality of Specification Mining Algorithms on a Real-world Application. (arXiv:1903.11242v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11242</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamic model inference techniques have been the center of many research
projects recently. There are now multiple open source implementations of
state-of-the-art algorithms, which provide basic abstraction and merging
capabilities. Most of these tools and algorithms have been developed with one
particular application in mind, which is program comprehension. The outputs
models can abstract away the details of the program and represent the software
behavior in a concise and easy to understand form. However, one application
context that is less studied is using such inferred models for debugging, where
the behavior to abstract is a faulty behavior (e.g., a set of execution traces
including a failed test case). We tried to apply some of the existing model
inference techniques (implemented in a promising tool called MINT) in a
real-world industrial context to support program comprehension for debugging.
Our initial experiments have shown many limitations both in terms of
implementation as well as the algorithms. The paper will discuss the root cause
of the failures and proposes ideas for future improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mashhadi_M/0/1/0/all/0/1&quot;&gt;Mohammad Jafar Mashhadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemmati_H/0/1/0/all/0/1&quot;&gt;Hadi Hemmati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11249">
<title>W-Net: Reinforced U-Net for Density Map Estimation. (arXiv:1903.11249v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11249</link>
<description rdf:parseType="Literal">&lt;p&gt;Crowd management is of paramount importance when it comes to preventing
stampedes and saving lives, especially in a countries like China and India
where the combined population is a third of the global population. Millions of
people convene annually all around the nation to celebrate a myriad of events
and crowd count estimation is the linchpin of the crowd management system that
could prevent stampedes and save lives. We present a network for crowd counting
which reports state of the art results on crowd counting benchmarks. Our
contributions are, first, a U-Net inspired model which affords us to report
state of the art results. Second, we propose an independent decoding
Reinforcement branch which helps the network converge much earlier and also
enables the network to estimate density maps with high Structural Similarity
Index (SSIM). Third, we discuss the drawbacks of the contemporary architectures
and empirically show that even though our architecture achieves state of the
art results, the merit may be due to the encoder-decoder pipeline instead.
Finally, we report the error analysis which shows that the contemporary line of
work is at saturation and leaves certain prominent problems unsolved.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valloli_V/0/1/0/all/0/1&quot;&gt;Varun Kannadi Valloli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_K/0/1/0/all/0/1&quot;&gt;Kinal Mehta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11250">
<title>Auto-Embedding Generative Adversarial Networks for High Resolution Image Synthesis. (arXiv:1903.11250v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11250</link>
<description rdf:parseType="Literal">&lt;p&gt;Generating images via the generative adversarial network (GAN) has attracted
much attention recently. However, most of the existing GAN-based methods can
only produce low-resolution images of limited quality. Directly generating
high-resolution images using GANs is nontrivial, and often produces problematic
images with incomplete objects. To address this issue, we develop a novel GAN
called Auto-Embedding Generative Adversarial Network (AEGAN), which
simultaneously encodes the global structure features and captures the
fine-grained details. In our network, we use an autoencoder to learn the
intrinsic high-level structure of real images and design a novel denoiser
network to provide photo-realistic details for the generated images. In the
experiments, we are able to produce 512x512 images of promising quality
directly from the input noise. The resultant images exhibit better perceptual
photo-realism, i.e., with sharper structure and richer details, than other
baselines on several datasets, including Oxford-102 Flowers, Caltech-UCSD Birds
(CUB), High-Quality Large-scale CelebFaces Attributes (CelebA-HQ), Large-scale
Scene Understanding (LSUN) and ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yong Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1&quot;&gt;Qi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qingyao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1&quot;&gt;Qinfeng Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1&quot;&gt;Mingkui Tan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11306">
<title>Linkage Based Face Clustering via Graph Convolution Network. (arXiv:1903.11306v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11306</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present an accurate and scalable approach to the face
clustering task. We aim at grouping a set of faces by their potential
identities. We formulate this task as a link prediction problem: a link exists
between two faces if they are of the same identity. The key idea is that we
find the local context in the feature space around an instance (face) contains
rich information about the linkage relationship between this instance and its
neighbors. By constructing sub-graphs around each instance as input data, which
depict the local context, we utilize the graph convolution network (GCN) to
perform reasoning and infer the likelihood of linkage between pairs in the
sub-graphs. Experiments show that our method is more robust to the complex
distribution of faces than conventional methods, yielding favorably comparable
results to state-of-the-art methods on standard face clustering benchmarks, and
is scalable to large datasets. Furthermore, we show that the proposed method
does not need the number of clusters as prior, is aware of noises and outliers,
and can be extended to a multi-view version for more accurate clustering
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhongdao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Liang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yali Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shengjin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11340">
<title>Multilevel Text Normalization with Sequence-to-Sequence Networks and Multisource Learning. (arXiv:1903.11340v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11340</link>
<description rdf:parseType="Literal">&lt;p&gt;We define multilevel text normalization as sequence-to-sequence processing
that transforms naturally noisy text into a sequence of normalized units of
meaning (morphemes) in three steps: 1) writing normalization, 2) lemmatization,
3) canonical segmentation. These steps are traditionally considered separate
NLP tasks, with diverse solutions, evaluation schemes and data sources. We
exploit the fact that all these tasks involve sub-word sequence-to-sequence
transformation to propose a systematic solution for all of them using neural
encoder-decoder technology. The specific challenge that we tackle in this paper
is integrating the traditional know-how on separate tasks into the neural
sequence-to-sequence framework to improve the state of the art. We address this
challenge by enriching the general framework with mechanisms that allow
processing the information on multiple levels of text organization (characters,
morphemes, words, sentences) in combination with structural information
(multilevel language model, part-of-speech) and heterogeneous sources (text,
dictionaries). We show that our solution consistently improves on the current
methods in all three steps. In addition, we analyze the performance of our
system to show the specific contribution of the integrating components to the
overall improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruzsics_T/0/1/0/all/0/1&quot;&gt;Tatyana Ruzsics&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samardzic_T/0/1/0/all/0/1&quot;&gt;Tanja Samard&amp;#x17e;i&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11771">
<title>A Large-Scale Multi-Length Headline Corpus for Improving Length-Constrained Headline Generation Model Evaluation. (arXiv:1903.11771v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11771</link>
<description rdf:parseType="Literal">&lt;p&gt;Browsing news articles on multiple devices is now possible. The lengths of
news article headlines have precise upper bounds, dictated by the size of the
display of the relevant device or interface. Therefore, controlling the length
of headlines is essential when applying the task of headline generation to news
production. However, because there is no corpus of headlines of multiple
lengths for a given article, prior researches on controlling output length in
headline generation have not discussed whether the evaluation of the setting
that uses a single length reference can evaluate multiple length outputs
appropriately. In this paper, we introduce two corpora (JNC and JAMUL) to
confirm the validity of prior experimental settings and provide for the next
step toward the goal of controlling output length in headline generation. The
JNC provides common supervision data for headline generation. The JAMUL is a
large-scale evaluation dataset for headlines of three different lengths
composed by professional editors. We report new findings on these corpora; for
example, while the longest length reference summary can appropriately evaluate
the existing methods controlling output length, the methods do not manage the
selection of words according to length constraint.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hitomi_Y/0/1/0/all/0/1&quot;&gt;Yuta Hitomi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taguchi_Y/0/1/0/all/0/1&quot;&gt;Yuya Taguchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamori_H/0/1/0/all/0/1&quot;&gt;Hideaki Tamori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kikuta_K/0/1/0/all/0/1&quot;&gt;Ko Kikuta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nishitoba_J/0/1/0/all/0/1&quot;&gt;Jiro Nishitoba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okazaki_N/0/1/0/all/0/1&quot;&gt;Naoaki Okazaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1&quot;&gt;Kentaro Inui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okumura_M/0/1/0/all/0/1&quot;&gt;Manabu Okumura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11783">
<title>A dataset for resolving referring expressions in spoken dialogue via contextual query rewrites (CQR). (arXiv:1903.11783v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11783</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Contextual Query Rewrite (CQR) a dataset for multi-domain
task-oriented spoken dialogue systems that is an extension of the Stanford
dialog corpus (Eric et al., 2017a). While previous approaches have addressed
the issue of diverse schemas by learning candidate transformations (Naik et
al., 2018), we instead model the reference resolution task as a user query
reformulation task, where the dialog state is serialized into a natural
language query that can be executed by the downstream spoken language
understanding system. In this paper, we describe our methodology for creating
the query reformulation extension to the dialog corpus, and present an initial
set of experiments to establish a baseline for the CQR task. We have released
the corpus to the public [1] to support further research in this area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regan_M/0/1/0/all/0/1&quot;&gt;Michael Regan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastogi_P/0/1/0/all/0/1&quot;&gt;Pushpendre Rastogi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Arpit Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathias_L/0/1/0/all/0/1&quot;&gt;Lambert Mathias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11787">
<title>Successive-Cancellation Decoding of Linear Source Code. (arXiv:1903.11787v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11787</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the error probability of several decoding methods for
a source code with decoder side information, where the decoding methods are: 1)
symbol-wise maximum a posteriori decoding, 2) successive-cancellation decoding,
and 3) stochastic successive-cancellation decoding. The proof of the
effectiveness of a decoding method is reduced to that for an arbitrary decoding
method, where `effective&apos; means that the error probability goes to zero as $n$
goes to infinity. Furthermore, we revisit the polar source code showing that
stochastic successive-cancellation decoding, as well as successive-cancellation
decoding, is effective for this code.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muramatsu_J/0/1/0/all/0/1&quot;&gt;Jun Muramatsu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11791">
<title>Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection. (arXiv:1903.11791v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11791</link>
<description rdf:parseType="Literal">&lt;p&gt;Sound event detection with weakly labeled data is considered as a problem of
multi-instance learning. And the choice of pooling function is the key to
solving this problem. In this paper, we proposed a hierarchical pooling
structure to improve the performance of weakly labeled sound event detection
system. Proposed pooling structure has made remarkable improvements on three
types of pooling function without adding any parameters. Moreover, our system
has achieved competitive performance on Task 4 of Detection and Classification
of Acoustic Scenes and Events (DCASE) 2017 Challenge using hierarchical pooling
structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1&quot;&gt;Ke-Xin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yu-Han Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei-Qiang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11863">
<title>On Inertial Navigation and Attitude Initialization in Polar Areas. (arXiv:1903.11863v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1903.11863</link>
<description rdf:parseType="Literal">&lt;p&gt;Inertial navigation and attitude initialization in polar areas become a hot
topic in recent years in the navigation community, as the widely-used
navigation mechanization of the local level frame encounters the inherent
singularity when the latitude approaches 90 degrees. Great endeavors have been
devoted to devising novel navigation mechanizations such as the grid or
transversal frames. This paper highlights the fact that the common Earth-frame
mechanization is sufficiently good to well handle the singularity problem in
polar areas. Simulation results are reported to demonstrate the singularity
problem and the effectiveness of the Earth-frame mechanization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuanxin Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1&quot;&gt;Chao He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Gang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12033">
<title>Repeatable and Reproducible Wireless Networking Experimentation through Trace-based Simulation. (arXiv:1903.12033v2 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/1903.12033</link>
<description rdf:parseType="Literal">&lt;p&gt;To properly validate wireless networking solutions we depend on
experimentation. Simulation very often produces less accurate results due to
the use of models that are simplifications of the real phenomena they try to
model. Networking experimentation may offer limited repeatability and
reproducibility. Being influenced by external random phenomena such as noise,
interference, and multipath, real experiments are hardly repeatable. In
addition, they are difficult to reproduce due to testbed operational
constraints and availability. Without repeatability and reproducibility, the
validation of the networking solution under evaluation is questionable. In this
paper, we show how the Trace-based Simulation (TS) approach can be used to
accurately repeat and reproduce real experiments and, consequently, introduce a
paradigm shift when it comes to the evaluation of wireless networking
solutions. We present an extensive evaluation of the TS approach using the
Fed4FIRE+ w-iLab.2 testbed. The results show that it is possible to repeat and
reproduce real experiments using ns-3 trace-based simulations with more
accuracy than in pure simulation, with average accuracy gains above 50%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamela_V/0/1/0/all/0/1&quot;&gt;Vitor Lamela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fontes_H/0/1/0/all/0/1&quot;&gt;Helder Fontes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveira_T/0/1/0/all/0/1&quot;&gt;Tiago Oliveira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruela_J/0/1/0/all/0/1&quot;&gt;Jose Ruela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ricardo_M/0/1/0/all/0/1&quot;&gt;Manuel Ricardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campos_R/0/1/0/all/0/1&quot;&gt;Rui Campos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.12063">
<title>Robust, fast and accurate: a 3-step method for automatic histological image registration. (arXiv:1903.12063v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1903.12063</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a 3-step registration pipeline for differently stained
histological serial sections that consists of 1) a robust pre-alignment, 2) a
parametric registration computed on coarse resolution images, and 3) an
accurate nonlinear registration. In all three steps the NGF distance measure is
minimized with respect to an increasingly flexible transformation. We apply the
method in the ANHIR image registration challenge and evaluate its performance
on the training data. The presented method is robust (error reduction in 99.6%
of the cases), fast (runtime 4 seconds) and accurate (median relative target
registration error 0.19%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lotz_J/0/1/0/all/0/1&quot;&gt;Johannes Lotz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiss_N/0/1/0/all/0/1&quot;&gt;Nick Weiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heldmann_S/0/1/0/all/0/1&quot;&gt;Stefan Heldmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11672">
<title>MuSE-ing on the Impact of Utterance Ordering On Crowdsourced Emotion Annotations. (arXiv:1903.11672v1 [cs.SD] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1903.11672</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotion recognition algorithms rely on data annotated with high quality
labels. However, emotion expression and perception are inherently subjective.
There is generally not a single annotation that can be unambiguously declared
&quot;correct&quot;. As a result, annotations are colored by the manner in which they
were collected. In this paper, we conduct crowdsourcing experiments to
investigate this impact on both the annotations themselves and on the
performance of these algorithms. We focus on one critical question: the effect
of context. We present a new emotion dataset, Multimodal Stressed Emotion
(MuSE), and annotate the dataset using two conditions: randomized, in which
annotators are presented with clips in random order, and contextualized, in
which annotators are presented with clips in order. We find that contextual
labeling schemes result in annotations that are more similar to a speaker&apos;s own
self-reported labels and that labels generated from randomized schemes are most
easily predictable by automated systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaiswal_M/0/1/0/all/0/1&quot;&gt;Mimansa Jaiswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aldeneh_Z/0/1/0/all/0/1&quot;&gt;Zakaria Aldeneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bara_C/0/1/0/all/0/1&quot;&gt;Cristian-Paul Bara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yuanhang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burzo_M/0/1/0/all/0/1&quot;&gt;Mihai Burzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1&quot;&gt;Rada Mihalcea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Provost_E/0/1/0/all/0/1&quot;&gt;Emily Mower Provost&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1903.11935">
<title>A Stay-in-a-Set Game without a Stationary Equilibrium. (arXiv:1903.11935v1 [math.OC] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1903.11935</link>
<description rdf:parseType="Literal">&lt;p&gt;We give an example of a finite-state two-player turn-based stochastic game
with safety objectives for both players which has no stationary Nash
equilibrium. This answers an open question of Secchi and Sudderth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hansen_K/0/1/0/all/0/1&quot;&gt;Kristoffer Arnsfelt Hansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Raskin_M/0/1/0/all/0/1&quot;&gt;Mikhail Raskin&lt;/a&gt;</dc:creator>
</item>
</rdf:RDF>